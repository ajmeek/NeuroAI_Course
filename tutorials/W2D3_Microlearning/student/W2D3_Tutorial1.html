
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 7: Microlearning — Neuromatch Academy: NeuroAI</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="application/vnd.jupyter.widget-state+json">{"state": {"e164b0f32af34a59aba80769ef040855": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "77a34daf4d6344b88b6c9d986af900b1": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_e164b0f32af34a59aba80769ef040855", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "If you want to download the slides: https://osf.io/download//\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.IFrame at 0x7f934c83ff70>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io//?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}], "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/W2D3_Microlearning/student/W2D3_Tutorial1';</script>
<link href="../../../_static/ai-logo.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../further_reading.html" rel="next" title="Suggested further readings"/>
<link href="../chapter_title.html" rel="prev" title="Microlearning"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/ComputationalNeuroscience.html">
                        Prerequisites and preparatory materials for NMA Computational Neuroscience
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
                        Neuro Video Series (W0D0)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
                        Python Workshop 1 (W0D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
                        Python Workshop 2 (W0D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
                        Linear Algebra (W0D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D4_Calculus/chapter_title.html">
                        Calculus (W0D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D5_Statistics/chapter_title.html">
                        Statistics (W0D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_CognitiveStructures/chapter_title.html">
                        Cognitive Structures (W2D2)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/keynote.html">
                        Project Day keynote (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/continuing_your_project_after_the_course.html">
                        Continuing your project after the course
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/past_projects_overview.html">
                        Past projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/ComputationalNeuroscience.html">
                        Prerequisites and preparatory materials for NMA Computational Neuroscience
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
                        Neuro Video Series (W0D0)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
                        Python Workshop 1 (W0D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
                        Python Workshop 2 (W0D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
                        Linear Algebra (W0D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D4_Calculus/chapter_title.html">
                        Calculus (W0D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D5_Statistics/chapter_title.html">
                        Statistics (W0D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_CognitiveStructures/chapter_title.html">
                        Cognitive Structures (W2D2)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/keynote.html">
                        Project Day keynote (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/continuing_your_project_after_the_course.html">
                        Continuing your project after the course
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/past_projects_overview.html">
                        Past projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">Prerequisites and preparatory materials for NMA Computational Neuroscience</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pre-reqs Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">Neuro Video Series (W0D0)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.html">Human Psychophysics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.html">Behavioral Readout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.html">Live in Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.html">Brain Signals: Spiking Activity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.html">Brain Signals: LFP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.html">Brain Signals: EEG &amp; MEG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.html">Brain Signals: fMRI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.html">Brain Signals: Calcium Imaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.html">Stimulus Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.html">Neurotransmitters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.html">Neurons to Consciousness</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">Python Workshop 1 (W0D1)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">Tutorial: LIF Neuron Part I</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">Python Workshop 2 (W0D2)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">Tutorial 1: LIF Neuron Part II</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">Linear Algebra (W0D3)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">Tutorial 1: Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">Tutorial 2: Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">Bonus Tutorial: Discrete Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">Calculus (W0D4)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">Tutorial 1: Differentiation and Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">Tutorial 2: Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">Tutorial 3: Numerical Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">Statistics (W0D5)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">Tutorial 1: Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">Tutorial 2: Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D1_Generalization/chapter_title.html">Generalization (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Intro.html">W1D1 Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial1.html">Tutorial 1: Generalization in AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial2.html">Tutorial 2: Generalization in Neuroscience</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial3.html">Tutorial 3: Generalization in Cognitive Science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Outro.html">W1D1 Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_DaySummary.html">W1D1 Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_Macrocircuits/chapter_title.html">Macrocircuits (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Tutorial1.html">Tutorial 1: Depth vs Width</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_CognitiveStructures/chapter_title.html">Cognitive Structures (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_Tutorial1.html">Tutorial 1: Cognitive Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Microlearning (W2D3)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 7: Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../further_reading.html">Suggested further readings</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D4_Macrolearning/chapter_title.html">Macrolearning (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial1.html">Tutorial 1: The problem of changing data distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial2.html">Tutorial 2: Continual Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial3.html">Tutorial 3: Meta-learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial4.html">Tutorial 4: Biological meta reinforcement learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial5.html">Tutorial 5: Replay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mysteries</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D5_Mysteries/chapter_title.html">Mysteries (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_Intro.html">W2D5 Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_Tutorial1.html">Tutorial 1: Consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_Outro.html">W2D4 Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_DaySummary.html">W2D4 Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/keynote.html">Project Day keynote (W2D2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Project materials</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Example_project.html">Project Template</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/continuing_your_project_after_the_course.html">Continuing your project after the course</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/past_projects_overview.html">Past projects</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/past-projects/example_past_project.html">Example Past Project</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Professional Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/impact_talks.html">Impact Talks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_features.html">Career Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_panels.html">Career Panels</a></li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/NeuroAI_Course" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/NeuroAI_Course/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D3_Microlearning/student/W2D3_Tutorial1.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W2D3_Microlearning/student/W2D3_Tutorial1.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 7: Microlearning</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 7: Microlearning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
     Import dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-weight-perturbation">
   Section 1: Weight Perturbation
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-fill-in-the-blank">
     Exercise 1: fill-in-the-blank
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-node-perturbation">
   Section 2: Node Perturbation
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-assessing-the-variance-of-learning-algorithms">
   Section 3: Assessing the variance of learning algorithms
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-feedback-alignment">
   Section 4: Feedback Alignment
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-fill-in-the-blank">
     Exercise 2: fill-in-the-blank
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-kolen-pollack">
   Section 5: Kolen-Pollack
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-fill-in-the-blank">
   Exercise 3: fill-in-the-blank
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-assessing-the-bias-of-learning-algorithms">
   Section 5: Assessing the bias of learning algorithms
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-7-microlearning">
<h1>Tutorial 7: Microlearning<a class="headerlink" href="#tutorial-7-microlearning" title="Permalink to this heading">#</a></h1>
<p>**Week 2, Day 3: Microlearning</p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Blake Richards, Roman Pogodin, Daniel Levenstein, Colin Bredenberg, Jonathan Cornford</p>
<p><strong>Content reviewers:</strong> Names &amp; Surnames</p>
<p><strong>Production editors:</strong> Names &amp; Surnames</p>
<br/>
<p>Acknowledgments: [ACKNOWLEDGMENT_INFORMATION]</p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: [insert estimated duration of whole tutorial in minutes]</em></p>
<p>In this tutorial, you will learn about normative models of synaptic plasticity. Normative models of synaptic plasticity are learning rules for parameters in neural networks that have two important features:</p>
<ul class="simple">
<li><p>They optimize global objective functions that define behavioral/perceptual goals for an agent.</p></li>
<li><p>Unlike learning algorithms like backpropagation, they demonstrate how learning is ‘local’, i.e. it uses only information that could conceivably be available to a single synapse.</p></li>
</ul>
<p>These two features together make such learning algorithms good candidate models for how learning could work in the brain.</p>
<p>In this tutorial we will:</p>
<p><strong>Tutorial Learning Objectives</strong></p>
<ul class="simple">
<li><p>Relate local plasticity rules to estimates of loss gradients</p></li>
<li><p>Understand the impact of variance and bias in gradient estimators and how they affect performance on training data and generalization</p></li>
<li><p>Implement 2-3 learning rules in toy tasks</p></li>
<li><p>Describe issues with biological plausibility in some learning algorithms, most notably, weight transport</p></li>
</ul>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "77a34daf4d6344b88b6c9d986af900b1"}</script></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="import-dependencies">
<h2>Import dependencies<a class="headerlink" href="#import-dependencies" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Import dependencies</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pdb</span> <span class="c1"># we encourage you to use the debugger, rather than print statements!</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>

<span class="kn">import</span> <span class="nn">logging</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="c1"># @markdown</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>

<span class="c1"># The sigmoid activation function</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Returns the sigmoid function, i.e. 1/(1+exp(-X))</span>
<span class="sd">    """</span>

    <span class="c1"># to avoid runtime warnings, if abs(X) is more than 500, we just cap it there</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># this ensures we don't overwrite entries in X - Python can be a trickster!</span>
    <span class="n">toobig</span> <span class="o">=</span> <span class="n">X</span> <span class="o">&gt;</span> <span class="mi">500</span>
    <span class="n">toosmall</span> <span class="o">=</span> <span class="n">X</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">500</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">toobig</span><span class="p">]</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">toosmall</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">500</span>

    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Y</span><span class="p">))</span>


<span class="c1"># The ReLU activation function</span>
<span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Returns the ReLU function, i.e. X if X &gt; 0, 0 otherwise</span>
<span class="sd">    """</span>

    <span class="c1"># to avoid runtime warnings, if abs(X) is more than 500, we just cap it there</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># this ensures we don't overwrite entries in X - Python can be a trickster!</span>
    <span class="n">neg</span> <span class="o">=</span> <span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">Y</span>


<span class="c1"># A helper function to add an "always on" unit to the inputs, let's us keep the biases in the weight matrices</span>
<span class="k">def</span> <span class="nf">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Append an "always on" bias unit to some inputs</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># Creates a random set of batches, returns an array of indices, one for each batch</span>
<span class="k">def</span> <span class="nf">create_batches</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    For a given number of samples, returns an array of indices of random batches of the specified size.</span>

<span class="sd">    If the size of the data is not divisible by the batch size some samples will not be included.</span>
<span class="sd">    """</span>

    <span class="c1"># determine the total number of batches</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>

    <span class="c1"># get the batches (without replacement)</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_samples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_batches</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="c1"># Calculate the accuracy of the network on some data</span>
<span class="k">def</span> <span class="nf">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate the accuracy in categorization of some outputs given some targets.</span>
<span class="sd">    """</span>

    <span class="c1"># binarize the outputs for an easy calculation</span>
    <span class="n">categories</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float'</span><span class="p">)</span>

    <span class="c1"># get the accuracy</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">categories</span> <span class="o">*</span> <span class="n">targets</span><span class="p">)</span> <span class="o">/</span> <span class="n">targets</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span>


<span class="k">def</span> <span class="nf">calculate_cosine_similarity</span><span class="p">(</span><span class="n">grad_1</span><span class="p">,</span> <span class="n">grad_2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate the cosine similarity between two gradients</span>
<span class="sd">    """</span>
    <span class="n">grad_1</span> <span class="o">=</span> <span class="n">grad_1</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">grad_2</span> <span class="o">=</span> <span class="n">grad_2</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_1</span><span class="p">,</span> <span class="n">grad_2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_1</span><span class="p">,</span> <span class="n">grad_1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_2</span><span class="p">,</span> <span class="n">grad_2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">calculate_grad_snr</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate the average SNR |mean|/std across all parameters in a gradient update</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the MNIST dataset, 50K training images, 10K validation, 10K testing</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'./'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'./'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">rng_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">shuffled_train_idx</span> <span class="o">=</span> <span class="n">rng_data</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="mi">60000</span><span class="p">)</span>

<span class="n">full_train_images</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">full_train_images</span><span class="p">[</span><span class="n">shuffled_train_idx</span><span class="p">[:</span><span class="mi">50000</span><span class="p">]]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">valid_images</span> <span class="o">=</span> <span class="n">full_train_images</span><span class="p">[</span><span class="n">shuffled_train_idx</span><span class="p">[</span><span class="mi">50000</span><span class="p">:]]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>

<span class="n">full_train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">full_train_labels</span><span class="p">[</span><span class="n">shuffled_train_idx</span><span class="p">[:</span><span class="mi">50000</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">valid_labels</span> <span class="o">=</span> <span class="n">full_train_labels</span><span class="p">[</span><span class="n">shuffled_train_idx</span><span class="p">[</span><span class="mi">50000</span><span class="p">:]]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/9912422 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 9912422/9912422 [00:00&lt;00:00, 138927929.95it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/28881 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 28881/28881 [00:00&lt;00:00, 131812506.88it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/1648877 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 1648877/1648877 [00:00&lt;00:00, 39214403.39it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/4542 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 4542/4542 [00:00&lt;00:00, 10980131.85it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Plot some example images to make sure everything is loaded in properly</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_images</span><span class="p">[:,</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/5a1f747e3633dbb7540c2ff75cd26d8fbb5338ef4cf7aaf5fac4d4d1691d9f67.png" src="../../../_images/5a1f747e3633dbb7540c2ff75cd26d8fbb5338ef4cf7aaf5fac4d4d1691d9f67.png">
</img></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The main network class</span>
<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    The class for creating and training a two-layer perceptron.</span>
<span class="sd">    """</span>

    <span class="c1"># The initialization function</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        The initialization function for the MLP.</span>

<span class="sd">         - N is the number of hidden units</span>
<span class="sd">         - sigma is the SD for initializing the weights</span>
<span class="sd">         - activation is the function to use for unit activity, options are 'sigmoid' and 'ReLU'</span>
<span class="sd">        """</span>

        <span class="c1"># store the variables for easy access</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>

        <span class="c1"># initialize the weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_h</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="mi">784</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># input-to-hidden weights &amp; bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># hidden-to-output weights &amp; bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>  <span class="c1"># feedback weights</span>

    <span class="c1"># The non-linear activation function</span>
    <span class="k">def</span> <span class="nf">activate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Pass some inputs through the activation function.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">'sigmoid'</span><span class="p">:</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">'ReLU'</span><span class="p">:</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">"Unknown activation function"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Y</span>

    <span class="c1"># The function for performing a forward pass up through the network during inference</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">W_h</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Recognize inputs, i.e. do a forward pass up through the network. If desired, alternative weights</span>
<span class="sd">        can be provided</span>
<span class="sd">        """</span>

        <span class="c1"># load the current network weights if no weights given</span>
        <span class="k">if</span> <span class="n">W_h</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">W_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_h</span>
        <span class="k">if</span> <span class="n">W_y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span>

        <span class="c1"># calculate the hidden activities</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W_h</span><span class="p">,</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">noise</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">):</span>
            <span class="n">hidden</span> <span class="o">+=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">hidden</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># calculate the output activities</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W_y</span><span class="p">,</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">hidden</span><span class="p">)))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">noise</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">output</span>

    <span class="c1"># A function for calculating the derivative of the activation function</span>
    <span class="k">def</span> <span class="nf">act_deriv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activity</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculate the derivative of some activations with respect to the inputs</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">'sigmoid'</span><span class="p">:</span>
            <span class="n">derivative</span> <span class="o">=</span> <span class="n">activity</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">activity</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">'ReLU'</span><span class="p">:</span>
            <span class="n">derivative</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">activity</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">"Unknown activation function"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">derivative</span>

    <span class="k">def</span> <span class="nf">mse_loss_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">W_h</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculate the mean-squared error loss on the given targets (average over the batch)</span>
<span class="sd">        """</span>

        <span class="c1"># do a forward sweep through the network</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">W_y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">targets</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># The function for calculating the mean-squared error loss</span>
    <span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">W_h</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculate the mean-squared error loss on the given targets (average over the batch)</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_loss_batch</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">W_h</span><span class="o">=</span><span class="n">W_h</span><span class="p">,</span> <span class="n">W_y</span><span class="o">=</span><span class="n">W_y</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">))</span>

    <span class="c1"># function for calculating perturbation updates</span>
    <span class="k">def</span> <span class="nf">perturb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for perturbation learning, using noise with SD as given</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="n">NotImpelmentedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">node_perturb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for node perturbation learning, using noise with SD as given</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="n">NotImpelmentedError</span><span class="p">()</span>

    <span class="c1"># function for calculating gradient updates</span>
    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for gradient descent learning</span>
<span class="sd">        """</span>

        <span class="c1"># do a forward pass</span>
        <span class="n">hidden</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># calculate the gradients</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">output</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">hidden</span><span class="p">),</span> \
            <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span>

    <span class="c1"># function for calculating feedback alignment updates</span>
    <span class="k">def</span> <span class="nf">feedback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for feedback alignment learning</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="n">NotImpelmentedError</span><span class="p">()</span>

    <span class="c1"># function for calculating Kolen-Pollack updates</span>
    <span class="k">def</span> <span class="nf">kolepoll</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">eta_back</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for Kolen-Polack learning</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="n">NotImpelmentedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">return_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'backprop'</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="c1"># calculate the updates for the weights with the appropriate algorithm</span>
        <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">'perturb'</span><span class="p">:</span>
            <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturb</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">'node_perturb'</span><span class="p">:</span>
            <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_perturb</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">'feedback'</span><span class="p">:</span>
            <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedback</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">'kolepoll'</span><span class="p">:</span>
            <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kolepoll</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">eta_back</span><span class="o">=</span><span class="n">eta</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span>

    <span class="c1"># function for updating the network</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'backprop'</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Updates the synaptic weights (and unit biases) using the given algorithm, options are:</span>

<span class="sd">        - 'backprop': backpropagation-of-error (default)</span>
<span class="sd">        - 'perturb' : weight perturbation (use noise with SD as given)</span>
<span class="sd">        - 'feedback': feedback alignment</span>
<span class="sd">        - 'kolepoll': Kolen-Pollack</span>
<span class="sd">        """</span>

        <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_grad</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>

        <span class="c1"># do the updates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_h</span> <span class="o">+=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">delta_W_h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span> <span class="o">+=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">delta_W_y</span>

    <span class="c1"># train the network using the update functions</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> \
              <span class="n">algorithm</span><span class="o">=</span><span class="s1">'backprop'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Trains the network with algorithm in batches for the given number of epochs on the data provided.</span>

<span class="sd">        Uses batches with size as indicated by batch_size and given learning rate.</span>

<span class="sd">        For perturbation methods, uses SD of noise as given.</span>

<span class="sd">        Categorization accuracy on a test set is also calculated.</span>

<span class="sd">        Prints a message every report_rate epochs if requested.</span>

<span class="sd">        Returns an array of the losses achieved at each epoch (and accuracies if test data given).</span>
<span class="sd">        """</span>

        <span class="c1"># provide an output message</span>
        <span class="k">if</span> <span class="n">report</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Training starting..."</span><span class="p">)</span>

        <span class="c1"># make batches from the data</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="n">create_batches</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># create arrays to store loss and accuracy values</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_epochs</span> <span class="o">*</span> <span class="n">batches</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_epochs</span><span class="p">,))</span>
        <span class="n">cosine_similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_epochs</span><span class="p">,))</span>

        <span class="c1"># estimate the gradient SNR on the test set</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">W_h</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="p">[</span><span class="n">t</span><span class="p">]]</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="p">[</span><span class="n">t</span><span class="p">]]</span>
            <span class="n">grad</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_grad</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="n">snr</span> <span class="o">=</span> <span class="n">calculate_grad_snr</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
        <span class="c1"># run the training for the given number of epochs</span>
        <span class="n">update_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

            <span class="c1"># step through each batch</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batches</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="c1"># get the inputs and targets for this batch</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">images</span><span class="p">[:,</span> <span class="n">batches</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:]]</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="n">batches</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:]]</span>

                <span class="c1"># calculate the current loss</span>
                <span class="n">losses</span><span class="p">[</span><span class="n">update_counter</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

                <span class="c1"># update the weights</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
                <span class="n">update_counter</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># calculate the current test accuracy</span>
            <span class="p">(</span><span class="n">testhid</span><span class="p">,</span> <span class="n">testout</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">test_images</span><span class="p">)</span>
            <span class="n">accuracy</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">testout</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
            <span class="n">grad_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_grad</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
            <span class="n">grad_bp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_grad</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'backprop'</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
            <span class="n">cosine_similarity</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">calculate_cosine_similarity</span><span class="p">(</span><span class="n">grad_test</span><span class="p">,</span> <span class="n">grad_bp</span><span class="p">)</span>

            <span class="c1"># print an output message every 10 epochs</span>
            <span class="k">if</span> <span class="n">report</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">report_rate</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"...completed "</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                      <span class="s2">" epochs of training. Current loss: "</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="n">update_counter</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">"."</span><span class="p">)</span>

        <span class="c1"># provide an output message</span>
        <span class="k">if</span> <span class="n">report</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Training complete."</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">cosine_similarity</span><span class="p">,</span> <span class="n">snr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-weight-perturbation">
<h1>Section 1: Weight Perturbation<a class="headerlink" href="#section-1-weight-perturbation" title="Permalink to this heading">#</a></h1>
<p>INSERT COLIN’s VIDEO HERE
<span class="math notranslate nohighlight">\(
\newcommand{\stim}{\mathbf{x}}
\newcommand{\noisew}{\boldsymbol \Psi}
\newcommand{\noiser}{\boldsymbol \xi}
\newcommand{\target}{y}
\newcommand{\targetdim}{\mathbf{y}}
\newcommand{\identity}{\mathbf{I}}
\newcommand{\blackbox}{f}
\newcommand{\weight}{\mathbf{W}}
\newcommand{\loss}{\mathcal{L}}
\newcommand{\derivative}[2]{\frac{d#1}{d#2}}
\newcommand{\pderivative}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\rate}{\mathbf{r}}
\newcommand{\T}{^{\top}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}\,}
\newcommand{\brackets}[1]{\left(#1\right)}
\newcommand{\sqbrackets}[1]{\left[#1\right]}
\newcommand{\var}[1]{\mathbb{V}\mathrm{ar}\brackets{#1}}\)</span></p>
<p>Both subsequent methods of gradient estimation that we will explore are very closely related to <em>finite differences</em> derivative approximation. We will start with the update, and will subsequently demonstrate why it provides an estimate of the gradient. We will first add noise to our weights, using <span class="math notranslate nohighlight">\(\weight' = \weight + \noisew\)</span>, where <span class="math notranslate nohighlight">\(\noisew \sim \mathcal N(0, \sigma^2)\)</span>. We take as our update:</p>
<div class="amsmath math notranslate nohighlight" id="equation-01a6b5d0-5988-4369-a39f-351e46ca8829">
<span class="eqno">(125)<a class="headerlink" href="#equation-01a6b5d0-5988-4369-a39f-351e46ca8829" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \Delta \weight =  - \eta \mathbb{E}_{\noisew} \left [\left (\loss(\noisew) - \loss(0)\right ) \frac{(\weight' - \weight)}{\sigma^2} \right ].
\end{equation}\]</div>
<p>First, we will clarify why this parameter update is interesting from a neuroscientific perspective. If we look at the parameter update for a \textit{single synapse}, <span class="math notranslate nohighlight">\(\weight_{ij}\)</span>, we have:</p>
<div class="amsmath math notranslate nohighlight" id="equation-49817996-547a-4982-bb94-69c7c42c04d2">
<span class="eqno">(126)<a class="headerlink" href="#equation-49817996-547a-4982-bb94-69c7c42c04d2" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{ij} &amp;=  - \eta \mathbb{E}_{\noisew} \left [\left (\loss(\noisew) - \loss(0)\right ) \frac{(\weight'_{ij} - \weight_{ij})}{\sigma^2} \right ] \\
    &amp; \approx  - \eta \frac{1}{K}\sum_{k = 0}^K\left [\left (\loss(\noisew^{(k)}) - \loss(0)\right ) \frac{(\weight'^{(k)}_{ij} - \weight_{ij})}{\sigma^2} \right ],
\end{align}\]</div>
<p>where for the last approximate equality we are substituting an expectation over <span class="math notranslate nohighlight">\(\noisew\)</span> for an empirical approximation over <span class="math notranslate nohighlight">\(K\)</span> samples of <span class="math notranslate nohighlight">\(\noisew\)</span>. This update only requires information about the global loss, <span class="math notranslate nohighlight">\(\loss(\noisew^{(k)})\)</span> and the local parameter values, <span class="math notranslate nohighlight">\(\weight'^{(k)}_{ij}\)</span>: using this update, a synapse in a neural network can adapt its strength with <em>very little</em> information about what is going on in the rest of the neural circuit.</p>
<p>To see why this update is an approximation of the gradient, we first notice that by Taylor expansion <span class="math notranslate nohighlight">\(\loss(\noisew) \approx \loss(0) + \derivative{\loss}{\weight}\T \noisew\)</span>. Plugging this approximation into our update equation, we get:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9e795977-4ee6-4906-8a50-ddc867a6fa97">
<span class="eqno">(127)<a class="headerlink" href="#equation-9e795977-4ee6-4906-8a50-ddc867a6fa97" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{ij} &amp;=  - \eta \mathbb{E}_{\noisew} \left [\left (\derivative{\loss}{\weight}\T \noisew\right ) \frac{\noisew_{ij}}{\sigma^2} \right ] \\
    &amp;=  - \eta \derivative{\loss}{\weight_{ij}},
\end{align}\]</div>
<p>where this last equality follows from the fact that <span class="math notranslate nohighlight">\(\mathbb{E}_{\noisew} \left[\noisew_{ij} \noisew_{kl} = \sigma^2 \right]\)</span> if and only if <span class="math notranslate nohighlight">\(i = k\)</span> and <span class="math notranslate nohighlight">\(j = l\)</span>, and is 0 otherwise. Therefore, in expectation over many noise samples <span class="math notranslate nohighlight">\(\noisew\)</span>, our parameter update based purely on measuring how perturbations of the weights <span class="math notranslate nohighlight">\(\weight'\)</span> correlate with changes in the loss function <span class="math notranslate nohighlight">\(\loss(\noisew)\)</span>, ends up being an unbiased approximation of gradient descent.</p>
<section id="exercise-1-fill-in-the-blank">
<h2>Exercise 1: fill-in-the-blank<a class="headerlink" href="#exercise-1-fill-in-the-blank" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">WeightPerturbMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through weight perturbation</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">perturb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for perturbation learning, using noise with SD as given</span>
<span class="sd">        """</span>
        <span class="c1">###################################################################</span>
        <span class="c1">## Fill out the following then remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: determine the sign of the updates"</span><span class="p">)</span>
        <span class="c1">###################################################################</span>

        <span class="c1"># get the random perturbations</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_h</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># calculate the loss with and without the perturbations</span>
        <span class="n">loss_now</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss_per</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_h</span> <span class="o">+</span> <span class="n">delta_W_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span> <span class="o">+</span> <span class="n">delta_W_y</span><span class="p">)</span>

        <span class="c1"># updates</span>
        <span class="n">delta_loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">W_h_update</span> <span class="o">=</span> <span class="n">delta_loss</span> <span class="o">*</span> <span class="n">delta_W_h</span> <span class="o">/</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">W_y_update</span> <span class="o">=</span> <span class="n">delta_loss</span> <span class="o">*</span> <span class="n">delta_W_y</span> <span class="o">/</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">W_h_update</span><span class="p">,</span> <span class="n">W_y_update</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to remove solution</span>

<span class="k">class</span> <span class="nc">WeightPerturbMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through weight perturbation</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">perturb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for perturbation learning, using noise with SD as given</span>
<span class="sd">        """</span>

        <span class="c1"># get the random perturbations</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_h</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># calculate the loss with and without the perturbations</span>
        <span class="n">loss_now</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss_per</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_h</span> <span class="o">+</span> <span class="n">delta_W_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span> <span class="o">+</span> <span class="n">delta_W_y</span><span class="p">)</span>

        <span class="c1"># updates</span>
        <span class="n">delta_loss</span> <span class="o">=</span> <span class="n">loss_now</span> <span class="o">-</span> <span class="n">loss_per</span>
        <span class="n">W_h_update</span> <span class="o">=</span> <span class="n">delta_loss</span> <span class="o">*</span> <span class="n">delta_W_h</span> <span class="o">/</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">W_y_update</span> <span class="o">=</span> <span class="n">delta_loss</span> <span class="o">*</span> <span class="n">delta_W_y</span> <span class="o">/</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">W_h_update</span><span class="p">,</span> <span class="n">W_y_update</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># run parameters</span>
<span class="n">numhidden</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">initweight</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">learnrate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">numepochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">numrepeats</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">numbatches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">numupdates</span> <span class="o">=</span> <span class="n">numepochs</span> <span class="o">*</span> <span class="n">numbatches</span>
<span class="n">activation</span> <span class="o">=</span> <span class="s1">'sigmoid'</span>
<span class="n">report</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">rep_rate</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># set the random seed to the current time</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">12345</span>  <span class="c1"># int(round(datetime.now().timestamp()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create and train a WeightPerturbMLP</span>
<span class="n">rng_wp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="n">losses_perturb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numupdates</span><span class="p">,))</span>
<span class="n">accuracy_perturb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>

<span class="c1"># select 1000 random images to test the accuracy on</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">rng_wp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># create a network and train it using weight perturbation</span>
<span class="n">netperturb</span> <span class="o">=</span> <span class="n">WeightPerturbMLP</span><span class="p">(</span><span class="n">rng_wp</span><span class="p">,</span> <span class="n">numhidden</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">initweight</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
<span class="p">(</span><span class="n">losses_perturb</span><span class="p">[:],</span> <span class="n">accuracy_perturb</span><span class="p">[:],</span> <span class="n">_</span><span class="p">,</span> <span class="n">snr_perturb</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">netperturb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">rng_wp</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">numepochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> \
                     <span class="n">learning_rate</span><span class="o">=</span><span class="n">learnrate</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'perturb'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> \
                     <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="n">rep_rate</span><span class="p">)</span>

<span class="c1"># plot performance over time</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_perturb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Weight Perturbation"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Updates"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"MSE"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training starting...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  1  epochs of training. Current loss:  0.97 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  2  epochs of training. Current loss:  0.93 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  3  epochs of training. Current loss:  0.95 .
Training complete.
</pre></div>
</div>
<img alt="../../../_images/59a074ee5c72e68726fe6688f1de5a7d36849f214abb72d8f5e7cc6f5b044d05.png" src="../../../_images/59a074ee5c72e68726fe6688f1de5a7d36849f214abb72d8f5e7cc6f5b044d05.png">
</img></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-2-node-perturbation">
<h1>Section 2: Node Perturbation<a class="headerlink" href="#section-2-node-perturbation" title="Permalink to this heading">#</a></h1>
<p>While we can get an unbiased derivative approximation based solely on perturbations of the weights, we will show later on that this is actually a very inefficient method, because it requires averaging out <span class="math notranslate nohighlight">\(N^2\)</span> noise sources, where <span class="math notranslate nohighlight">\(N\)</span> is the dimension of <span class="math notranslate nohighlight">\(\rate\)</span>. Alternatively, if we add noise at the level of the units <span class="math notranslate nohighlight">\(\rate\)</span>, we will only have to average over <span class="math notranslate nohighlight">\(N\)</span> noise sources. To do this, we can use the following update, taking <span class="math notranslate nohighlight">\(\rate' = \rate + \noiser\)</span>, where <span class="math notranslate nohighlight">\(\noiser \sim \mathcal{N}(0,\sigma^2)\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8c30080b-f081-4e11-a630-c6c9863e3f4f">
<span class="eqno">(128)<a class="headerlink" href="#equation-8c30080b-f081-4e11-a630-c6c9863e3f4f" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \Delta \weight =  - \eta \mathbb{E}_{\noiser} \left [\left(\loss(\noiser) - \loss(0) \right ) \frac{(\rate' - \rate)}{\sigma^2} \stim\T \right ].
\end{equation}\]</div>
<p>We will now show why this update is interesting from a neuroscience perspective (for much the same reason as for weight perturbation). For a single synapse, the approximate update using samples of <span class="math notranslate nohighlight">\(\noiser\)</span> is given by:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e696f67a-9037-4e2c-9ee3-6fbe4be00369">
<span class="eqno">(129)<a class="headerlink" href="#equation-e696f67a-9037-4e2c-9ee3-6fbe4be00369" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \Delta \weight_{ij} \approx - \eta \frac{1}{K} \sum_{k=0}^{K} \left [\left(\loss(\noiser^{(k)}) - \loss(0) \right ) \frac{(\rate'^{(k)}_i - \rate_i)}{\sigma^2} \stim_j \right ].
\end{equation}\]</div>
<p>Once again this update requires very little knowledge about the rest of the neural circuit in order for a synapse to compute it. It requires knowledge of the global loss, <span class="math notranslate nohighlight">\(\loss(\noiser^{(k)})\)</span>, postsynaptic activity <span class="math notranslate nohighlight">\(\rate^{(k)}_i\)</span>, and presynaptic activity <span class="math notranslate nohighlight">\(\stim_j\)</span>. This form of parameter update is often called a Reward (loss)-modulated Hebbian plasticity rule, or a 3-factor plasticity rule.</p>
<p>To show that this update is unbiased, we again employ a Taylor expansion: <span class="math notranslate nohighlight">\(\loss(\noiser) \approx \loss(0) + \derivative{\loss}{\rate}\T\noiser\)</span>, to get:</p>
<div class="amsmath math notranslate nohighlight" id="equation-632c95c1-cd8b-41da-8a31-ecf96cdfab0f">
<span class="eqno">(130)<a class="headerlink" href="#equation-632c95c1-cd8b-41da-8a31-ecf96cdfab0f" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{ij} &amp;=  - \eta \mathbb{E}_{\noiser} \left [\left(\derivative{\loss}{\rate}\T\noiser \right ) \frac{\noiser_i}{\sigma^2} \stim_j \right ] \\
    &amp;=  - \eta \pderivative{\loss}{\rate_i} \stim_j \\
    &amp;=  - \eta \pderivative{\loss}{\rate_i} \pderivative{\rate_i}{\weight_{ij}}\\
    &amp;=  - \eta \pderivative{\loss}{\weight_{ij}},
\end{align}\]</div>
<p>Where the second equality follows from the fact that <span class="math notranslate nohighlight">\(\mathbb{E}_{\noiser} \left [ \noiser_i \noiser_k \right ] = \sigma^2\)</span> if and only if <span class="math notranslate nohighlight">\(i = k\)</span>, and is 0 otherwise. This analysis shows that we can estimate derivatives by correlating fluctuations in either <span class="math notranslate nohighlight">\(\weight\)</span> <em>or</em> <span class="math notranslate nohighlight">\(\rate\)</span> with fluctuations in the loss function. Neither strategy requires evaluating derivatives of <span class="math notranslate nohighlight">\(\blackbox(\cdot)\)</span>, they only require some extrinsic measure of performance, given by <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> and how performance varies in response to perturbations in either weights or nodes, respectively. In subsequent sections, we will investigate how these different methods compare in terms of their ability to estimate gradients in systems with large numbers of neurons. We will show that there is no free lunch–though these methods require less information, they are less <em>efficient</em> than analytic gradient calculations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NodePerturbMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through node perturbation</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">node_perturb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for node perturbation learning, using noise with SD as given</span>
<span class="sd">        """</span>

        <span class="c1"># get the random perturbations</span>
        <span class="n">hidden</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">hidden_p</span><span class="p">,</span> <span class="n">output_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>

        <span class="n">loss_now</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss_batch</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
        <span class="n">loss_per</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss_batch</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output_p</span><span class="p">)</span>
        <span class="n">delta_loss</span> <span class="o">=</span> <span class="n">loss_now</span> <span class="o">-</span> <span class="n">loss_per</span>

        <span class="n">hidden_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">delta_loss</span> <span class="o">*</span> <span class="p">(((</span><span class="n">hidden_p</span> <span class="o">-</span> <span class="n">hidden</span><span class="p">)</span> <span class="o">/</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">output_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">delta_loss</span> <span class="o">*</span> <span class="p">(((</span><span class="n">output_p</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span> <span class="o">/</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">hidden_p</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">hidden_update</span><span class="p">,</span> <span class="n">output_update</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create and train a NodePerturbMLP network</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Record the start time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">losses_node_perturb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numupdates</span><span class="p">,))</span>
<span class="n">accuracy_node_perturb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>

<span class="c1"># set the random seed</span>
<span class="n">rng_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># select 1000 random images to test the accuracy on</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">rng_np</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># create a network and train it using weight perturbation</span>
<span class="n">netnodeperturb</span> <span class="o">=</span> <span class="n">NodePerturbMLP</span><span class="p">(</span><span class="n">rng_np</span><span class="p">,</span> <span class="n">numhidden</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">initweight</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
<span class="p">(</span><span class="n">losses_node_perturb</span><span class="p">[:],</span> <span class="n">accuracy_node_perturb</span><span class="p">[:],</span> <span class="n">_</span><span class="p">,</span> <span class="n">snr_node_perturb</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">netnodeperturb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">rng_np</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">numepochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> \
                         <span class="n">learning_rate</span><span class="o">=</span><span class="n">learnrate</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'node_perturb'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> \
                         <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="n">rep_rate</span><span class="p">)</span>

<span class="c1"># plot performance over time</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_node_perturb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Node Perturbation"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'c'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_perturb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Weight Perturbation"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Updates"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"MSE"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Record the end time</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Calculate elapsed time</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="c1"># Print the results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Start Time: </span><span class="si">{:.5f}</span><span class="s2"> seconds"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start_time</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"End Time: </span><span class="si">{:.5f}</span><span class="s2"> seconds"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end_time</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Elapsed Time: </span><span class="si">{:.5f}</span><span class="s2"> seconds"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training starting...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  1  epochs of training. Current loss:  0.89 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  2  epochs of training. Current loss:  0.85 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  3  epochs of training. Current loss:  0.81 .
Training complete.
</pre></div>
</div>
<img alt="../../../_images/cd8a4c095809e91d36a87e31631662d9c24ffed815c9198289bde98ff1a8c527.png" src="../../../_images/cd8a4c095809e91d36a87e31631662d9c24ffed815c9198289bde98ff1a8c527.png">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Start Time: 1713371072.90105 seconds
End Time: 1713371295.93256 seconds
Elapsed Time: 223.03151 seconds
</pre></div>
</div>
</img></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-3-assessing-the-variance-of-learning-algorithms">
<h1>Section 3: Assessing the variance of learning algorithms<a class="headerlink" href="#section-3-assessing-the-variance-of-learning-algorithms" title="Permalink to this heading">#</a></h1>
<p><span class="math notranslate nohighlight">\(\newcommand{\stim}{\mathbf{x}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\noisew}{\boldsymbol \Psi}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\noiser}{\boldsymbol \xi}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\target}{y}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\targetdim}{\mathbf{y}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\identity}{\mathbf{I}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\blackbox}{f}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\weight}{\mathbf{W}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\loss}{\mathcal{L}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\derivative}[2]{\frac{d#1}{d#2}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\rate}{\mathbf{r}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\T}{^{\top}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\RR}{\mathbb{R}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\EE}{\mathbb{E}\,}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\brackets}[1]{\left(#1\right)}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\sqbrackets}[1]{\left[#1\right]}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\var}[1]{\mathbb{V}\mathrm{ar}\brackets{#1}}\)</span>
ADD VIDEO</p>
<p>The main issue of perturbation methods is noise. Here we will show that analytically for a simplified loss and network. First, we will work with a linear network so <span class="math notranslate nohighlight">\(\widehat\targetdim =\weight\stim\)</span>, where <span class="math notranslate nohighlight">\(\widehat\targetdim\in\RR^M\)</span>, <span class="math notranslate nohighlight">\(\weight\in\RR^{M\times N}\)</span> and <span class="math notranslate nohighlight">\(\stim\in\RR^N\)</span>. Second, we will assume that the target output is zero <span class="math notranslate nohighlight">\(\targetdim=0\)</span>, so the loss  becomes <span class="math notranslate nohighlight">\(\loss(\weight)=\frac{1}{2}\|\weight\stim\|^2_2\)</span>. (This is equivalent to saying that <span class="math notranslate nohighlight">\(\targetdim=\weight^*\stim\)</span> and then shifting the actual weights to be <span class="math notranslate nohighlight">\(\weight - \weight^*\)</span>.)</p>
<p>With these changes, we will compute the variance of weight updates for a given input <span class="math notranslate nohighlight">\(\stim\)</span>, i.e.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    \var{\Delta \weight}=\EE\brackets{\Delta \weight - \EE\Delta\weight}^2 = \EE\brackets{\Delta \weight}^2 - \brackets{\EE\Delta\weight}^2\,.
\end{equation*}\]</div>
<p>We already know that the <span class="math notranslate nohighlight">\(\EE\Delta\weight\)</span> is the gradient update, so</p>
<div class="amsmath math notranslate nohighlight" id="equation-f8c828a6-f298-4dbe-8758-66887bbb5e7f">
<span class="eqno">(131)<a class="headerlink" href="#equation-f8c828a6-f298-4dbe-8758-66887bbb5e7f" title="Permalink to this equation">#</a></span>\[\begin{equation}
   \brackets{\EE\Delta\weight_{ij}}^2 =  \eta^2  \brackets{\derivative{\loss}{\weight}}_{ij}^2.
\end{equation}\]</div>
<p>Therefore we only need to compute <span class="math notranslate nohighlight">\(\EE(\Delta\weight)^2\)</span> for both algorithms.</p>
<p><strong>Weight perturbation</strong> For a single weight <span class="math notranslate nohighlight">\(\weight_{ij}\)</span>, we can use the approximate weight change:</p>
<div class="amsmath math notranslate nohighlight" id="equation-2f51c321-9952-4ee6-8b9d-e074e9bc3faa">
<span class="eqno">(132)<a class="headerlink" href="#equation-2f51c321-9952-4ee6-8b9d-e074e9bc3faa" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{ij} \,&amp;=  - \eta \sum_{kl} \brackets{\brackets{\derivative{\loss}{\weight}}_{kl} \noisew_{kl}} \frac{\noisew_{ij}}{\sigma^2}\,,\\
    \brackets{\Delta \weight_{ij}}^2 \,&amp;=  \frac{\eta^2}{\sigma^4} \brackets{\sum_{kl}\brackets{\derivative{\loss}{\weight}}_{kl} \noisew_{kl}}^2 \noisew_{ij}^2\\
    &amp;=\frac{\eta^2}{\sigma^4} \brackets{\sum_{kldn}\brackets{\derivative{\loss}{\weight}}_{kl}\brackets{\derivative{\loss}{\weight}}_{dn} \noisew_{kl}\noisew_{dn}} \noisew_{ij}^2\,.
\end{align}\]</div>
<p>Now we can take the expectation of the last line w.r.t. the noise <span class="math notranslate nohighlight">\(\noisew\)</span>. Since all entries of the noise matrix are independent and zero-mean, we will have non-zero terms in two case: <span class="math notranslate nohighlight">\(kl=dn\neq ij\)</span> and <span class="math notranslate nohighlight">\(kl=dn=ij\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bed6161b-afd7-474f-acb5-8411ba29bd20">
<span class="eqno">(133)<a class="headerlink" href="#equation-bed6161b-afd7-474f-acb5-8411ba29bd20" title="Permalink to this equation">#</a></span>\[\begin{align}
    \EE\noisew_{kl}\noisew_{dn}\noisew_{ij}^2 = \begin{cases}
        0 &amp; k \neq d\ \mathrm{or}\ l\neq n\\
        \sigma^4 &amp; k=d, l=n, (k\neq i\ \mathrm{or}\ l\neq j)\\
        3\,\sigma^4 &amp; k=d=i,l=n=j
    \end{cases}
\end{align}\]</div>
<p>Therefore,</p>
<div class="amsmath math notranslate nohighlight" id="equation-e8d89761-1516-4b94-b8a5-d918f6b154a2">
<span class="eqno">(134)<a class="headerlink" href="#equation-e8d89761-1516-4b94-b8a5-d918f6b154a2" title="Permalink to this equation">#</a></span>\[\begin{align}
    \EE_{\noisew}\brackets{\brackets{\Delta \weight_{ij}}^2} \,&amp; = \frac{\eta^2}{\sigma^4}  \brackets{\derivative{\loss}{\weight}}_{ij}^2 \EE \noisew_{ij}^4 + \frac{\eta^2}{\sigma^4} \sum_{kl\neq ij} \brackets{\derivative{\loss}{\weight}}_{kl}^2 \EE\brackets{\noisew_{kl}^2 \noisew_{ij}^2}\\
    &amp;=3\eta^2  \brackets{\derivative{\loss}{\weight}}_{ij}^2 + \eta^2\sum_{kl\neq ij} \brackets{\derivative{\loss}{\weight}}_{kl}^2\,,
\end{align}\]</div>
<p>where we used that the 4th central of the Gaussian <span class="math notranslate nohighlight">\(\EE \noisew_{ij}^4=3\sigma^4\)</span>.</p>
<p>Using the above result, we arrive at</p>
<div class="amsmath math notranslate nohighlight" id="equation-ad6b16c4-2655-4fcd-916c-c012f3df154e">
<span class="eqno">(135)<a class="headerlink" href="#equation-ad6b16c4-2655-4fcd-916c-c012f3df154e" title="Permalink to this equation">#</a></span>\[\begin{align}
    \var{\Delta \weight_{ij}} = \eta^2  \brackets{\derivative{\loss}{\weight}}_{ij}^2 + \eta^2\sum_{kl} \brackets{\derivative{\loss}{\weight}}_{kl}^2 = O(MN)\,,
\end{align}\]</div>
<p>where the scaling comes from having <span class="math notranslate nohighlight">\(MN\)</span> terms in the sum.</p>
<p><strong>Node perturbation</strong> Again, for a single weight <span class="math notranslate nohighlight">\(\weight_{ij}\)</span>, we can use the approximate weight change:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9ead52ca-08a5-441c-890c-e770d883827b">
<span class="eqno">(136)<a class="headerlink" href="#equation-9ead52ca-08a5-441c-890c-e770d883827b" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{ij} \,&amp;= -\frac{\eta}{\sigma^2}\brackets{\sum_{k}\brackets{\derivative{\loss}{\rate}}_k\noiser_k} \noiser_i\stim_j\,,\\
    \brackets{\Delta \weight_{ij}}^2 \,&amp;= \frac{\eta^2}{\sigma^4}\brackets{\sum_{k}\brackets{\derivative{\loss}{\rate}}_k\noiser_k}^2 \noiser_i^2\stim_j^2\\
    &amp;=\frac{\eta^2}{\sigma^4}\brackets{\sum_{k}\brackets{\derivative{\loss}{\rate}}_k\brackets{\derivative{\loss}{\rate}}_d\noiser_k\noiser_d} \noiser_i^2\stim_j^2\,.
\end{align}\]</div>
<p>Again, computing the expectation over the last line will make use of the independent zero-mean Gaussian noise:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6c8d278e-79ed-4517-92cc-d6de18747f6b">
<span class="eqno">(137)<a class="headerlink" href="#equation-6c8d278e-79ed-4517-92cc-d6de18747f6b" title="Permalink to this equation">#</a></span>\[\begin{align}
    \EE\noiser_k\noiser_d\noiser_i^2 = \begin{cases}
        0 &amp; k \neq d\\
        \sigma^4 &amp; k=d\neq i\\
        3\,\sigma^4 &amp; k=d=i
    \end{cases}
\end{align}\]</div>
<p>Since only <span class="math notranslate nohighlight">\(k=d\neq i\)</span> and <span class="math notranslate nohighlight">\(k=d=i\)</span> terms will remain non-zero, we obtain</p>
<div class="amsmath math notranslate nohighlight" id="equation-c3bc6ff7-fa1c-45cf-b9e9-a037c3d89a6f">
<span class="eqno">(138)<a class="headerlink" href="#equation-c3bc6ff7-fa1c-45cf-b9e9-a037c3d89a6f" title="Permalink to this equation">#</a></span>\[\begin{align}
    \EE_{\noiser}\brackets{\brackets{\Delta \weight_{ij}}^2} \,&amp;= \frac{\eta^2}{\sigma^4}\brackets{\derivative{\loss}{\rate}}_i^2 \EE\brackets{\noiser_i^4}\stim_j^2 + \frac{\eta^2}{\sigma^4}\brackets{\sum_{k\neq i}\brackets{\derivative{\loss}{\rate}}_k^2\EE\brackets{\noiser_k^2 \noiser_i^2}\stim_j^2}\\
    &amp;=3 \eta^2\brackets{\derivative{\loss}{\rate}}_i^2 \stim_j^2 + \eta^2\sum_{k\neq i}\brackets{\derivative{\loss}{\rate}}_k^2\stim_j^2\,.
\end{align}\]</div>
<p>Now since <span class="math notranslate nohighlight">\(\brackets{\EE_{\noiser}\Delta \weight_{ij}}^2=\eta^2\brackets{\derivative{\loss}{\rate}}_i^2 \stim_j^2\)</span>, we have</p>
<div class="amsmath math notranslate nohighlight" id="equation-762bff94-e886-4a16-846d-5c8908187ba3">
<span class="eqno">(139)<a class="headerlink" href="#equation-762bff94-e886-4a16-846d-5c8908187ba3" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \var{\Delta \weight_{ij}} = \eta^2\brackets{\derivative{\loss}{\rate}}_i^2 \stim_j^2 + \eta^2\sum_{k}\brackets{\derivative{\loss}{\rate}}_k^2\stim_j^2 = O(M)\,,
\end{equation}\]</div>
<p>where the scaling comes from the sum over <span class="math notranslate nohighlight">\(M\)</span> outputs.</p>
<p>EXPLAIN SNR</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare the SNRs for Weight Perturbation, Node Perturbation, and Backpropagation</span>

<span class="c1"># initialize the loss and accuracy holders</span>
<span class="n">losses_backprop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numupdates</span><span class="p">,))</span>
<span class="n">accuracy_backprop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>

<span class="c1"># First, we have to train a network with Backpropagation for comparison</span>

<span class="c1"># set the random seed to the current time</span>
<span class="n">rng_bp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># select 1000 random images to test the accuracy on</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">rng_bp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># create a network and train it using backprop</span>
<span class="n">netbackprop</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">rng_np</span><span class="p">,</span> <span class="n">numhidden</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">initweight</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
<span class="p">(</span><span class="n">losses_backprop</span><span class="p">[:],</span> <span class="n">accuracy_backprop</span><span class="p">[:],</span> <span class="n">_</span><span class="p">,</span> <span class="n">snr_backprop</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">netbackprop</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">rng_bp</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">numepochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> \
                      <span class="n">learning_rate</span><span class="o">=</span><span class="n">learnrate</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'backprop'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> \
                      <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="n">rep_rate</span><span class="p">)</span>

<span class="c1"># plot performance over time</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_node_perturb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Node Perturbation"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'c'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_perturb</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Weight Perturbation"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_backprop</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Backprop"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Updates"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"MSE"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># plot the SNR at initialization for the three learning algorithms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">snr_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">snr_perturb</span><span class="p">,</span> <span class="n">snr_node_perturb</span><span class="p">,</span> <span class="n">snr_backprop</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'b'</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Weight Perturbation'</span><span class="p">,</span> <span class="s1">'Node Perturbation'</span><span class="p">,</span> <span class="s1">'Backprop'</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">snr_vals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">tick_label</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'SNR'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Algorithm'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Gradient SNR'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training starting...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  1  epochs of training. Current loss:  0.41 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  2  epochs of training. Current loss:  0.32 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  3  epochs of training. Current loss:  0.28 .
Training complete.
</pre></div>
</div>
<img alt="../../../_images/632d7d92bb25530a4fc0248df864300f85b25b6dbbe80518456951e74dd9acee.png" src="../../../_images/632d7d92bb25530a4fc0248df864300f85b25b6dbbe80518456951e74dd9acee.png">
<img alt="../../../_images/5add935072055c22edbbfb15abb8a1d36c6dadac68a532f6245aaecf4c2e7280.png" src="../../../_images/5add935072055c22edbbfb15abb8a1d36c6dadac68a532f6245aaecf4c2e7280.png"/>
</img></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-4-feedback-alignment">
<h1>Section 4: Feedback Alignment<a class="headerlink" href="#section-4-feedback-alignment" title="Permalink to this heading">#</a></h1>
<p>INSERT JONNY’S VIDEO HERE</p>
<p><span class="math notranslate nohighlight">\(\newcommand{\stim}{\mathbf{x}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\h}{\mathbf{h}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\noisew}{\boldsymbol \Psi}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\noiser}{\boldsymbol \xi}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\target}{y}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\pred}{\mathbf{\hat{y}}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\identity}{\mathbf{I}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\blackbox}{f}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\weight}{\mathbf{W}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\weightout}{\mathbf{W}^{\textrm{out}}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\loss}{\mathcal{L}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\derivative}[2]{\frac{\partial#1}{\partial#2}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\rate}{\mathbf{r}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\error}{\boldsymbol \delta}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\losserror}{\mathbf{e}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\backweight}{\mathbf{B}}\)</span></p>
<p>We assume the following network setup:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8ac7de78-5914-42c5-b8e0-7787a1093fe9">
<span class="eqno">(140)<a class="headerlink" href="#equation-8ac7de78-5914-42c5-b8e0-7787a1093fe9" title="Permalink to this equation">#</a></span>\[\begin{align}
    \pred = \blackbox(\weight \stim) = \weightout\sigma(\weight\stim) =\weightout \h
\end{align}\]</div>
<p>With a mean squared error loss over all of the output neurons.</p>
<div class="amsmath math notranslate nohighlight" id="equation-d3a4e269-dd07-4780-87c2-65e5cc6073e2">
<span class="eqno">(141)<a class="headerlink" href="#equation-d3a4e269-dd07-4780-87c2-65e5cc6073e2" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \loss = \frac{1}{2n} \sum_{k=1}^{n}\left (\target_k - \hat{y}_k \right )^2
\end{equation}\]</div>
<p>Note here we have suppressed the batch index notation, and will calculate the following gradients as averages over batch elements.</p>
<p>Backpropagation updates parameters using the gradient of the loss scaled by the learning rate <span class="math notranslate nohighlight">\(\eta\)</span>.</p>
<div class="amsmath math notranslate nohighlight" id="equation-455bd519-b99f-4ad9-be3f-28ea924be21d">
<span class="eqno">(142)<a class="headerlink" href="#equation-455bd519-b99f-4ad9-be3f-28ea924be21d" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{ji} &amp;= - \eta \derivative{\loss}{\weight}_{ji} \\
    &amp;= - \eta \underbrace{\derivative{\loss}{\pred}\derivative{\pred}{h_j}}_{\delta_j}\derivative{h_j}{\weight_{ji}}\\
    &amp;= - \eta \delta_j \sigma^{\prime}(\weight\stim)_j\stim_i \\
    &amp;= - \eta \delta_j h^{\prime}_j\stim_i
\end{align}\]</div>
<p>While <span class="math notranslate nohighlight">\(h^{\prime}_j\)</span> and <span class="math notranslate nohighlight">\(\stim_i\)</span> are available locally to the neuron, calculating <span class="math notranslate nohighlight">\(\delta_j\)</span>
involves non-local information, and is therefore biologically implausbile.</p>
<div class="amsmath math notranslate nohighlight" id="equation-c28aadbb-33f0-4f48-92e2-8fd7bfe85c7e">
<span class="eqno">(143)<a class="headerlink" href="#equation-c28aadbb-33f0-4f48-92e2-8fd7bfe85c7e" title="Permalink to this equation">#</a></span>\[\begin{align}
    \delta_j &amp;= \derivative{\loss}{h_j} \\
    &amp;= \sum_{k=1}^n \derivative{\loss}{\hat{y}_k}\derivative{\hat{y}_k}{h_j} \\
    &amp;= \sum_{k=1}^n \overbrace{(y_k - \hat{y_k})}^{e_k} \weightout_{kj} \\
    &amp;= e_1 {\color{red}\weightout_{1j}} + e_2 {\color{green}\weightout_{2j}} + e_3{\color{magenta}\weightout_{3j}}
\end{align}\]</div>
<p>In order to calculate <span class="math notranslate nohighlight">\(\delta_j\)</span> we need to use all of of the outgoing weights from neuron <span class="math notranslate nohighlight">\(h_j\)</span>.</p>
<p>Writing <span class="math notranslate nohighlight">\(\error\)</span> as a column vector (i.e. <span class="math notranslate nohighlight">\(\derivative{\loss}{\h}\)</span> in  \href{https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions}{denominator layout}) we see that in order to calcuate <span class="math notranslate nohighlight">\(\error\)</span> we need the transpose of the forward weights.</p>
<div class="amsmath math notranslate nohighlight" id="equation-09ba165b-1155-4ece-84de-fa1ce62ee0a3">
<span class="eqno">(144)<a class="headerlink" href="#equation-09ba165b-1155-4ece-84de-fa1ce62ee0a3" title="Permalink to this equation">#</a></span>\[\begin{align}
    \error &amp;= \weight_{out}^T \losserror .
\end{align}\]</div>
<p>Feedback alignment replaces <span class="math notranslate nohighlight">\(\weight_{out}^T \)</span> with a random matrix, <span class="math notranslate nohighlight">\(\backweight\)</span>.</p>
<section id="exercise-2-fill-in-the-blank">
<h2>Exercise 2: fill-in-the-blank<a class="headerlink" href="#exercise-2-fill-in-the-blank" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedbackAlignmentMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through the Feedback Alignment algorithm</span>
<span class="sd">    """</span>

    <span class="c1"># function for calculating feedback alignment updates</span>
    <span class="k">def</span> <span class="nf">feedback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for feedback alignment learning</span>
<span class="sd">        """</span>
        <span class="c1">###################################################################</span>
        <span class="c1">## Fill out the following then remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: calculate the updates"</span><span class="p">)</span>
        <span class="c1">###################################################################</span>

        <span class="c1"># do a forward pass</span>
        <span class="n">hidden</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># calculate the updates</span>
        <span class="n">error</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">,</span> <span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">hidden</span><span class="p">),</span>
                           <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="o">...</span>

        <span class="k">return</span> <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to remove solution</span>

<span class="k">class</span> <span class="nc">FeedbackAlignmentMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through the Feedback Alignment algorithm</span>
<span class="sd">    """</span>

    <span class="c1"># function for calculating feedback alignment updates</span>
    <span class="k">def</span> <span class="nf">feedback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for feedback alignment learning</span>
<span class="sd">        """</span>

        <span class="c1"># do a forward pass</span>
        <span class="n">hidden</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># calculate the updates</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">output</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">,</span> <span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">hidden</span><span class="p">),</span>
                           <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># run parameters</span>
<span class="n">numhidden</span>  <span class="o">=</span> <span class="mi">500</span>
<span class="n">batchsize</span>  <span class="o">=</span> <span class="mi">200</span>
<span class="n">initweight</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">learnrate</span>  <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">noise</span>      <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">numepochs</span>  <span class="o">=</span> <span class="mi">3</span>
<span class="n">numrepeats</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">numbatches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">numupdates</span> <span class="o">=</span> <span class="n">numepochs</span> <span class="o">*</span> <span class="n">numbatches</span>
<span class="n">activation</span> <span class="o">=</span> <span class="s1">'sigmoid'</span>
<span class="n">report</span>     <span class="o">=</span> <span class="kc">True</span>
<span class="n">rep_rate</span>   <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># set the random seed to the current time</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">12345</span> <span class="c1">#int(round(datetime.now().timestamp()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create and train a FeedbackAlignmentMLP</span>
<span class="n">rng_fa</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="n">losses_feedback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numupdates</span><span class="p">,))</span>
<span class="n">accuracy_feedback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>
<span class="n">cosine_sim_feedback</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>

<span class="c1"># select 1000 random images to test the accuracy on</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">rng_fa</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># create a network and train it using feedback alignment</span>
<span class="n">netfeedback</span> <span class="o">=</span> <span class="n">FeedbackAlignmentMLP</span><span class="p">(</span><span class="n">rng_fa</span><span class="p">,</span> <span class="n">numhidden</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">initweight</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
<span class="p">(</span><span class="n">losses_feedback</span><span class="p">[:],</span> <span class="n">accuracy_feedback</span><span class="p">[:],</span> <span class="n">cosine_sim_feedback</span><span class="p">[:],</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">netfeedback</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">rng_fa</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">numepochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> \
                      <span class="n">learning_rate</span><span class="o">=</span><span class="n">learnrate</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'feedback'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> \
                      <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="n">rep_rate</span><span class="p">)</span>

<span class="c1"># Train a network with Backpropagation for comparison</span>

<span class="c1"># set the random seed to the current time</span>
<span class="n">rng_bp2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># select 1000 random images to test the accuracy on</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">rng_bp2</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">losses_backprop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numupdates</span><span class="p">,))</span>
<span class="n">accuracy_backprop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>
<span class="n">cosine_sim_backprop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>

<span class="c1"># create a network and train it using backprop</span>
<span class="n">netbackprop</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">rng_bp2</span><span class="p">,</span> <span class="n">numhidden</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">initweight</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
<span class="p">(</span><span class="n">losses_backprop</span><span class="p">[:],</span> <span class="n">accuracy_backprop</span><span class="p">[:],</span> <span class="n">cosine_sim_backprop</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">netbackprop</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">rng_bp2</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">numepochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> \
                      <span class="n">learning_rate</span><span class="o">=</span><span class="n">learnrate</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'backprop'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> \
                      <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="n">rep_rate</span><span class="p">)</span>

<span class="c1"># plot performance over time</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_feedback</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Feedback Alignment"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_backprop</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Backprop"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Updates"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"MSE"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training starting...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  1  epochs of training. Current loss:  0.58 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  2  epochs of training. Current loss:  0.41 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  3  epochs of training. Current loss:  0.34 .
Training complete.
Training starting...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  1  epochs of training. Current loss:  0.43 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  2  epochs of training. Current loss:  0.32 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  3  epochs of training. Current loss:  0.27 .
Training complete.
</pre></div>
</div>
<img alt="../../../_images/b8a3719d9db65250eae81a934e28ed04b487311be56409676e9467605b18ebb7.png" src="../../../_images/b8a3719d9db65250eae81a934e28ed04b487311be56409676e9467605b18ebb7.png"/>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-5-kolen-pollack">
<h1>Section 5: Kolen-Pollack<a class="headerlink" href="#section-5-kolen-pollack" title="Permalink to this heading">#</a></h1>
<p>INSERT DAN’S VIDEO HERE</p>
<p><span class="math notranslate nohighlight">\(\newcommand{\error}{\boldsymbol \delta}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\losserror}{\mathbf{e}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\backweight}{\mathbf{B}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\h}{\mathbf{h}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\y}{\mathbf{y}}\)</span></p>
<p>As we’ve just seen, to update a feed-forward matrix using back-propagated error, we need to simply follow the weight update equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-23b7b17c-beb3-405f-9ba5-6fd5eb31bd9d">
<span class="eqno">(145)<a class="headerlink" href="#equation-23b7b17c-beb3-405f-9ba5-6fd5eb31bd9d" title="Permalink to this equation">#</a></span>\[\begin{align}
    %\Delta \weight_{ji} &amp;= - \eta \delta_j h^{\prime}_j\stim_i \\
    \Delta \weight_{out} &amp;= - \eta \losserror \h^T \\
    \Delta \weight &amp;= - \eta (\error \h^{\prime})\stim^T,
\end{align}\]</div>
<p>where</p>
<div class="amsmath math notranslate nohighlight" id="equation-0630f943-809a-4723-9db5-7d2991c58bd9">
<span class="eqno">(146)<a class="headerlink" href="#equation-0630f943-809a-4723-9db5-7d2991c58bd9" title="Permalink to this equation">#</a></span>\[\begin{align}
    \error &amp;= \weight_{out}^T \losserror .
\end{align}\]</div>
<p>While directly “transporting” the weights, <span class="math notranslate nohighlight">\(\weight_{out}^T\)</span>, is not biologically plausible, we showed that a random feedback matrix, <span class="math notranslate nohighlight">\(\backweight\)</span>, can align the weights to propagate an approximated error,</p>
<div class="amsmath math notranslate nohighlight" id="equation-4bc17f8e-8938-4b82-9be3-53f64cc748c0">
<span class="eqno">(147)<a class="headerlink" href="#equation-4bc17f8e-8938-4b82-9be3-53f64cc748c0" title="Permalink to this equation">#</a></span>\[\begin{align}
    \error &amp;= \backweight \losserror .
\end{align}\]</div>
<p>However, this approach fails with deeper networks and more complicated datasets. We will now show a biologically plausible approach to modifying <span class="math notranslate nohighlight">\(\backweight\)</span>, such that over learning, <span class="math notranslate nohighlight">\(\backweight\)</span> and <span class="math notranslate nohighlight">\( \weight_{out}^T \)</span> become equal. This approach builds off an observation by Kolen and Pollack (1994) that if two matrices are repeatedly modified by the same values with weight decay,</p>
<div class="amsmath math notranslate nohighlight" id="equation-d1936675-8ea6-475f-9634-7d65480f2e58">
<span class="eqno">(148)<a class="headerlink" href="#equation-d1936675-8ea6-475f-9634-7d65480f2e58" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight(t) &amp;= \mathbf{A}(t) - \lambda \weight(t) \\
    \Delta \backweight(t) &amp;= \mathbf{A}(t) - \lambda \backweight(t) ,
\end{align}\]</div>
<p>then</p>
<div class="amsmath math notranslate nohighlight" id="equation-c813a23d-eeab-4a57-9b94-767e274141ec">
<span class="eqno">(149)<a class="headerlink" href="#equation-c813a23d-eeab-4a57-9b94-767e274141ec" title="Permalink to this equation">#</a></span>\[\begin{align}
    \weight(t+1) - \backweight(t+1) &amp;= \weight(t) + \Delta \weight(t) - \backweight(t) - \Delta \backweight(t) \\
    &amp;= \weight(t) - \backweight(t) - \lambda[\weight(t) - \backweight(t)] \\
    &amp;= (1-\lambda)^{t+1} [\weight(0) - \backweight(0)] .
\end{align}\]</div>
<p>That is, as <span class="math notranslate nohighlight">\(t \rightarrow \infty\)</span>, the difference between the two matrices will converge to 0.</p>
<p>The key observation is that the corresponding elements of <span class="math notranslate nohighlight">\(\weight_{out}^T\)</span> and <span class="math notranslate nohighlight">\( \backweight \)</span> have access to the same locally available information. We can thus pick a plausible learning rule for the backward weights:</p>
<div class="amsmath math notranslate nohighlight" id="equation-acc277f9-4e98-4dc9-92a8-d1b892999345">
<span class="eqno">(150)<a class="headerlink" href="#equation-acc277f9-4e98-4dc9-92a8-d1b892999345" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \backweight &amp;= - \eta \h \losserror^T - \lambda \backweight ,
\end{align}\]</div>
<p>such that the updates to <span class="math notranslate nohighlight">\(\backweight\)</span> correspond to a transpose of the updates to <span class="math notranslate nohighlight">\(\weight_{out}\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-8becde54-c103-4906-ad70-a1f44fba4bfa">
<span class="eqno">(151)<a class="headerlink" href="#equation-8becde54-c103-4906-ad70-a1f44fba4bfa" title="Permalink to this equation">#</a></span>\[\begin{align}
    \Delta \weight_{out} &amp;= - \eta \losserror \h^T - \lambda \weight_{out} \\
    \Delta \weight_{out}^T &amp;= - \eta \h \losserror^T - \lambda \weight_{out}^T.
\end{align}\]</div>
<p>Thus, over many weight updates, <span class="math notranslate nohighlight">\( \backweight \)</span> will converge to <span class="math notranslate nohighlight">\(\weight_{out}^T\)</span> and can be used to propagate errors back to inform updates to <span class="math notranslate nohighlight">\(\weight\)</span>. Note that the same reasoning can be applied to networks of many layers.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-3-fill-in-the-blank">
<h1>Exercise 3: fill-in-the-blank<a class="headerlink" href="#exercise-3-fill-in-the-blank" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">KolenPollackMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through the Kolen-Pollack algorithm</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">kolepoll</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">eta_back</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for Kolen-Polack learning</span>
<span class="sd">        """</span>
        <span class="c1">###################################################################</span>
        <span class="c1">## Fill out the following then remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: calculate updates."</span><span class="p">)</span>
        <span class="c1">###################################################################</span>

        <span class="c1"># do a forward pass</span>
        <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># calculate the updates for the forward weights</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">output</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">,</span> <span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">hidden</span><span class="p">),</span> \
                           <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="n">delta_err</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="n">delta_err</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span>

        <span class="c1"># calculate the updates for the backwards weights and implement them</span>
        <span class="n">delta_V</span> <span class="o">=</span> <span class="n">delta_err</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">V</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">+=</span> <span class="o">...</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to remove solution</span>

<span class="k">class</span> <span class="nc">KolenPollackMLP</span><span class="p">(</span><span class="n">MLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A multilayer perceptron that is capable of learning through the Kolen-Pollack algorithm</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">kolepoll</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">eta_back</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the weight updates for Kolen-Polack learning</span>
<span class="sd">        """</span>

        <span class="c1"># do a forward pass</span>
        <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># calculate the updates for the forward weights</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">output</span>
        <span class="n">delta_W_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">,</span> <span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">hidden</span><span class="p">),</span> \
                           <span class="n">add_bias</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="n">delta_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_deriv</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">add_bias</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="n">delta_W_y</span> <span class="o">=</span> <span class="n">delta_err</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_y</span>

        <span class="c1"># calculate the updates for the backwards weights and implement them</span>
        <span class="n">delta_V</span> <span class="o">=</span> <span class="n">delta_err</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">V</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">+=</span> <span class="n">eta_back</span> <span class="o">*</span> <span class="n">delta_V</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">delta_W_h</span><span class="p">,</span> <span class="n">delta_W_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create and train a KolenPollackMLP</span>
<span class="n">rng_kp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="n">losses_kolepoll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numupdates</span><span class="p">,))</span>
<span class="n">accuracy_kolepoll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>
<span class="n">cosine_sim_kolepoll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">numepochs</span><span class="p">,))</span>
<span class="c1"># select 1000 random images to test the accuracy on</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">rng_kp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># create a network and train it using feedback alignment</span>
<span class="n">netkolepoll</span> <span class="o">=</span> <span class="n">KolenPollackMLP</span><span class="p">(</span><span class="n">rng_kp</span><span class="p">,</span> <span class="n">numhidden</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">initweight</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
<span class="p">(</span><span class="n">losses_kolepoll</span><span class="p">[:],</span> <span class="n">accuracy_kolepoll</span><span class="p">[:],</span> <span class="n">cosine_sim_kolepoll</span><span class="p">[:],</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">netkolepoll</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">rng_kp</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">numepochs</span><span class="p">,</span> <span class="n">test_images</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">],</span> \
                      <span class="n">learning_rate</span><span class="o">=</span><span class="n">learnrate</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">'kolepoll'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> \
                      <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">report_rate</span><span class="o">=</span><span class="n">rep_rate</span><span class="p">)</span>

<span class="c1"># plot performance over time</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_feedback</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Feedback Alignment"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_backprop</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Backprop"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses_kolepoll</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Kolen-Pollack"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Updates"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"MSE"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training starting...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  1  epochs of training. Current loss:  0.56 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  2  epochs of training. Current loss:  0.38 .
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>...completed  3  epochs of training. Current loss:  0.31 .
Training complete.
</pre></div>
</div>
<img alt="../../../_images/e1274f1bac903a0c54e82f8ab4f67f1f93f7635ae87087be92f24a7ec25799ad.png" src="../../../_images/e1274f1bac903a0c54e82f8ab4f67f1f93f7635ae87087be92f24a7ec25799ad.png"/>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-5-assessing-the-bias-of-learning-algorithms">
<h1>Section 5: Assessing the bias of learning algorithms<a class="headerlink" href="#section-5-assessing-the-bias-of-learning-algorithms" title="Permalink to this heading">#</a></h1>
<p>EXPLAIN COSINE SIMILARITY HERE</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the gradient similarity to backprop over training with shaded error regions</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cosine_sim_backprop</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Backprop"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cosine_sim_feedback</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Feedback Alignment"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cosine_sim_kolepoll</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Kolen-Pollack"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Cosine Sim"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Cosine Similarity to Backprop"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/9d6c33a48442a7c371fd7da82e7b82b6e0a43590fd94e094cf82b583958b4aaf.png" src="../../../_images/9d6c33a48442a7c371fd7da82e7b82b6e0a43590fd94e094cf82b583958b4aaf.png"/>
</div>
</div>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/W2D3_Microlearning/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="../chapter_title.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Microlearning</p>
</div>
</a>
<a class="right-next" href="../further_reading.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Suggested further readings</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 7: Microlearning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
     Import dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-weight-perturbation">
   Section 1: Weight Perturbation
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-fill-in-the-blank">
     Exercise 1: fill-in-the-blank
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-node-perturbation">
   Section 2: Node Perturbation
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-assessing-the-variance-of-learning-algorithms">
   Section 3: Assessing the variance of learning algorithms
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-feedback-alignment">
   Section 4: Feedback Alignment
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-fill-in-the-blank">
     Exercise 2: fill-in-the-blank
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-kolen-pollack">
   Section 5: Kolen-Pollack
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-fill-in-the-blank">
   Exercise 3: fill-in-the-blank
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-assessing-the-bias-of-learning-algorithms">
   Section 5: Assessing the bias of learning algorithms
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>