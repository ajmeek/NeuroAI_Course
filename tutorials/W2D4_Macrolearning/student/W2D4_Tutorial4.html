
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 4: Biological meta reinforcement learning — Neuromatch Academy: NeuroAI</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="application/vnd.jupyter.widget-state+json">{"state": {"bb643cf9640942faa495dd60f1f33270": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4d2fcb97d86a4d49818b846029659bbf": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_bb643cf9640942faa495dd60f1f33270", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "If you want to download the slides: https://osf.io/download//\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.IFrame at 0x7f90c8ae8640>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io//?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}], "tabbable": null, "tooltip": null}}, "3ede9ea62b9d4173ac98d2acc67b0c3f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c960b9257d8f4128bf12043eb704c777": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_3ede9ea62b9d4173ac98d2acc67b0c3f", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=HbokMkc3rQ0\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f90c8b57700>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/HbokMkc3rQ0?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}], "tabbable": null, "tooltip": null}}, "b25560591ab2417a8616a877e2daf520": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2d6e51bad86e40e389999fc1efe5b8b9": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "TabModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_c960b9257d8f4128bf12043eb704c777"], "layout": "IPY_MODEL_b25560591ab2417a8616a877e2daf520", "selected_index": 0, "tabbable": null, "titles": ["Youtube"], "tooltip": null}}, "d6ed6f40fa5b402dafb9cfb2ba1620f9": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "16805c7bb96946328958887d0a6fa07d": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_d6ed6f40fa5b402dafb9cfb2ba1620f9", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=Sr56qH1NCjI\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8ff04ddfd0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/Sr56qH1NCjI?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhsaGRoeHRsfIzIlISIiIDguLSgyMjI9MC0tMzc4U1BCNTpLOTYyRWFFS1NWW15bMkVlbWRYbFBZW1cBERISGRYZLxsbL1c9NzdXV1dXV1dXV1dXV1dXV1dXXVdXV1dXV1dXV1dXV1dXV1dXV1dXXVdXV1dXV1dXV1dXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAQUDBAYCB//EAEMQAAEEAAMDCQYEBAUEAgMAAAEAAgMRBBIhBTFRBhMUIkFSkZKhFmFxcoGyMjVj0RUjQrEzNGJzwVOi4fAkwkOCg//EABcBAQEBAQAAAAAAAAAAAAAAAAABAgP/xAAjEQEAAgMAAQMFAQAAAAAAAAAAARECEiExMkFRAxMiUmFC/9oADAMBAAIRAxEAPwD5+iIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hT0STu+oQWSIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiArTY2DZLnzVprZr3cSB2qrWfDYt0YIFEFBf/wLdTWG92/XQnhpoO1eW7GBc9uVnUbmsC70sBVjdsygECqIrf2cPcvDtqPJsgE8SSgtTslhflaGnQHrNreaA0viPHWl6/hMdvGhyVubv0s+FFVR2vITZ31V5ju4KBtWQXQq99E6oPW2MKyJwDfrpXZdEcQq5bGLxjpSC7s99/3WugIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgL02RzQ4A0HaH3ryiAr7ZOxYp4GyPL8xJ3HTQkKhXX8nP8AKM+LvuKsM5MXs3Bxk8w/ZPZuDjJ5h+yuVXjbEPSjhesJBxGh0ugfgqzctb2bg4yeYfsns3Bxk8w/ZbA21CcQ+AZi9gJcQNNBZF8Voe2GF7svlH7pxes/s3Bxk8w/ZPZuDjJ5h+y8YnlThopHRuEltNGmj91mj5QwOw78R1wxjspsakmt2vvTh149m4OMnmH7J7NwcZPMP2W9s3aMeKj5yO6uiCKIKy4vEthifI68rBZreiXKs9m4OMnmH7J7NwcZPMP2VhgMazERNlZeV11Y10Nf8KpdyuwwJGWXQ1+Efuh1m9m4OMnmH7J7NwcZPMP2WzitrxRYdmIfmyPrKK16wsafBeodqxPwxxLc3NgEkVrpvFIdans3Bxk8w/ZPZuDjJ5h+y8RcrMK5wB5xgO5zm6ei3BtiHpRwtkSe8aHS6B+CcOtb2bg4yeYfsns3Bxk8w/ZexyhgMc0lPywuDXdUXZNCtVL+UEDTAHZhzwDmkjQAmteCHWP2bg4yeYfsns3Bxk8w/ZbTNrRHESQdYPjbmcSOrWnb9VoHldhc1fzMvfyafv6Jw6y+zcHGTzD9k9m4OMnmH7Ldxm0Y4YOfNuj0Nt1sHcVJ2hH0fn7OTJnrtr4IXLR9m4OMnmH7J7NwcZPMP2XocooCITUn84kM6o7HZddeKwScrcM1xaRLYJB6o7PqnF6y+zcHGTzD9k9m4OMnmH7L0zlHARDQk/nOLW9UbwcuuvErZdtWMYoYWnc4Re7Tde9E61PZuDjJ5h+yezcHGTzD9lu7T2lHhYxJLdE5QGiySvMe1onYU4kZubAJIrXQ0RSFy1fZuDjJ5h+yezcHGTzD9l6fyiw4w7cR1ixzslACwd9EWtvH7QZh4edfmy2BoNdULlpezcHGTzD9k9m4OMnmH7Jg+UuGmkbGC9rnfhztoG9y2sDtWOeSWNgdmiNOsab608E4dans3Bxk8w/ZPZuDjJ5h+yt3vDWlxNACyfgq7Ze3IcU5zY8wLRdOFWPchcsPs3Bxk8w/ZPZuDjJ5h+yjG8p8NDIYzneWmnZG2Bx3kLLNyhw7IGT25zHuyjKNQRqQQapOL1j9m4OMnmH7J7NwcZPMP2TC8pcPKXhokGRjnm2jc0We1e28oYDh3YgZsjXBrhXWBO7S04nXj2bg4yeYfsns3Bxk8w/ZeJ+VWGjIBEmrWu0aNzgHDt4FbeytsxYvPzQd1KvMK33X9k4da/s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZYzsHDj+qTx/8ACu3blrsH9z/dSeNY9U8+woqHN84TfH/wsbdgX/RJ4hdFGFuwNXDLCcpu5h0iacq3k0T/AES+IWQcl/05fELuYGCrWB+2MM12UzMv08dyz9mf3lqPqRH+Ycd7MN7Wy+IT2dh7ed8f/C7mVrXNsUQdxHaquZq19uY/1K/dj9Yc4OT2H7TL4/8Ahehyewvel8f/AArhwXnLatT8pvHxDn9r7Gw8OGfJG55c0tHWOmpA4Lnl2PKePLg3D3j7mrjlvFnIXX8nP8oz4u+4rkF1/Jz/ACjPi77itw55eFouI2jg5J9qTiI1IwB7Na1Ab29i7decgu6F8a1VZiacTs3Bugxz2PNv5hznH3lllaeycZzcRHTXQda8giLuGt/+7l9CyNu8ovjWq8dHj7jPKFKXZzfLcgwwEdrib+i8cq5i+XD4aNhef8RzG73cB4B3iuqdG072g1xFpkbeahfGtVUtx2wp5Y58Th2s5h8oL4mP3NO8Ddw93YrDGR4xuExPSpI3N5vqhg7b+AXQlgu6F8a1UuAIoixwKUW5fk1tuCPDw4dznc4XEVlNW5xrX6qlwGK5t0w6W7D2/cIy7Nv19y78QMGoY2/lCjo7O4zyhSltyO2sYcRNhY42uxAYwSOaBWewDqOzQf8AcsOzpzHDj8M9pjOQvaw7xxHhl8F2zY2g2GtB4gIYmk2WtJ40lFvnRZJ0fC88/wD+K55rK0WzWnf8lb20sG6baU4hNPYxr2V25Wtql2/NNqsra4UKUiNoNhoB41qlGz5/hXl2z8aTvL4yfMsuMwvP/wAPius8IF8NSu65ptEZW0d+g1Tm26dVum7Td8Eo2cJsqKZ8+LjeCZujvZR3kjK0D37ljZtEMwLYWuyytkJdG6IODrqjroK8V9ADBd0L41qo5lmbNlbm40L8Uo2U+Kgc7ZLmvbTxDZFAUR1tw3blxmWbmOfvqf4H0q6+C+mleeabWXK3LwoUrSRLi8bFk/hbfcD4uB/5W9yoaOmYLQfj/wDsF0xjaatoNbrG74KXMaSCQCRusbkotyvK6MuxOEa05CTQI7CXCisOBw0kW12MllMr8p65+Q6arsHMaSCQCRuJG5MgvNQvjWvihbkuUs7pcbFCyMzCEZnRt/qJ1IP0rxWpgJ3MwuOwz2lhDc7Wu3jUAj7V3AYLuhZ7a1UGJpJJa0k7zSUW+a4nCyRYaJ1kxTdb3BzbFeH/ALouu5Wfl/1YrwxNqsra4VopcwEUQCOBCUtuGwzH9LwQxUlx5GOiIAqt7Wn60Fm2RtSLC4vGGYkBzyBQvc4rsjG01bWmt2m74KDAw6ljb+UKUWo+Ue1G9AzRn/H6reNdvpp9VRYGR+ExWGe+B0LaEby7+vi71B+i7oxNNAtbQ3abvgpewO/EAfiLVS3CwYkYZ+OjkcYpHnqkszXTiSKPYQVixhkOzY3SNDc05LaYG2MtXQA7bXfPia7VzWuI3WAVL2Ndo4Aj3i1KXZyWFxwfHiGnGunvDyUwxFv9O+1QuwsjMIJWkmKU5XjgWmxf/vFfSRCwbmNHwaFPNNrLlbl4Vp4JRs5fbgH8Iw57csf2roNlgdGhr/pt+0LZMbSKLQRwI0UgUqlpRERBERAREQEREHl+5eo8PcQI36/XUry/ctzBj+U36/3Kzk1i0AtqB6jEQ2bG9Y4lh0Y+UGMcImQsOUyk2fcNT/wqCLDRBpLnZiN6vtrRZmxnuuOvxFV/7wVHI4RuLWMzkjrWfBSZdcMV7yfxZyPYCTGNWg9nEfBbUz9VU7KniYC6wxp35jWq2otoQzPLI3hzgL3H04q3bnlFSyFyz4Vt6+CwZLNLew7aCIp+V4/+IfiPuauIXccsv8ofiPuauHC1ALr+Tn+UZ8XfcVyC6/k5/lGfF33FahjLwtEUIqwlERAREQEREBEUIJRQiCURQglFCIJRQiCUUIglFCIJRQiCUUIglFCIJRQiCUUIglFCIJRQiCUUIglFCIJRQiCUUIglFCIIfuW5gv8ACb9f7labty2sG7+UPr/crOTWL29eGR6r0Sq7F7YETsoGYrNW6LTEYfNE9rQC4tOW911p6rjpnva4tLCSDrX7qyxG2ZJGV+EHsHBVBgBN0T8Hn/gpOFmP1KYdpOlIjqJzwSRlaCTfZu+q2+T+y8V0qOV8XNsFg5tCbBFVvUQsymw2viSf7rPPjJCL5yQEbi2Qj+2isY1DM53LpywWvbHgODb1O4LkNm4/ENxDWPmdJFJoC78TDVizwKvC5xOpOh0KzPGo6x8s/wDKfUfc1cOF1HKBxOFdd3Y0JuusFy4WoQX0XkXC12zoyWtJzP1I/wBZXzpfSORH5dF8z/vcqLro0fcb5QnRo+43yhZVzm2sfNhsURF15J4g2Fjicudr6Jr5X2flQX3Ro+43yhOjR9xvlC5iHbz3Z54ySJ5mRR2x7wwNizuORupN5hQrdruVtBjJJcFM6RpY9oeLyOZmoaOAd1m3wO5BY9Gj7jfKE6NH3G+ULm8Ftyd2BE0Yj0MULWyEl+Yuaxzn0erd2Bqdx7aWzJtfERulheInTNfE1jwCGfzSQCW2TplOl66bkF30aPuN8oTo0fcb5QqU7blheW4jm8scoZLI0ECnR52OAJNa00izvXrZG25cQ+KN8bWSU90ze4BlyD4kPafoUFx0aPuN8oTo0fcb5Quaxk00OIx2JJif0eMc20tdpYJAHWoe/TX3KwkxeL53mGmASNjMr3FjspBcQ1oF32G3Xw0QWvRo+43yhOjR9xvlC56Tb+IfG+aJsQZHho8Q5rwS45g4loIIA0bvr6Ky2djZjPJDPzZIjZK0xggU4uGU2TZBbv7b3BBv9Gj7jfKE6NH3G+UKm/jE2bnaj5jpPR8lHP8Aj5vPmuvxf01u7Vki2xI6LCvysubEOidv0A5zUe/qD1QWvRo+43yhOjR9xvlC0NjYueeDnpebAeLY1gNiiRqSdb07NPeqaPbU0WCgcxzXlmFbK8OjfI52l9ZwoMBo9Yk3rpog6jo0fcb5QnRo+43yhVEm1pm4lrXBkcLi0ML43kPzAa84Oq02aDSNa36r1ybM5bPz0jHgTyAU0ggh5B3k9XgOz3oLXo0fcb5QnRo+43yhUX8ZkkjEZY3nWsl6QNQG82C3TWxmcWka7rWvjNoYh+ExAhMcbIcKC68xcS6Mu6pvq0O03ZQdL0aPuN8oTo0fcb5QufdtyYSOZGwvbEWNc0QyOL7a1zjnb1WUHbjd12Ws/wDF583O1HzHSej5KOf8fN5811+L+mt3aguejR9xvlCdGj7jfKFVY4z/AMSwzWSMEZikJaWk3TmZtxAuiKNaa77WnsnH4iOPCmQsdFNK+Mb84NvcHFxNEdWqrhqg6Ho0fcb5QnRo+43yhUEO2p5JBGDGRKyR0bxE8NaW1XWcRzgIO8UtjZE2IGymSWySXmA5lg69QEB1kkn36ILfo0fcb5QnRo+43yhc+7lO5zniJjSHhgwzjfXcS0PvXc3nG8Nzlkw23JpJwGxkxc86IgQyW0NJbn5z8B1H4ewHfogvOjR9xvlCdGj7jfKFVbX2vLBI+NjGve5jThx3nF2V4PuFtPwtaw2x0h0T2NBh5+NrDZBsxl7jodasCj2goL7o0fcb5QnRo+43yhc/sGZ7psPme4gwSk24myJgAfBbc+2JGxYt+VlwTNjbd6ghh19/XPogtejR9xvlCdGj7jfKFU/xaZuKLJQ2OPM4MaY3W8BpIc2T8BJr8FArHsTbU2IfHnj/AJcsecEQyNEZ0IaXu6r7B3it3vQXXRo+43yhOjR9xvlCpsbteeN+McGxmHCtBIo53kszAXdDWtaOi1ZtqzOieJWZgHQlr+alhHWla0tpxs1vsGj2hB0fRo+43yhOjR9xvlCoztfEgvlIh5lmJ5gtp2cgvDA67oEEjSta7Fp4aaeObEyExPlfiRh2EscA22tPePVA/pHb26oOo6NH3G+UJ0aPuN8oVG/a+JDhABDzwxAhLy12QgxGUOAuwd2ln10zxY3FPkeW8xzcUoieHAhzjTczg66b+LQEG636oLXo0fcb5QnRo+43yhUWC27NLK2o7ie97KEEgyBuYBxkPUdZbqBVX20V4we1MbL0Yf8AxgcTEZWnI7qZctgjN1rzDhWu9B0HRo+43yhOjR9xvlC513KOZ4jEbAHmASuHMySgkktyDJ+EW09Y8RosuI2xiqnkYyJjIImSuZI12c20ucywRlIrfR+CC96NH3G+UJ0aPuN8oVPs6Wd+0MQS9vNc1E7JlNgOz1WtA6amtdN1LXxG1HwTYoNsl+JjjZbXPDLha8kMbqdx0HaUF/0aPuN8oWF+z4z/AEN8oVV/GZzGwU1kpkc0ZsPIS9rQDnbFo4DUA2QBxOi9YDa+IxD4GsbEwPi5yQuBJ0flIbqN/v3e9Bvu2VEd8bD8WheP4HhrvmIr+QLRwG18S8YWSUQ83iXFgawODmkNc4GyaN5TpQq9619m7TxMkcTIBCwDCsmPOZ3akuGW8111d5J+qti2OxMP/wBCLyBSdi4c74Yz/wDoFXjbc8zS+BsTWswzJ3CQElxeHENBBFAZTrrv3K7wMxkgikNAvY1xrdqLSxpjYmH/AOjF5Ap/g0H/AEY/IFZIpaVCtGx4Buhj8gXv+Fxf9NnlC30QqHMcsMIyPZ0ha1oOZm4f6wvn6+kct/y6T5mfeF83RRfSORH5dF8z/vcvm6+kciPy6L5n/e5BfrBLhI3yRyOaC+O8h7uYUfRZ1TY3HlmJlc57xDhoBK5rAOuXFw1+AbxGpQbh2TAYua5umZy8USCHE2XAjUGydyyQYGKOIxMbTDdiySc28knUk8Vou27UQkMEpzPaxrWljsxduIIdXx1Q7eaGkOie2USCLmiW3mLc4N3lrLrd9nFBsnZGHJvmxdMGhIvIQWXxogUSvc+zYZOcL2AmQNDzZ1yklvwIJOoWmzbzXhgjhkfK5z282C225KzEm8tat3HXMFr47bb2xzSRslzNwxlET2NblIJBJs3pWo7QNLQWH8Hw/MuhMYdG85nhxLi4itSSbJ0G89i2I8JG2V8rWASPADncQ3cqTZ+13RscJhiJZszGhjuasueLAbkoAUCdTpS337XIjzHDytcHljmuytDaF3mJykcCD/yg2ZtnxSCUPYCJgBJqesBoF5xuzIcQQZWEkAgEOLTR3tJaRYPA6Kmxu33mN8sBpvRTK0OaCQ4Py6+qs5NsMbzgyuzsmbDk0sl1FpHuo38AeCDO7ZsJEjebFSRiJwFgFgsBum78R3cVlbhmCQyBvXLQwn/SCSB4kqv27jZoxHHhg0zvzOAduysFu8Tlb/8AsvOKxskkMc8U0cGGMfOPlc3MdQMoo6Deb7exBtfwjD89z3N9fNm/EcuaqzZby5q7ateW7Fw4l50R9cOzjrOoOO8ht0CbN0NVXYTH4rEuhjtuHf0ds0pyWbcSA0A7h1STeuoWcS4mObCmZwuVzonsb+A01zmyN7QTl1F9vuQWuHw7IoxGxuVgFALSk2BhXNa0xdVrBHQe4AtG4OAPWrsu6Wpj9oysxoYRIzDxxmV7m5KcARZN2co1GgBtZDyha1jnyQSx1CZmh2W3tbV1RNHUaHig2nbHw5kEhZ1rBrM7KS38Li28pIoakXoFngwUcb3yMbldIbdRNE8a3A+9aG09pyswE07IXskawlrXFtjTRxokV21drC/bE7cSGdHkcDBzhjBZbTmIJJutQBQBKCzGz4Q+V4jGaYASHvAChf0WDEbDw0lZ47pgZQc4AtG4OAPWrsu1rS8o4g1rmMfIDEJjRaMrDdfiIs6HQcPgtvF40AYdzXHLLI0AgA2CCdb3DTeNUCXY+He8PdHZFWMxp2X8OZt06uywVP8ACMPz3Pc3182b8Ry5qrNlvLmrtq1q4Tb7ZHR3BKxkr3MZI7LRc29KBJF5TRrsUYHlA2XmSYZYmTA829+WiWguI0JI0BIvggscTgo5XMc9tujNscCQRx1HZoNNxXkbPhDY25BljdnYLOjjev8A3HxVa3lPFkLzG8N5p0zDbTna0WdAbaaINGt/xWbHbSkGAnxDY3QvbG5zBJlJ0FgkAkfRBnw2xsPE8PZHTmghtucQ0He1oJoD3DRZ8Hgo4G5Im5W3eWyQPhe4e4aLQl2/GyUsLHFrXtjfJbaDnVQq8xFkAkDt9xXs7aaMQIXRvaXOc1jiW6loJ/DeYAgGiR/cIM8eycOwRBsTQInF0f8ApLrs+pUDZMAm57J182b8Ry5joXZby5vfVrSi5RZ44ZBhZ/57gIh1Ld1S6/xaCh2r0NtBxhNSRnPIx8Za0m2MLiCb91gjfYQWUuEjfJHI5gL47LD3bFH0WOPZkDGta2MBrZDI0C9HGyT6laOG5QscGukhlhY+IzMe/LRa0Au/CSQaN69iy4LbPOysidh5YjJGZGF+Wi0V3SaPWGiDagwEUZa5jAC1paNToHHMR46rDiNi4aWQyPjtzqLus4AkbiQDRIoa71qnbBZNiGOaXkTMihY0CyXRteRZod42ewL2NutIDWwyGYyGPmurYLRmJJvLWUg3faEGy3ZMAl50M6+YuHWOUOO9wbeUO1OtXqpwmyYIX542UaIHWJDQdSGgmmj3ClqDb4cYmxwSvkkz9QZQWGMhrw4k0NT2Wt/AYxuIibKwEB16O3gg04H3gghBJwcRMtsB57SS9Q7TLqPhotePYuHa1zRGSHFtlz3OPUOZoskkAHUDcrBEGqdnwljmZBldJzhFnV2YOvxAKiTZsLmyNdGCJH536nV2lOveDoN3BbaINKHZUEYblZ+B/OAlxJzEFpcSTbjRrW1EmyYHS866O32HHrGiRucW3lJFDUi9FvIg0WbIgbLzoZ1rLh1jlBd+JwbeUE2bIF6rLDgImc1lZXMsLI9T1WmrH/aPBbKIK6XYeGc1jTHQY3KMr3N6p1LSQes33Gws52fCRI3mxUrQx47C0DKB7tDWi2kQaowEQlbKG09rcoIJGg3Ajcas715n2ZDJzmZn+I4PcQSDmaAGuBGoIAGoW4iCvOxMPla3IRlJIIe4Ot34rcDmN0Ls60s2F2dDDl5tgblbkbROjbzV4raRBqs2dC1sTQwBsJzRiz1TRH9ifFRh9mwxVzbA2oxHvP4RZA9T4rbRBQbR5Pc5TYhEGCIRAODraBdbiM41/C7tHxV1hoRHGyMahjQ0X7hSyogIiICIiCg5b/l0nzM+8L5uvpHLf8uk+Zn3hfN0BfSORH5dF8z/AL3L5uvpHIj8ui+Z/wB7kF+qvE4KXpTpIzTZYhG9wIDmFpcWuAIIP4iKPuVoiDncRyfeBcbzzj5o3ucxrWBoZfWDdxOut3a2X7ADgS+UumMol5wsbVhuQNy7suXSt+t3auUQVI2KQI3Mmc2WPNTwxtEPrM3KBVaNrt0R+xA5sjXSyOMkBgc51E6kku+PW3blbLDipxFE+QgkMaXUPcLQaE2xGuLnCRzX5mOa4AdUsblGh32Cb+K8S7DLyx7sQ90rHOdme1rh1gBQadG0AKr377Kx7B2+cW97HRhhaMwINit1LZ2xtR2GyBmHkmc6z1dGtDRZLnHRq1nhOE1KY5RlFw1hyaZzPNc6+uZdDdC6c7NfxWV2zM20hiC2msiABv8AE+3C6/0tJF/6/cq+TlgOYZOzCTOjLOce401rRmy1Z0cb7Aujw8wkjY8AgPaHAEUdReqyrSxOx4ZpzLMOc6gY1p3Nokkj3mx4Bab+TfViYyd7Y4nueyPK1zQSSRod+W9L3K9RBVybKeXslbiHNmDObc/I0h7bsW2q0J0riVjj2W9suHbZdFCXSGR7re97g5u6tB1ifAAK3UoNLEbNZLI57ySHwmFzewtcbK0n8n87HNlnfJcJgYS0DK11WdN7jQ19yukQa+MwjZoZIXXlkYWEjfRFaLBhtnFknOvldI/muaJLQLAcXA6dutLfRBRDk0xrYwyUtLImxEljXWG7iMwNO1Ovv3KyxGBbIIRZHNPDx76BFHxW0iCuj2O1seHZndUEhkB01JzaHzeiiHYzGx4WPM4jD3V/1WxzNfo5WaIKOPk21sT4edOQxOibUbAQCKskC3EDT+9qyx2CE2HkgJIa9hYSN4sUtpEFQdhNE7pGyFoe8SObzbSbAAIDiLANCx4UscPJ1rJWPErsrJHSBuRtkvDgczqt1ZjX/Ku0QVsGyGsZhGB7iML+H/V1CzX6FeDsRhfnzu/xXyVQ3vZzZH0GqtEQVcuxmmKJll4hhdEGk1nDmBup7N3ZxWhsbB4g4mKSUTBsULo6l5veS3RuTfo3UmuzTeukUIKyfYrXvfIJHNkdK2VrgB1XNZze7tBbfisbdh1T2zPE4kdIZKGpc3KQW7suUAV7grhQgoP4JIyfDmGVzQxkxfKQ0lz5HNcbb7+sdN1BWWz9ndHDWtleWBptrgOs5zsxeTvuydN2q3kQEREBERAUKVCCUREBERAREQEREBERAREQEREBERBQct/y6T5mfeF83X0jlv8Al0nzM+8L5ugL6RyI/Lovmf8Ae5fN19I5Efl0XzP+9yC/REQEREBQ4WCDqFgxOOiiIEjw0nUDea7Tp2LLHIHtDmkFpFgjcQrU+UtWbBwzGCfIxrf5z26DsB0HwCzbdwDsVhZIWloL61ddUCCbog9ijY+6f/fk+5WK19TuSY+FVtTY4nZh4wGCOKRriwg0Wt7AAR62FaKUWGhERBClQpQEUIglERAREQEREBERAUKVCApUIglERAREQEREBERAREQERQglERAREQEREBERAREQEREBERAREQUHLf8ALpPmZ94XzdfSOW/5dJ8zPvC+boC+kciPy6L5n/e5fN19I5Efl0XzP+9yC/REQEREFTtFzmzgxOdnLKc1sWfS9CbIrW1sbJYWwt/mZ20MpyZTXv8AetfaTXOmDYtJAyy7nSy23oNxvW/h9VubNLTBGWDK3KKBN19e34rpl6WI8sGx90/+/J9ysVXbH3T/AO/J9ysVM/UuPhCwvxcbXZS4A/vuvgsyq8RdyAOcIyeuebsDQXrd/FcsppZmm7jcTzUbn1ddnx0WgdpukwmIeBkeyNxBHHKSCrLm7ZlfTr36aH6LW2dCw4ZrS0EOb1hW+9DfFTu0J21ZhsZLG2Mc3OHzOaxpxD2ubq1ziRkJO5u7TeFnwG1pp5WsDIwAH84bJ1ZIYzl+NXqrSbCxyM5t7GuZp1SLGm5IcLHHWSNrcrcoytAob6HuW2lZJtl4xL42x2yORsbjRvrNDi7N+EAZhodTRWszlDJR6jDmawxkZg3+ZIIxZcLLdQc1C1dPwMLpRKYmGQbnlovTdr9T4rGzZOGaHBsEQDxlcAwajgfd7kFbLjMUcTDG10ObLMHAOJYcvNlpI3g9bd2Xeq9YjaEsuFwk0WWMyvjJBs/i/p03hWkGCijy5I2Ny3lpoFZqLvEgX8EfgoXRcy6JhioDIWjLQ3abkFW/bbxPkDGvaXPY2rHWYwuPWOh1aQa3cd60sbygljbE5wpzZg2RgDmaOieRnzDRoIvMLFNJ7KV8Nl4fPn5iLPr1sgvUUfEaKYNmwRgBkMbaOYU0DWst+UkfBBp7Vmm5qBsb2NllkY0kXXfdXupp+iscO95BzhoIJHVdYIB0Puvh2LG7AQmNsZiYY2EFrcoppG6h2LLFC1gIY0NBJcaFWSbJ+JKDIiIgIihAUqEQSiIgIiICIiAiIgIiIChSiAiIgIiICIiAiIgIiICIiAiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP8Avcvm6+kciPy6L5n/AHuQX6IiAoUqEFbjNmvmd13wuaD1Q+AOr62t+FhaxrSQSBWgofQdi08bjHxStADXMe2gC9rTmvsvfotyCTOxrqqxdA36jetTM1FsxVtLY+6f/fk+5WKrtj7p/wDfk+5WKufqMfCFWYj8UjsvUa7rjnCL0H9P/tqzO5aXRC52Yujc4HfzWun1XHLpk3VrbM/wI/lWyVrbM/wI/lV91920iItKKs2097ejlmaxI4mr7IpCLrsuvrSs1r4rGNiMYdf8x2UHhTXPs+6mlBTsnxBkjjec180/PzdZS9smYDs0LRv46rVweLljghtzy/mWNc9zdWuzU4OvQVxIP1V4NrQuALHteCQCQRpYLgfeKB3b1jwu24ZI2SXlY9geMxF6mg2t92a0QVGHxkz5GSSBwBbHm6rqFGe3AcaDezhpuUt2riDE1wfo9ztSzVgA6jXab3and7t+quP4vGZAxuoIa7NYoh+eq4nqHRe/4th8pdzraByn3Gs1eGvwQYppJP8A4z3Et74aLFlu7XXfpqtZm0Ji13WoAtOYtreHWN1A2Bv+F2rPEY6KIAySNaCLBJ7BvPwHHcvDtpQCQxmVgeLsE8BmPgNSszCU08NiZTK7QhrqLcwIt3Nt6p35OPbr8Ncs+KlbJGDQBq2t6291byBYrhqPesp2vhw3MZm1db9bAzEVv3EH4aqYNpRSTPiabLWtfY3EOuqP/u9K/pSvj2hMYw4OzW1pcclZLcAfSz9L3LNHjJSWhzsu7LUZOfrEH/tA3cb3LbhxuHDWhkjMtMoA9j9GfQ9i8t2pC7Lke1wc6rzAV1S+9d4oHd8VNZ+UqVeA/PG+iaDaaW6C5CDXA12rdwE75Gm327KCRzdZHG7Hvrhv8V5ftzDjKRIHAvDCR/SS0ubfbrl042F6btmAvLQ8UIxJn/pLTfb9PVWMaIhrR4/EO/8Ax72lwGXutIc0/F9V7io6XMW5hTyMxacp35Ca0ob/ANt6sunRc3zucZLq/feWvjelb7WN2Ow76YZGOEg0G+wbGvxII14FTWfkqflpMmkklDWykhr6zZK0Md6jdvUNxEury/K50UZALTluzmrQ1/5F6BWeEZGGB0VFrusHA3m00N9uizJrJTBgpS+Jrjd67xW41a2FClbaEREBERAUKVCCUREBERAREQEREBERAREQEREBERBQct/y6T5mfeF83X0jlv8Al0nzM+8L5ugL6RyI/Lovmf8Ae5fN19I5Efl0XzP+9yC/REQFClQgodp4qEz9XExRvZWbOLHVdYG8EG944UrTZgHR48t1lFWKPh2LBtF4a8Hn3ROLf6Yw6xfwPgtnZ73ugjMl5y0ZrFG/h2fBdMvTDEepr7H3T/78n3KxVdsfdP8A78n3KxUz9S4+EKslfUkhGcDeafWoyg6VwP1pWaq5Sx0zi50LHNcAMzbcdAbuwuOfgyWhWtsz/Aj+VbJWtsz/AAI/lV91920iItKLU2hgROGW4tyOLtBvtjmf/a/ottQgrhsgCVkmc2xsbarfzYeB484fBYG7DLY2ME5/lsDGnLva02A6iL99EX6K4RBT4fYAjLSJTmblo5RvaZCDX/8AQ+C8jYLsjGmYF7C458h62f8AGXdbUk636VortQgqtpbF5+JkQlLGNjMZbVgggC6FCxWm8anRaU+xZJZebdYw+aRxNjXnI3MNHfduJoihxOi6NEFZhNkc29r3PzOBJNNq7aG9pJ7OK9bN2X0ctyyFzRCyIgt35LAdfZvNhaxlkZiJcvOG5QcmS2ubzbbIdW+xx3/FYm4vEFjus8U5upYbILTYByUNQP6fda6aSxuyRcm42vDs7jq+xxDhlY34MG74rweTg5ui/OQK3Zcw5t8YBOp/rJvdwAWfDYnEOxADgWs7rmn8OS70bQOb/V7qXmfEYoSOa0HKHZA7L39Wu+DBofippK7MeA2ZM6XnZyWlrmFooWcrHt1okV1739nZuWcbFoOAk0cxzXBzA4EF7njT3FxHvHBYOexDjIHCxf4SwmqkAbXVA/DZ3njosb8TNJbM7yXNLi3m6DSJGgZTXWABPaVftym7fGzHdH5rnnZs+bNrW+8tXeXsrN9Vgg2DzZiyzEZDZIZTj1y/LYP4TmIIN6bqOqHnRM3M+QtY9zQ7IOsC1rhdDddixW7itnZM0jmu5wuJBHWLaB07NGn6EacSszjUWsZNyFhaxrXHMQKJAq/p2L2q+N+J6W8OazmcjaOY8X3Wm+sti+CwyukjfNTpLdICOroBlGt5T2itx/5WJmlmaWylUoxE7gzNn60erQwijlNk2Ph2iuC2dnvmMbQ4DMKDg6wAKFZTRzfXt4blIytLWClUrsXMM4Ln/jaMwj3AuogAt3183FOk4i2VddhLD1uuR1gGmurXd338JvBsuUVTzsrhqXl2duZpi0b/ADANDWumvbx0WCBkkRcRnGZ3XfzYLgM7heg10y77q02Nl6i0JppWwMezM916gsouBsCx2akH6Far8RiQ3WxTshcG78o/ENHaOPu7FdltcqVTGaVpOYllm3OZHZJEbewi6u9a7K0UYN0xHOZndd0djKKOZjQ527sPDTRTZNl0oVLBJKxkIBkNaObk1uwK/DRH1HGyrpaibWJtKIiqiIiAiLxLeV2X8VGvj2IPaLT2XLK+BpnaGyiw8N3WDVi+O9biAiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP+9y+br6RyI/Lovmf97kF+oUqEEoiIKvacT3SAlk0keXRsUmQh17zq29K7dFuYJr2wsEht4aM2t+vas6LU5XFJXbV+x90/8AvyfcrFV2x90/+/J9ysVc/UmPhCr3vPOPDnStp1ANjsVQ7aKsHCwRxWA4NhN9bzu/dcsomfCzDJNK1jS5xoDeVrbJla6BoBstFH3LPi8OJYyx1gHtCxbPwDYGkAlxO8lSb2/idttoiLbQtXF4vm3wNy3zsmS73dRz79/4a+q2lr4zCNmDQS5pa7MxzTRaaIsfQkfVBpHbkbc2drxlMl5Wl1NjdlLjW5TJtpglaxrXuaS8F4aSOo0lwbQ6xsVQ99XSxv2AwkDnJAzI9rwHdZ/OODn2ffrurfpSyS7ChfmsvyHP1A6mgvBDyO3Wygj+OML42sY52aQxv0/AQ3Pr9K+iz4TasUwdzZcS1ofVVbTeUj40Vji2LE2qc/NznOZrGpy5CKAqi3SqWXZ+zI8MC2PNVBoBO4DcBX9zZ96CItpNLInOa5vOAdmgvQa/EqH7UYG5heXMGlxFDWxY47t29P4VH1es+mgAajc020buz17bUnZcZLi63ZiLv3XQ9+/edVj8mesrsdGGklwFNzFp/EB7xvCxv2kxtWHjQuPVOgBok+5Z+jjJlt26s19bxWn/AAlt1mcGFpDgDWazZvsr4UrNk2zHaUQLhZ0vWt9GiBxNmljxG0srSQwkhrjlIINggeGu9e/4ZHbvxU69AdxJux279V6OAaQcznuJBaSTrqQT8Nw3KfkdeItotoZgS7W8rD1adl14a/2U54IZCA1rHuIGjd+a69QV6Oz2XYc9pJN5XVduzEH6k7lOJwEcrszrvIWWDWh7fiOw+9X8qOvDdpROIAJ1qjWmosD6j+4UR7TY7Lvt1Cw05bLc1X8F7Gzow8OFjQaDdoKHv3f2Ws3ZZbI2nVE0g1Zs0zJqOPvv6dqn5HXpu1wY2uyOzHIS2jueasce3/0rahxbXuc1ubq2DppY3j4rwdnsygdYU1rQQdRlNtPxteo8G1shktxdRGvv1P8Abt3disbHWjDt+Mx53skaeucoaSQ2N1Odp2bvqa1W3iNoxRvYxxNuaXggWA1tZnE9gFha79hxEEZ5Wg5xo/8ApkNvZ8CRfEdhC2pMBG5wcRdRuirsyuqx/wBoWmmsNswPA0e52YUzIS7cXB1cKBN+6t+iYPbMckLJHW0u5uxRNGWg0eJCM2LG1rQ18gc11tcCARoW1uqqJ3i+3fqobsKIZAHSBrMnVzaO5s2wn36fVB6G24S3N16NZDkNPskDKdx3H6a7l7ftRnNwyN1ZI/LZ0y6OJJ+GWqWP+BxZMmaTK2ubBcCI63BoIrtrUHTRbB2dGY44zZaw2LO/Qg34lBr/AMdgofjBcW5WlhDjmBLSAewhrvCt6zwbSjkldG3PmbWa2EAEtDqN7jRG/wCG9a42HHlLc8hJDW5iQTlbeVlEUQMx3g77WSDZEUckbwXnm25WAuuhly79507CavWrQYsVtPDODhI0uazObMZIJZo8N4kbq+O+is7Nox81K8BwENh7S2iKaHbvgQVjdsSIl1l+V2am5uq0vNvI95PG6s1VrPLs6N7Z2uusR/ia/wCkM04aBBii2o3JhzK10b56AZV06rI9DqsGH5S4aV0TWF7jKA5tRuNAktBPAWCtjG7KZOyJr3SZonBzXtdlddVdjiCtNvJfDAQj+YWwkFjS/SwS4H3ansq+1Bhw/K3D82wykhxGZxYx7mtbnLASa0FjtW7Fygw78QMO0vLy9zAchylzBbgHbjSwDkthhG6Pr5Xx82et2ZzJ45iVrYbk29mPbiC9ojZJJI1rc2peKqiSBxJG/gEG0zb4OPdhebOQW0SX+KRrQ8sr5Tx7Fov5WPjGI53DU6FjXZWyh2r3ZWseaprtx7dFvDkvhQ8SBrhKJDJzod1ySSTZ4a7l4g5KYZkckWaZ0co6zHSEi7BzfNYGqDf2diZ35xPBzTmkUQ/M1wI3g6HT3hby0dnbMZh85a6R75CC98jy5xrQangt5BClQiCUREBERBQct/y6T5mfeF83X0jlv+XSfMz7wvm6AvpHIj8ui+Z/3uXzdfSORH5dF8z/AL3IL9EUIJREQFixM7Y43yO/CxpcfgNVlXl7A4FrgCCKIPagoeTO1WTOmYGlri90ovg4/wBwp5Xwjoxmc+TLF/8AjbKI2vLqa3M7TQE3vVlgNlQYYuMTMpdvNk/TXsW1LE17cr2hzTvDhYXT6k4zlePhnCJiOuK2psiaPC4VsmIlkxDssLLnysY5xvP2FxA07bXZ4eMsjY1zi9zWgFx3uIGp+q9Pia6szQcptti6PEcCva5tIUqFKAiKEEqFKhBKIiCEUqEBSiIIREQSoUogKERBKIiCEREBSoRAUqFKAihEBSoUoIUqFKCFKhSghSoUoIUqEQFKhSghSoUoCIiAiIgoOW/5dJ8zPvC+br6Ry3/LpPmZ94XzdAX0jkR+XRfM/wC9y+br6RyI/Lovmf8Ae5BfqFKICIiAiIghERAUoiCFKIgIiIChSoQSoUqEEqFKhAUqFKCEREEqFKIIREQSiIghERARFKCFKhSghERAUqFKCFKhSghSoUoIUqFKCEUoghSiIIREQSiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP8Avcvm6+kciPy6L5n/AHuQX6hSoQSiIgIiIIREQFKhSghSoUoC4/GbSnIxEjJMQ3+fzcJDW80KIjBcSCaz3a69VUOwImhrS+VzGOzhjn9XNeayBv1117UB+2ailkEd5ZxAwZvxkuawndp1ieP4V52TicRLiMUXtYIWvyMp5JBaBdChvs2b3ivesjdhRB4dmkLWymVsZf1A8kkmviSdfotrB4FsJkLC6pHF5aTYBJJcRwslBWjlG3PGxzKuSRkhzaRhhe0OPzFhofHgtc7WxMs8RhiAaIHSvY+TKKc6oy45SbytcarS9+i35OT2Gc2VrmEiWXnX67zd18u/T3nitl+zo3GZ3WBmYGOIO4AECuG8oKt3KN7ojLDAHNZA2eXPJlyhzcwY3Q26hfYN3Fe8JjsTLjWtyMbE2Brnt50mjJqP6dSMrhVjQ37lmxHJ6B+YZpGse1rXsa+muDRTb+mnvW6zAtbO6ZpcHPADm31TW41xQVu1ttSRjEczE14w7Lkc5+WiRYDRRzECjrW8LH/F5ooz/LErMPkjmkdJlc55Dc2VtEEjMN5Gui3MVsKKV73OdIBI5rnsD6a5zaokfAD3aL27YsRkLyZMpeJDHm6heNziPoDW6xdIPW0dpjDvYHt6jmPcXA6gsAIAHaTZ8FX+0wEed0RGWLPKM34HF2Rke7UlwdwqverTGbPindE6QWYn52cL7L48fosA2HAIpYwHASyc64h3WzWHAg9lECkHnZG1jiHyMc1gLA05o5M7TmvS6GorX4haGJ2zPIITHGI4ZpgxkvOdctacznZaoNLWu7b1V3hMKIgRne8uNlz3WT2fAD3ABaWH2BDG5huRzY8wjY59tYHCiAPgSNUGPB7afJJBmgDYsTm5p3OW6g0uBc2qAIHYTvC1tr4yUYstPVw2Hi56Utlc1xBOl0Nayu6t0b14KxwOx4oHNcC9xYzm487rDG6dVvgNd+m9ZZtmRSc/nBPPsDH6/wBIBAA4bz4oK2Xb0sQdz2HDXcyZo2iWyaLW5HaDK4lzd1jetnaOOniwM0zomNla0lrRISPdrl3+6vqvQ2HEbL3SSOJZbnus0x2ZreAF6nj2rbxuEbPE6J95XVuNHQ2CD8Qgoum4xkzGZGPdDhs0wMxDSSaaS7LZdTHaVWp1XvE8qAGsMbGZjC2ZzZJclBwtrBQNu0PDsVn/AAqMtmBLyZmBj3F3WIALRr2bz9SvL9jRl+Zr5WW1rXNY8tDg38N1qPoQgnF7SyRwlkeeScgRsJy6luY5jrQABJ0K18Htpz5WQuiDZOcex9PsAMaHFwNCx1mjcN54LdxuAbNkJc9jozmY9hogkUfdqCVrfwKICPI6VjmZuu1/WdnIL8xN3ZAN70GjidrYiV0DcPGynTyN60hGZsVg/wBJoEj+w7bGRnKQOnDGNY5hl5onnOvd0XBlfhB7b963ItixMEGQvaYLDCHakOILg7jZAtItjRsJyvlDbcQznDlaX3mIA37zvuuxBGydoyYiLnnxNjiIzMPOZi4WaJFCrFHed6rcFtqfo4LYxK5sXSJTJJkDWvJcxgoGzlHhSvBgWDD9HFiMR82KOobWXfxpak2wYXk6yNa5rWPY19NeG6NDvpppVjeg1cRyhcGSSxQB0ULGulLpMpGZoflaKNkNI3kDWl6xO3JWumc3DtdDDI1jnmWnG8t5W1qQXcexbUuxIXSOcS/K9we+MOpjnNoAkfQabjW5a2A2AG9aZ73OMrpnMDzzeYuJaa7aGX3WLpBjx3SDimsjndzhe1wjaBzbIgacX2LJd1gNd+7cSr5YmYcNkfJbiXgAgnQZbquG8rMghSoUoIUqFKCERSghSoUoIUqEQSiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP8Avcvm67Hk24jBsone7t/1FEmadsoXPZzxPimc8T4q0mzokXO5zxPimc8T4pRs6JFzuc8T4pnPE+KUbOhRc9nPE+KZzxPilGzoVK53OeJ8UznifFKNnQqVzuc8T4pnPE+KUbOiULns54nxTOeJ8Uo2dEi53OeJ8UznifFKNnRIudznifFM54nxSjZ0Shc9nPE+KZzxPilGzokXO5zxPimc8T4pRs6JQueznifFM54nxSjZ0Shc9nPE+KZzxPilGzoVK53OeJ8UznifFKNnRIudznifFM54nxSjZ0Shc9nPE+KZzxPilGzoUXPZzxPimc8T4pRs6FSudznifFM54nxSjZ0Klc7nPE+KZzxPilGzokXO5zxPimc8T4pRs6FSudznifFM54nxSjZ0SLnc54nxTOeJ8Uo2dEi53OeJ8UznifFKNnQoueznifFM54nxSjZ0Klc7nPE+KZzxPilGzoUXPZzxPimc8T4pRs6JFzuc8T4pnPE+KUbOiRc7nPE+KZzxPilGz3y3/LpPmZ94XzddhylcTg32Tvb2/wCoLj1FibF1/Jv/ACjPi77iuQXX8m/8oz4u+4qwStERFWBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQERa0uMAeWCi4Ns9YADd/wAG0Gpyk/yj/i37guQXW8oH5sETRF5DR3jrDRckpLcCv9kbahgw7Y358wJum2NSSqBFFp1ftLh/1PKntLh/1PKuURW0p1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntJh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKvMnKDCuFOa5w97Af/dw8FyyJZS+2ttiGbDujjDgSW1baGhBVCiKFCKs6XJ3vQJ0uTvegRVmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEGFERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREH//Z\n"}}], "tabbable": null, "tooltip": null}}, "31213955ce3243b589a0a5d90c700274": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d4d6df094dba40e1a55c51d7c4fad677": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "TabModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_16805c7bb96946328958887d0a6fa07d"], "layout": "IPY_MODEL_31213955ce3243b589a0a5d90c700274", "selected_index": 0, "tabbable": null, "titles": ["Youtube"], "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4';</script>
<link href="../../../_static/ai-logo.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D4_Tutorial5.html" rel="next" title="Tutorial 5: Replay"/>
<link href="W2D4_Tutorial3.html" rel="prev" title="Tutorial 3: Meta-learning"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/ComputationalNeuroscience.html">
                        Prerequisites and preparatory materials for NMA Computational Neuroscience
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
                        Neuro Video Series (W0D0)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
                        Python Workshop 1 (W0D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
                        Python Workshop 2 (W0D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
                        Linear Algebra (W0D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D4_Calculus/chapter_title.html">
                        Calculus (W0D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D5_Statistics/chapter_title.html">
                        Statistics (W0D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_CognitiveStructures/chapter_title.html">
                        Cognitive Structures (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/keynote.html">
                        Project Day keynote (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/continuing_your_project_after_the_course.html">
                        Continuing your project after the course
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/past_projects_overview.html">
                        Past projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/ComputationalNeuroscience.html">
                        Prerequisites and preparatory materials for NMA Computational Neuroscience
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
                        Neuro Video Series (W0D0)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
                        Python Workshop 1 (W0D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
                        Python Workshop 2 (W0D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
                        Linear Algebra (W0D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D4_Calculus/chapter_title.html">
                        Calculus (W0D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D5_Statistics/chapter_title.html">
                        Statistics (W0D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_CognitiveStructures/chapter_title.html">
                        Cognitive Structures (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/keynote.html">
                        Project Day keynote (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/continuing_your_project_after_the_course.html">
                        Continuing your project after the course
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/past_projects_overview.html">
                        Past projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">Prerequisites and preparatory materials for NMA Computational Neuroscience</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pre-reqs Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">Neuro Video Series (W0D0)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.html">Human Psychophysics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.html">Behavioral Readout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.html">Live in Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.html">Brain Signals: Spiking Activity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.html">Brain Signals: LFP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.html">Brain Signals: EEG &amp; MEG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.html">Brain Signals: fMRI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.html">Brain Signals: Calcium Imaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.html">Stimulus Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.html">Neurotransmitters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.html">Neurons to Consciousness</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">Python Workshop 1 (W0D1)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">Tutorial: LIF Neuron Part I</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">Python Workshop 2 (W0D2)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">Tutorial 1: LIF Neuron Part II</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">Linear Algebra (W0D3)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">Tutorial 1: Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">Tutorial 2: Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">Bonus Tutorial: Discrete Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">Calculus (W0D4)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">Tutorial 1: Differentiation and Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">Tutorial 2: Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">Tutorial 3: Numerical Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">Statistics (W0D5)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">Tutorial 1: Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">Tutorial 2: Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D1_Generalization/chapter_title.html">Generalization (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Intro.html">W1D1 Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial1.html">Tutorial 1: Generalization in AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial2.html">Tutorial 2: Generalization in Neuroscience</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial3.html">Tutorial 3: Generalization in Cognitive Science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_Macrocircuits/chapter_title.html">Macrocircuits (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Tutorial1.html">Tutorial 1: Depth vs Width</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_CognitiveStructures/chapter_title.html">Cognitive Structures (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_Tutorial1.html">Tutorial 1: Cognitive Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_CognitiveStructures/student/W2D2_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D3_Microlearning/chapter_title.html">Microlearning (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_Tutorial1.html">Tutorial 7: Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Macrolearning (W2D4)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial1.html">Tutorial 1: The problem of changing data distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial2.html">Tutorial 2: Continual Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial3.html">Tutorial 3: Meta-learning</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 4: Biological meta reinforcement learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial5.html">Tutorial 5: Replay</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mysteries</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D5_Mysteries/chapter_title.html">Mysteries (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_Tutorial1.html">Tutorial 1: Consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/student/W2D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/keynote.html">Project Day keynote (W2D2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Project materials</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Example_project.html">Project Template</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/continuing_your_project_after_the_course.html">Continuing your project after the course</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/past_projects_overview.html">Past projects</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/past-projects/example_past_project.html">Example Past Project</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Professional Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/impact_talks.html">Impact Talks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_features.html">Career Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_panels.html">Career Panels</a></li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/NeuroAI_Course" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/NeuroAI_Course/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 4: Biological meta reinforcement learning</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Biological meta reinforcement learning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
     Data retrieval
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu">
     Set device (GPU or CPU).
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-harlow-experiment">
   Section 1: Harlow Experiment
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-harlow-experiment">
     Video 1: Harlow Experiment
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-meta-structure">
     Coding Exercise 1: Meta-Structure
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-advantage-actor-critic-a2c-agent">
   Section 2: Advantage Actor Critic (A2C) Agent
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-baldwin-effect">
   Section 3: Baldwin Effect
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-baldwin-effect">
     Video 2: Baldwin Effect
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-agent-s-rate-to-learn">
     Coding Exercise 2: Agent’s Rate to Learn
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-evolutionary-framework">
   Section 4: Evolutionary Framework
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-genetic-algorithm">
     Coding Exercise 3: Genetic Algorithm
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-evolutionary-theories-in-code">
     Think 1: Evolutionary Theories in Code
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-newbie-experienced-bird">
   Section 5: Newbie &amp; Experienced Bird
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id7">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<p><a href="https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/n?euromatch/NeuroAI_Course/blob/main/tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-4-biological-meta-reinforcement-learning">
<h1>Tutorial 4: Biological meta reinforcement learning<a class="headerlink" href="#tutorial-4-biological-meta-reinforcement-learning" title="Permalink to this heading">#</a></h1>
<p><strong>Week 2, Day 4: Macro-Learning</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Hlib Solodzhuk, Ximeng Mao, Grace Lindsay</p>
<p><strong>Content reviewers:</strong> Hlib Solodzhuk, Ximeng Mao, Grace Lindsay</p>
<p><strong>Production editors:</strong> Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk</p>
<br/></section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: 50 minutes</em></p>
<p>In this tutorial, you will observe how meta reinforcement learning may be occurring in the brain.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "4d2fcb97d86a4d49818b846029659bbf"}</script></div>
</div>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-and-import-feedback-gadget">
<h2>Install and import feedback gadget<a class="headerlink" href="#install-and-import-feedback-gadget" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install and import feedback gadget</span>

<span class="c1"># !pip3 install vibecheck datatops --quiet</span>

<span class="c1"># from vibecheck import DatatopsContentReviewContainer</span>
<span class="c1"># def content_review(notebook_section: str):</span>
<span class="c1">#     return DatatopsContentReviewContainer(</span>
<span class="c1">#         "",  # No text prompt - leave this as is</span>
<span class="c1">#         notebook_section,</span>
<span class="c1">#         {</span>
<span class="c1">#             "url": "https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab",</span>
<span class="c1">#             "name": "sciencematch_sm", # change the name of the course : neuromatch_dl, climatematch_ct, etc</span>
<span class="c1">#             "user_key": "y1x3mpx5",</span>
<span class="c1">#         },</span>
<span class="c1">#     ).render()</span>

<span class="c1"># feedback_prefix = "W2D4_T4"</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>

<span class="c1">#working with data</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1">#plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="c1">#interactive display</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>

<span class="c1">#modeling</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">plot_cumulative_rewards</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plot the cumulative rewards over time.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - rewards (list): list containing the cumulative rewards at each time step.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">)),</span> <span class="n">rewards</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Time Step'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Cumulative Reward'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Cumulative Reward Over Time'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_boxplot_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots a boxplot of the given scores.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    scores (list): list of scores.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">''</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Score'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Distribution of Scores'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_two_boxplot_scores</span><span class="p">(</span><span class="n">newbie_scores</span><span class="p">,</span> <span class="n">experienced_scores</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots two boxplots of the given scores.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    scores (list): list of scores.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">([</span><span class="n">newbie_scores</span><span class="p">,</span> <span class="n">experienced_scores</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'Newbie'</span><span class="p">,</span> <span class="s1">'Experienced'</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Agent'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Score'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Distribution of Scores'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>

<span class="k">def</span> <span class="nf">run_dummy_agent</span><span class="p">(</span><span class="n">env</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Implement dummy agent strategy: chooses the last rewarded action.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): An environment.</span>
<span class="sd">    """</span>
    <span class="n">action</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cumulative_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span><span class="n">cumulative_reward</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">)):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">cumulative_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cumulative_reward</span><span class="p">)</span>

        <span class="c1">#dummy agent</span>
        <span class="k">if</span> <span class="n">reward</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">action</span>
    <span class="k">return</span> <span class="n">rewards</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="data-retrieval">
<h2>Data retrieval<a class="headerlink" href="#data-retrieval" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Data retrieval</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">hashlib</span>

<span class="c1"># Variables for file and download URL</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s2">"Evolution.pt"</span> <span class="c1"># The name of the file to be downloaded</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/wmvh4/download"</span> <span class="c1"># URL from where the file will be downloaded</span>
<span class="n">expected_md5</span> <span class="o">=</span> <span class="s2">"d0a74898e56549f7c5206e4c8f373ced"</span> <span class="c1"># MD5 hash for verifying file integrity</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Attempt to download the file</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="c1"># Make a GET request to the specified URL</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">:</span>
        <span class="c1"># Handle connection errors during the download</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Failed to download data !!!"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># No connection errors, proceed to check the response</span>
        <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="n">requests</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
            <span class="c1"># Check if the HTTP response status code indicates a successful download</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Failed to download data !!!"</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_md5</span><span class="p">:</span>
            <span class="c1"># Verify the integrity of the downloaded file using MD5 checksum</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Data download appears corrupted !!!"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If download is successful and data is not corrupted, save the file</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fid</span><span class="p">:</span>
                <span class="n">fid</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span> <span class="c1"># Write the downloaded content to a file</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="set-device-gpu-or-cpu">
<h2>Set device (GPU or CPU).<a class="headerlink" href="#set-device-gpu-or-cpu" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU).</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used</span>
<span class="sd">    in PyTorch operations to specify the device.</span>
<span class="sd">    """</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is not enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"If you want to enable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"`Hardware accelerator.` and select `GPU` from the dropdown menu"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"If you want to disable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"`Hardware accelerator.` and select `None` from the dropdown menu"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">device</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU is not enabled in this notebook. 
If you want to enable it, in the menu under `Runtime` -&gt; 
`Hardware accelerator.` and select `GPU` from the dropdown menu
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-harlow-experiment">
<h1>Section 1: Harlow Experiment<a class="headerlink" href="#section-1-harlow-experiment" title="Permalink to this heading">#</a></h1>
<p>In this section we will introduce the meta reinforcement learning environment which replicates the 1940s Harlow experiment and will observe its meta-nature.</p>
<section id="video-1-harlow-experiment">
<h2>Video 1: Harlow Experiment<a class="headerlink" href="#video-1-harlow-experiment" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2d6e51bad86e40e389999fc1efe5b8b9"}</script></div>
</div>
</section>
<section id="submit-your-feedback">
<h2>Submit your feedback<a class="headerlink" href="#submit-your-feedback" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_harlow_experiment")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="coding-exercise-1-meta-structure">
<h2>Coding Exercise 1: Meta-Structure<a class="headerlink" href="#coding-exercise-1-meta-structure" title="Permalink to this heading">#</a></h2>
<p>Any RL system consists of the agent who tries to succeed in the accomplishment of the task by observing the state of the enviornment, executing an action, and receiving the outcome (reward). If aspects of the environment change with time, previously learnt hard-coded strategies might not work anymore. Still, as in the previous tutorial, these changes share similar features across the tasks. The Harlow experiment illustrates that though there is no direct instruction on how to obtain the maximum possible reward, and the environment’s state changes with each new pair of the objects, the agent is still able to capture the meta-sructure of the experiment - the reward is associated with the object, not its relative placement.</p>
<p>In the coding exercies you should complete dynamics of the Harlow experiment environment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HarlowExperimentEnv</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">punishment</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initialize Harlow Experiment environment."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">punishment</span> <span class="o">=</span> <span class="n">punishment</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span><span class="p">])</span>

    <span class="c1">###################################################################</span>
    <span class="c1">## Fill out the following then remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: complete state update and choose appropriate feedback based on the condition."</span><span class="p">)</span>
    <span class="c1">###################################################################</span>
    <span class="k">def</span> <span class="nf">update_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Update state by selecting rewarded hand for random."""</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Reset environment by updating new rewarded and punished digits as well as create current state of the world (tuple of observations)."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Evaluate agent's perfromance, return reward and next observation."""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">:</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="o">...</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="n">feedback</span>
</pre></div>
</div>
</div>

</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D4_Macrolearning/solutions/W2D4_Tutorial4_Solution_25499fd3.py"><em>Click for solution</em></a></p>
<p>Let’s evaluate a simple strategy for this task: an agent always chooses the side that was previously rewarded (meaning it stays with the same hand if it received reward and changes its action if it was punished). Do you think this agent uses information about the current state? How much cumulative reward do you expect this “dummy” agent to get?</p>
<p>Make sure you execute this cell to observe the plot!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to observe the plot!</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">run_dummy_agent</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>

<span class="n">plot_cumulative_rewards</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>

</div>
<section id="id1">
<h3>Submit your feedback<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_meta_environment")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-2-advantage-actor-critic-a2c-agent">
<h1>Section 2: Advantage Actor Critic (A2C) Agent<a class="headerlink" href="#section-2-advantage-actor-critic-a2c-agent" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 10 minutes</em></p>
<p>Let’s see if we can do better than the dummy agent’s strategy. After defining the environment and observing the behaviour of the agent implementing such a simple policy, it is the right time to remind ourselves about more sophisticated agent architectures that are capable of learning the environment’s dynamics. For this we will use the Advantage Actor Critic (A2C).</p>
<p>The main idea behind A2C, as it name suggests, is that it consists of two networks, named actor and critic. Actor network learns the policy (mapping states to actions), while the critic network learns the value function (estimating the expected future rewards from a given state). In the most cases, they share the same “body” and only the last linear projection to the output is specific to each of the networks. The “advantage” term comes from the training step: instead of raw rewards, in A2C we calculate the advantage function, which estimates how much better or worse an action is compared to the average action value for a given state.</p>
<p>The architecture of the agent is the following: it receives the previous state, previous reward &amp; chosen action as input, which is linearly projected to the <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> (this creates an embedding); then, its core consists of recurrent <code class="docutils literal notranslate"><span class="pre">LSTM</span></code> cells, their number is exactly <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>. Right after this RNN layer there are two distinct linear projections: one for the actor (output dimension coincides with the number of actions; for the Harlow experiment it is 2) and the latter for critic (outputs one value).</p>
<p>We don’t propose an exercise to code for the agent, simply go through the cell below to understand the implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ActorCritic</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_inputs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num_actions</span> <span class="o">=</span> <span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initialize Actor-Critic agent."""</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ActorCritic</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1">#num_actions is 2 because left/right hand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">num_actions</span>

        <span class="c1">#num_inputs is 5 because one-hot encoding of action (2) + reward (1) + previous state (2)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_inputs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="c1">#hyperparameters involved in training (important to keep assigned to the agent)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.00075</span> <span class="c1">#learning rate for optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.91</span> <span class="c1">#gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="c1">#beta_v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#beta_e</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Implement forward pass through agent."""</span>
        <span class="c1">#at first, input goes through embedding</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1">#then through RNNs (observe that we pass hidden states too!)</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">hidden_states</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1">#critic -&gt; value</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_linear</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="c1">#actor -&gt; policy</span>
        <span class="n">policy_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_linear</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">policy_logits</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_init_hidden_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initialize hidden state with 0."""</span>
        <span class="c1">#initialize hidden state in RNNs</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>In the cell below we define the training procedure for the A2C agent as well as its evaluation afterwards. The function <code class="docutils literal notranslate"><span class="pre">train_evaluate_agent</span></code> performs <code class="docutils literal notranslate"><span class="pre">num_gradient_steps</span></code> gradient steps (by default - 25) and for each of the steps, the agent is exposed to the enviornment’s states sequence of length <code class="docutils literal notranslate"><span class="pre">num_trials</span></code>  (by default - 6, as in classical Harlow experiment). Each gradient step, it performs backpropagation of the loss for these 6 trials by calculating advantage and weighting actor and critic losses with the entropy of the policy (for more information, please refer to <a class="reference external" href="https://www.biorxiv.org/content/10.1101/295964v1.full.pdf">this resource</a>, p.14). After the training is complete, the evaluation phase starts, gathering rewards for <code class="docutils literal notranslate"><span class="pre">num_evaluation_trials</span></code> trials (by default - 20). Note: the evaluation is completed on the same task.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_gradient_steps</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="n">num_trials</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num_evaluation_trials</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Training and evaluation for agent in Harlow experiment environment.</span>
<span class="sd">    Evaluation goes only after all gradient steps.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - agent (ActorCritic): particular instance of Actor Critic agent to train.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - num_gradient_steps (int, default = 25): number of gradient steps to perform.</span>
<span class="sd">    - num_trials (int, default = 6): number of times the agent is exposed to the environment per gradient step to be trained .</span>
<span class="sd">    - num_evaluation_trials (int, default = 20): number of times the agent is exposed to the environment to evaluate it (no training happend during this phase).</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - score (int): cumulative reward over all trials of evaluation.</span>
<span class="sd">    """</span>
    <span class="c1">#training</span>

    <span class="c1">#reset environment</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1">#define optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_func</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">agent</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gradient_steps</span><span class="p">):</span>

      <span class="c1">#for storing variables for training</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">entropy_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>

      <span class="c1">#start conditions</span>
      <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">get_init_hidden_states</span><span class="p">()</span>
      <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
      <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

      <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">):</span>

          <span class="c1">#state + reward + one-hot encoding of action</span>
          <span class="n">full_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">preceding_reward</span><span class="p">,</span> <span class="n">preceding_action</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
          <span class="n">value</span><span class="p">,</span> <span class="n">policy_logits</span><span class="p">,</span> <span class="n">step_hidden_states</span> <span class="o">=</span> <span class="n">agent</span><span class="p">(</span><span class="n">full_state</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
          <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">step_hidden_states</span>
          <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

          <span class="c1">#sample action from policy</span>
          <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">policy_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
          <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

          <span class="c1">#perform action to get reward and new state</span>
          <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

          <span class="c1">#update preceding variables</span>
          <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">reward</span><span class="p">])</span>
          <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
          <span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>

          <span class="c1">#for training</span>
          <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
          <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
          <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
          <span class="n">log_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
          <span class="n">entropy_term</span> <span class="o">+=</span> <span class="n">entropy</span>

      <span class="c1">#calculataing loss</span>
      <span class="n">Qval</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">Qvals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))):</span>
        <span class="n">Qval</span> <span class="o">=</span> <span class="n">rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">*</span> <span class="n">Qval</span>
        <span class="n">Qvals</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">Qval</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">log_probs</span><span class="p">)</span>
      <span class="n">advantage</span> <span class="o">=</span> <span class="n">Qvals</span> <span class="o">-</span> <span class="n">values</span>
      <span class="n">actor_loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">log_probs</span> <span class="o">*</span> <span class="n">advantage</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
      <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">advantage</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
      <span class="n">entropy_term</span> <span class="o">=</span> <span class="n">entropy_term</span> <span class="o">/</span> <span class="n">num_trials</span>

      <span class="c1">#loss incorporates actor/critic terms + entropy</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">actor_loss</span> <span class="o">+</span> <span class="n">agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">*</span> <span class="n">critic_loss</span> <span class="o">-</span> <span class="n">agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">*</span> <span class="n">entropy_term</span>

      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1">#evaluation (on the same task after all gradient steps!)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1">#start conditions</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">get_init_hidden_states</span><span class="p">()</span>
    <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_evaluation_trials</span><span class="p">):</span>

      <span class="c1">#state + reward + one-hot encoding of action</span>
      <span class="n">full_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">preceding_reward</span><span class="p">,</span> <span class="n">preceding_action</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">value</span><span class="p">,</span> <span class="n">policy_logits</span><span class="p">,</span> <span class="n">step_hidden_states</span> <span class="o">=</span> <span class="n">agent</span><span class="p">(</span><span class="n">full_state</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
      <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">step_hidden_states</span>
      <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="c1">#sample action from policy</span>
      <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">policy_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
      <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

      <span class="c1">#perform action to get reward and new state</span>
      <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

      <span class="c1">#update preceding variables</span>
      <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">reward</span><span class="p">])</span>
      <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>

      <span class="c1">#add reward to the score of agent</span>
      <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span>

    <span class="k">return</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see what is the score for the default A2C agent in Harlow experiment (as the number of evaluation trials is 20, the maximum score to obtain is exactly 20).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define agent and optimizer</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#calculate score</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Score is </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<p>Can we think of a way to make the network better at this learning Harlow tasks?</p>
<section id="id2">
<h2>Submit your feedback<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_a2c_agent")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-3-baldwin-effect">
<h1>Section 3: Baldwin Effect<a class="headerlink" href="#section-3-baldwin-effect" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 25 minutes</em></p>
<p>This section discusses the Baldwin effect in evolutionary biology and proposes you to code for its implementation.</p>
<section id="video-2-baldwin-effect">
<h2>Video 2: Baldwin Effect<a class="headerlink" href="#video-2-baldwin-effect" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "d4d6df094dba40e1a55c51d7c4fad677"}</script></div>
</div>
</section>
<section id="id3">
<h2>Submit your feedback<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_baldwin_effect")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="coding-exercise-2-agent-s-rate-to-learn">
<h2>Coding Exercise 2: Agent’s Rate to Learn<a class="headerlink" href="#coding-exercise-2-agent-s-rate-to-learn" title="Permalink to this heading">#</a></h2>
<p>As it was introduced in the video, the Baldwin effect argues that we don’t inherit the features/weights that make us good at specific tasks but rather the ability to learn quickly to gain the needed features in the context of the tasks we face during our own lifetime. In this way, evolution works like the outer loop in a meta-learning context.</p>
<p>In the next section we will implement this evolutionary approach to meta-learning. But first we need to write a function that lets us evaluate how well an agent can learn each instantiation of the Harlow task. This looks something like this:</p>
<p>$</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp; [1] \: \theta \: \text{- network parameters} \\
&amp; [2] \: \text{Sample batch of tasks }\tau_i \sim p(\tau) \\
&amp; [3] \: \text{for all }\tau_i \text{ do} \\
&amp; [4] \: \quad\quad \theta_i \leftarrow \theta \\
&amp; [5] \: \quad\quad \text{for} \: k \: \text{in range(number of gradient steps)}  \\
&amp; [6] \: \quad\quad\quad\quad\text{Evaluate }\nabla_{\theta_i} \mathcal{L}_{\tau_i}(\theta_i) \\
&amp; [7] \: \quad\quad\quad\quad\text{Compute adapted parameters with gradient descent:} \: \: \theta_i \leftarrow \theta_i - \alpha \nabla_{\theta_i} \mathcal{L}_{\tau_i}(\theta_i) \\
&amp; [8] \: \quad\quad\text{end for} \\
&amp; [9] \: \quad\quad\text{Calculate score of updated agent on this task }f_i = \text{score}(\tau_i(\theta_i)) \\
&amp; [10] \: \text{end for} \\
&amp; [11] \: \text{Score of the agent for all tasks is} \: F = \sum_{i} f_i \\
\end{align*}\]</div>
<p>$</p>
<p>At first, we sample a bunch of tasks from the environment (different pair of objects; line[2]). The crucial concept involved in this algorithm is preserved in the line [4], where for each new task, we don’t start with updated parameters but the one we have before training and evaluating the agent. Then, we perform training for the defined number of gradient steps and evaluate the agent’s performance on thix same task (we have defined this function in the second section of the tutorial, it basically covers lines [5] - [9]). To evaluate the agent’s ability to learn quickly, one task is not enough - it is exactly why we sampled a bunch of them and the general score for the agent is defined as sum of rewards for all tasks.</p>
<p>In the coding exercise you are invited to complete the implementation of the evaluation of a randomly created agent on 10 tasks (thus, the maximum score which can obtained is 10 (number of tasks) x 20 (number of evaluation trials per task) = 200). In the next section of the tutorial, we will provide the framework in which we are going to learn “basic” or “starting” weights and which has underlying evolutionary idea!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_tasks</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num_gradient_steps</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="n">num_trials</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num_evaluation_trials</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Training and evaluation for agent in Harlow experiment environment for the bunch of tasks (thus measuring overall potential for agent's generalization across the tasks).</span>
<span class="sd">    Evaluation goes only after all gradient steps.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - agent (ActorCritic): particular instance of Actor Critic agent to train.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - num_tasks (int, default = 10): number of tasks to evaluate agent on.</span>
<span class="sd">    - num_gradient_steps (int, default = 25): number of gradient steps to perform.</span>
<span class="sd">    - num_trials (int, default = 6): number of times the agent is exposed to the environment per gradient step to be trained .</span>
<span class="sd">    - num_evaluation_trials (int, default = 20): number of times the agent is exposed to the environment to evaluate it (no training happend during this phase).</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - scores (list): list of scores obtained during evaluation on the specific tasks.</span>
<span class="sd">    """</span>
    <span class="c1">###################################################################</span>
    <span class="c1">## Fill out the following then remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: complete evaluation function with Baldwin effect in mind."</span><span class="p">)</span>
    <span class="c1">###################################################################</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tasks</span><span class="p">):</span> <span class="c1">#lines[2-3]; notice that environment resets inside `train_evaluate_agent`</span>
      <span class="n">agent_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="c1">#line[4]; remember that we don't want to change agent's parameters!</span>
      <span class="n">score</span> <span class="o">=</span> <span class="n">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_gradient_steps</span><span class="p">,</span> <span class="n">num_trials</span><span class="p">,</span> <span class="n">num_evaluation_trials</span><span class="p">)</span>
      <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">scores</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D4_Macrolearning/solutions/W2D4_Tutorial4_Solution_33ccd1d3.py"><em>Click for solution</em></a></p>
<p>Observe the box-plot of the scores as well as their sum. Not surprisingly, this random agent does not perform very well.</p>
<p>Make sure you execute this cell to observe the plot!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to observe the plot!</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define agent and optimizer</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#calculate score</span>
<span class="n">total_score</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total score is </span><span class="si">{</span><span class="n">total_score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="n">plot_boxplot_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>

</div>
<section id="id4">
<h3>Submit your feedback<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_agents_rate_to_learn")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-4-evolutionary-framework">
<h1>Section 4: Evolutionary Framework<a class="headerlink" href="#section-4-evolutionary-framework" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 35 minutes</em></p>
<p>This section explores genetic algorithms where we will observe how the Baldwin effect selects for individuals which learn more quickly!</p>
<section id="coding-exercise-3-genetic-algorithm">
<h2>Coding Exercise 3: Genetic Algorithm<a class="headerlink" href="#coding-exercise-3-genetic-algorithm" title="Permalink to this heading">#</a></h2>
<p>Genetic algorithms (GA) mimic some of the evolutionary processes while generating better and better (= more desired) individuals in the population. At first, we initialize a population which consists of randomly defined agents (so we have a list of <code class="docutils literal notranslate"><span class="pre">population_size</span></code> A2C agents which will in the very end evolve to the agents which quickly learn the new task from Harlow experiment environment). Each epoch (which is the classical term for machine learning) is defined as a generation in GA as we generate new individuals in the population. For each epoch, we choose top-score individuals from the population (of size <code class="docutils literal notranslate"><span class="pre">tournament_size</span></code>; should be big enough to preserve diversity and not too big for selecting top-score ones; it is exactly where selection takes place! and it is the only such place in the whole algorithm) and then we select a random batch of these high-performing individuals of size <code class="docutils literal notranslate"><span class="pre">parents_num</span></code>. From those, we create offspring of size <code class="docutils literal notranslate"><span class="pre">new_generation_new_individuals</span></code> which will replace random individuals from the population . We continue running generations until we are happy with the best-fit individual appearing in the population or until we are running out of time (reached maximum number of generations).</p>
<p>The funniest part happens at the place where we create offsprings - to simluate evoluntionary processes, we randomly select two parents (two agents) and for each of the layers in their networks, we randomly select which one will go to the child (simulating crossing over) and then we add Gaussian noise to each of the layers (simulating mutation). Moreover, GA propose unique feature which can’t be that easily introduced in classical gradient descent: we can evolve hyperparameters as well!</p>
<p>The following cell consists of 3 functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">create_initial_population</span></code>, which basically creates population and evaluates each individual as its score;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">create_new_agent</span></code>, which performs crossing over and mutation on parents networks to create one offspring;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">update_population</span></code>, which deletes random individuals in the end of the generation and adds new ones (while also evaluating them during that).</p></li>
</ul>
<p>Your task is to complete missing parts in the code and run the total agorithm with the Baldwin effect! The first cell defines noise constants to be used for each of the (hyper)parameters while mutating them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#for mutation of (hyper)parameters</span>
<span class="n">parameters_noise</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">learning_rate_noise</span> <span class="o">=</span> <span class="mf">0.00005</span>
<span class="n">discount_factor_noise</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">state_value_estimate_cost_noise</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">entropy_cost_noise</span> <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###################################################################</span>
<span class="c1">## Fill out the following then remove</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: complete genetic algorithm functions."</span><span class="p">)</span>
<span class="c1">###################################################################</span>

<span class="k">def</span> <span class="nf">create_initial_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optmizer_func</span><span class="p">,</span> <span class="n">population_size</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Creates an initial population of agents.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - population_size (int, default = 50): the size of the initial population.</span>
<span class="sd">    - hidden_size (int, default = 20): the size of LSTM layer in A2C agent.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - population (list): initial population which consists of tuples (agent, score).</span>
<span class="sd">    - best_score (int): the best score for the individual in the population registered so far.</span>
<span class="sd">    """</span>
    <span class="n">population</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">total_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">population_size</span><span class="p">):</span>
        <span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">optmizer_func</span><span class="p">)</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">best_score</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
        <span class="n">total_score</span> <span class="o">+=</span> <span class="o">...</span>
        <span class="n">population</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">agent</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generation: 0, mean population score: </span><span class="si">{</span><span class="n">total_score</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">population_size</span><span class="si">}</span><span class="s2">, best score: </span><span class="si">{</span><span class="n">best_score</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">population</span><span class="p">,</span> <span class="n">best_score</span>

<span class="k">def</span> <span class="nf">create_new_agent</span><span class="p">(</span><span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Creates new agent using crossing over technique over layers of network and mutation of the parameters with Gaussian noise.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - agent1 (ActorCritic): first parent agent.</span>
<span class="sd">    - agent2 (ActorCritic): second parent agent.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - new_agent (ActorCritic): new agent which is offspring of the given two.</span>
<span class="sd">    """</span>
    <span class="c1">#creates agent as copy of the first one</span>
    <span class="n">new_agent</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">agent1</span><span class="p">)</span>

    <span class="c1">#evolving network parameters with crossing over (over separate layes) &amp; mutating (Gaussian noise)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">new_agent</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
            <span class="c1">#add noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="o">...</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="o">*</span> <span class="o">...</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span>
                <span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
            <span class="c1">#add noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="o">...</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="o">...</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="o">...</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="o">...</span>

    <span class="c1">#evolving &amp; mutating hyperparameters</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">learning_rate</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="o">...</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">discount_factor</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="o">...</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span> <span class="mf">0.99</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">state_value_estimate_cost</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="o">...</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="mf">0.7</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">entropy_cost</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="o">...</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">),</span> <span class="mf">0.05</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_agent</span>

<span class="k">def</span> <span class="nf">update_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">population</span><span class="p">,</span> <span class="n">parents_population</span><span class="p">,</span> <span class="n">best_score</span><span class="p">,</span> <span class="n">new_generation_new_individuals</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Updates population with new individuals which are the result of crossing over and mutation of two parents agents.</span>
<span class="sd">    Removes the same amount of random agents from the population.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - population (list): current population which consists of tuples (agent, score).</span>
<span class="sd">    - parents_population (list) : parents individuals (part of current population) for creating new individuals.</span>
<span class="sd">    - best_score (int): the best score for the individual in the population registered so far.</span>
<span class="sd">    - new_generation_new_individuals (int, default = 5): the number of individuals to create (and the old ones to remove).</span>
<span class="sd">    """</span>

    <span class="c1">#create new individuals</span>
    <span class="n">new_individuals</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_generation_new_individuals</span><span class="p">):</span>
        <span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">new_agent</span> <span class="o">=</span> <span class="n">create_new_agent</span><span class="p">(</span><span class="n">agent1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
        <span class="c1">#evaluate whether best score has increased</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">best_score</span><span class="p">)</span>
        <span class="n">new_individuals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">new_agent</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

    <span class="c1">#remove random old individuals</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
        <span class="n">population</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">population</span> <span class="o">+</span> <span class="n">new_individuals</span><span class="p">,</span> <span class="n">best_score</span>
</pre></div>
</div>
</div>

</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D4_Macrolearning/solutions/W2D4_Tutorial4_Solution_55c8042e.py"><em>Click for solution</em></a></p>
<p>In order to get the desired results of the genetic algorithm, one should wait for the population to evolve enough :) Unfortunately, we don’t have that much time, thus in order to see the initial results we will only run for 1 generation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#selection - random</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define agent and optimizer</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#GA consts</span>
<span class="n">num_generations</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tournament_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">parents_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">new_generation_new_individuals</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">mean_population_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#create population</span>
<span class="n">population</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="n">create_initial_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>

<span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_generations</span><span class="p">):</span>

  <span class="c1">#at first, select top individuals from population (of size tournament_size) (selectivy happens here)</span>
  <span class="n">sorted_population</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">tournament_population</span> <span class="o">=</span> <span class="n">sorted_population</span><span class="p">[:</span><span class="n">tournament_size</span><span class="p">]</span>

  <span class="c1">#random choice of parents from tournament population</span>
  <span class="n">parents_population</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">tournament_population</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">parents_size</span><span class="p">)</span>

  <span class="c1">#update population</span>
  <span class="n">population</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="n">update_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">population</span><span class="p">,</span> <span class="n">parents_population</span><span class="p">,</span> <span class="n">best_score</span><span class="p">)</span>

  <span class="n">mean_population_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">agent_score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">agent_score</span> <span class="ow">in</span> <span class="n">population</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generation </span><span class="si">{</span><span class="n">generation</span><span class="si">}</span><span class="s2">, mean population score: </span><span class="si">{</span><span class="n">mean_population_scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, best score: </span><span class="si">{</span><span class="n">best_score</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<p>If you change <code class="docutils literal notranslate"><span class="pre">num_generations</span></code> to 800 in the previous code cell, the plot for the mean score in the population will roughly take the following form.</p>
<p><img alt="Picture which depicts the plot of mean scores per generation." src="tutorials/W2D4_Macrolearning/student/static/evolution.png"/></p>
<p>In the very start of the tutorial, we have downloaded the best agent we obtained from the training on 800 generations (you can get the same if you add extra infrastructure code around to “catch” such agent as soon as score reaches some threshold value; in this case, it can be even set up to 200). In the next section we are going to compare its performance with randomly initialized agent and observe that, indeed, during evolutionary processes we developed agents with parameters that are able to learn more quickly.</p>
<section id="id5">
<h3>Submit your feedback<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_genetic_algorithm")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="think-1-evolutionary-theories-in-code">
<h2>Think 1: Evolutionary Theories in Code<a class="headerlink" href="#think-1-evolutionary-theories-in-code" title="Permalink to this heading">#</a></h2>
<p>In this section we have observed how the Baldwin effect evolves individuals’ parameters so that they quickly learn. We would like to propose you to think about other evolutionary biology ideas. For example, what would this process look like if we took a <a class="reference external" href="https://en.wikipedia.org/wiki/Lamarckism">Lamarckian approach</a>? Discuss what should be changed in the implementation to use these ideas (simply put, what parts of code should be change to reflect their essence)?</p>
<p>Take time to think and then discuss as a group</p>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D4_Macrolearning/solutions/W2D4_Tutorial4_Solution_41fe24e3.py"><em>Click for solution</em></a></p>
<section id="id6">
<h3>Submit your feedback<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_evolutionary_theories_in_code")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-5-newbie-experienced-bird">
<h1>Section 5: Newbie &amp; Experienced Bird<a class="headerlink" href="#section-5-newbie-experienced-bird" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 45 minutes</em></p>
<p>This section proposes comparison of the evolutionary trained (found) agent which performs the Harlow experiment with the previously-mentioned model which is initialized from scratch (and thus only trains on the given task but does not benefit from meta-learning).</p>
<p>Make sure you execute this cell to observe the plot!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to observe the plot!</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define newbie agent and optimizer</span>
<span class="n">newbie</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#calculate newbie's score</span>
<span class="n">total_score</span><span class="p">,</span> <span class="n">newbie_scores</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">newbie</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total score of newbie agent is </span><span class="si">{</span><span class="n">total_score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>

<span class="c1">#define experienced agent</span>
<span class="n">experienced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"Evolution.pt"</span><span class="p">)</span>

<span class="c1">#calculate experienced's score</span>
<span class="n">total_score</span><span class="p">,</span> <span class="n">experienced_scores</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">experienced</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total score of experienced agent is </span><span class="si">{</span><span class="n">total_score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>

<span class="n">plot_two_boxplot_scores</span><span class="p">(</span><span class="n">newbie_scores</span><span class="p">,</span> <span class="n">experienced_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>

</div>
<section id="id7">
<h2>Submit your feedback<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_newbie_experienced")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: 50 minutes</em></p>
<p>Here is a summary of what we’ve learned:</p>
<ol class="arabic simple">
<li><p>The Baldwin effect says that evolution will select organisms that are good at learning.</p></li>
<li><p>We can use evolutionary/genetic algorithms to replicate this process. This is the “outer loop” of a meta-learning problem</p></li>
<li><p>To be more biologically plausible, we can use reinforcement learning as the inner loop.</p></li>
<li><p>This process creates agents that can quickly find the rewarding object in a Harlow experiment.</p></li>
</ol>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/W2D4_Macrolearning/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W2D4_Tutorial3.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 3: Meta-learning</p>
</div>
</a>
<a class="right-next" href="W2D4_Tutorial5.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 5: Replay</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Biological meta reinforcement learning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
     Data retrieval
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu">
     Set device (GPU or CPU).
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-harlow-experiment">
   Section 1: Harlow Experiment
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-harlow-experiment">
     Video 1: Harlow Experiment
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-meta-structure">
     Coding Exercise 1: Meta-Structure
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-advantage-actor-critic-a2c-agent">
   Section 2: Advantage Actor Critic (A2C) Agent
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-baldwin-effect">
   Section 3: Baldwin Effect
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-baldwin-effect">
     Video 2: Baldwin Effect
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-agent-s-rate-to-learn">
     Coding Exercise 2: Agent’s Rate to Learn
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-evolutionary-framework">
   Section 4: Evolutionary Framework
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-genetic-algorithm">
     Coding Exercise 3: Genetic Algorithm
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-evolutionary-theories-in-code">
     Think 1: Evolutionary Theories in Code
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-newbie-experienced-bird">
   Section 5: Newbie &amp; Experienced Bird
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id7">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>