
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 1: Consciousness — Neuromatch Academy: NeuroAI</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/W2D5_Mysteries/student/W2D5_Tutorial1';</script>
<link href="../../../_static/ai-logo.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D5_Tutorial2.html" rel="next" title="Tutorial 2: Ethics"/>
<link href="W2D5_Intro.html" rel="prev" title="Intro"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/NeuroAI.html">
                        Prerequisites and preparatory materials for NeuroAI course
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicStructures/chapter_title.html">
                        Neuro Symbolic Structures (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/NeuroAI.html">
                        Prerequisites and preparatory materials for NeuroAI course
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicStructures/chapter_title.html">
                        Neuro Symbolic Structures (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../prereqs/NeuroAI.html">Prerequisites and preparatory materials for NeuroAI course</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D1_Generalization/chapter_title.html">Generalization (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Intro.html">W1D1 Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial1.html">Tutorial 1: Generalization in AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial2.html">Tutorial 2: Generalization in Neuroscience</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Tutorial3.html">Tutorial 3: Generalization in Cognitive Science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/student/W1D1_DaySummary.html">Day Summary</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D2_ComparingTasks/chapter_title.html">Comparing Tasks (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/student/W1D2_Intro.html">W1D2 Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/student/W1D2_Tutorial1.html"><strong>Tutorial 1:Task definition, application, relations and impacts on generalization</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/student/W1D2_Tutorial2.html">Tutorial 2: Contrastive learning for object recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/student/W1D2_Tutorial3.html">Tutorial 3: Reinforcement learning across temporal scales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/student/W1D2_Outro.html">W1D2 Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/student/W1D2_DaySummary.html">W1D1 Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">Comparing Artificial And Biological Networks (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial1.html">Tutorial 1: Generalization and representational geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial2.html">Tutorial 2: Computation as transformation of representational geometries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial3.html">Tutorial 3: Representational geometry &amp; noise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial4.html">Tutorial 4: Statistical inference on representational geometries</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D5_Microcircuits/chapter_title.html">Microcircuits (W1D5)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/student/W1D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/student/W1D5_Tutorial1.html">Tutorial 1: Sparsity and Sparse Coding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/student/W1D5_Tutorial2.html">Tutorial 2: Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/student/W1D5_Tutorial3.html">Tutorial 3: Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/student/W1D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/student/W1D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_Macrocircuits/chapter_title.html">Macrocircuits (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Tutorial1.html">Tutorial 1: Depth vs Width</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/student/W2D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/chapter_title.html">Neuro Symbolic Structures (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/student/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/student/W2D2_Tutorial1.html">Tutorial 1: Basic operations of vector symbolic algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/student/W2D2_Tutorial2.html">Tutorial 2: Learning from structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/student/W2D2_Tutorial3.html">Tutorial 3: Generalizing representations in continuous space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/student/W2D2_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicStructures/student/W2D2_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D3_Microlearning/chapter_title.html">Microlearning (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_Tutorial1.html">Tutorial 1: Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/student/W2D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D4_Macrolearning/chapter_title.html">Macrolearning (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial1.html">Tutorial 1: The problem of changing data distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial2.html">Tutorial 2: Continual learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial3.html">Tutorial 3: Meta-learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial4.html">Tutorial 4: Biological meta reinforcement learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Tutorial5.html">Tutorial 5: Replay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/student/W2D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mysteries</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Mysteries (W2D5)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="W2D5_Intro.html">Intro</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 1: Consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D5_Tutorial2.html">Tutorial 2: Ethics</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Project materials</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Macrocircuits.html">Macrocircuits: leveraging neural architectural priors and modularity in embodied agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Microlearning.html">Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/ComparingNetworks.html">Comparing networks: characterizing computational similarity in task-trained recurrent neural networks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Professional Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/impact_talks.html">Impact Talks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/mentorship_program.html">Professional developemnt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_features.html">Career Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_panels.html">Career Panels</a></li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/NeuroAI_Course" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/NeuroAI_Course/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D5_Mysteries/student/W2D5_Tutorial1.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W2D5_Mysteries/student/W2D5_Tutorial1.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 1: Consciousness</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Consciousness
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Install and import feedback gadget
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
       Import dependencies
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
       Figure settings
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Helper functions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Plotting functions
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
       Set device (GPU or CPU). Execute
       <code class="docutils literal notranslate">
<span class="pre">
         set_device()
        </span>
</code>
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-global-neural-workspace">
   Section 1: Global Neural Workspace
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1">
     Video 1
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Video 1
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1a-modularity-of-the-mind">
     Section 1a: Modularity Of The Mind
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
       Data retrieval
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#rims">
       RIMs
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#lstm">
       LSTM
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion-point">
       Discussion point
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hint">
       Hint
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#rims-and-consciousness">
       RIMs and consciousness
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1b-a-shared-workspace">
     Section 1b: A Shared Workspace
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-creating-a-shared-workspace">
       Coding Exercise: Creating a Shared Workspace
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#step-1-aggregation-of-specialist-states">
       Step 1: Aggregation of specialist states
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#step-2-competitive-information-update-in-the-shared-workspace">
       Step 2: Competitive information update in the shared workspace
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#step-3-broadcasting-updated-information">
       Step 3: Broadcasting updated information
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#dynamic-filtering-and-enhanced-generalization">
       Dynamic filtering and enhanced generalization
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#integration-into-a-full-system">
       Integration into a full system
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1c-a-toy-model-for-illustrating-gnw">
     Section 1c: a toy model for illustrating GNW
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#recap">
     Recap
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-metacognition">
   Section 2: Metacognition
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video">
     Video
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2">
       Video 2
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2a-second-order-model">
     Section 2a: Second order model
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#activity-1-developing-a-second-order-network">
       Activity 1: Developing a Second-Order Network
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
       Discussion point
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2b-hoss-model">
     Section 2b: HOSS model
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id7">
       Video
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3">
         Video 3
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#make-our-stimulus-space">
       Make our stimulus space
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#add-in-higher-order-node-for-global-detection">
       Add in higher-order node for global detection
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#introducing-the-a-level">
         Introducing the “A” Level:
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise">
       Coding exercise
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#simulate-kl-divergence-surfaces">
       Simulate KL divergence surfaces
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id8">
       Discussion point
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id9">
       Hint
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#simulate-ignition-asymmetry-vs-symmetry">
       Simulate ignition (asymmetry vs. symmetry)
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id10">
       Discussion point
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1">
     Bonus section 1
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-a-first-order-network">
       Train a first-order network
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#testing-patterns">
       Testing patterns
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#activity-1-building-a-nework-for-a-blindsight-situation">
       Activity 1: Building a nework for a blindsight situation
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#steps-to-follow">
       Steps to follow
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#understanding-the-process">
       Understanding the process
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#testing-under-3-blindsight-conditions">
       Testing under 3 blindsight conditions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-2">
     Bonus section 2
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#plot-surfaces-for-content-awareness-inferences">
       Plot surfaces for content / awareness inferences
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id11">
     Video
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4">
       Video 4
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5">
       Video 5
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6">
       Video 6
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7">
       Video 7
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8">
       Video 8
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<p><a href="https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D5_Mysteries/student/W2D5_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D5_Mysteries/student/W2D5_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-1-consciousness">
<h1>Tutorial 1: Consciousness<a class="headerlink" href="#tutorial-1-consciousness" title="Permalink to this heading">#</a></h1>
<p><strong>Week 2, Day 5: Mysteries</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Samuele Bolotta, Juan David Vargas, Megan Peters, Steve Fleming, Guillaume Dumas, Joseph LeDoux, Matthias Michel, Daniel Dennett, Hakwan Lau, Anil Seth</p>
<p><strong>Content reviewers:</strong> Samuele Bolotta, Lily Chamakura, RyeongKyung Yoon, Yizhou Chen, Ruiyi Zhang</p>
<p><strong>Production editors:</strong> Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk</p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: 120 minutes</em></p>
<p>By the end of this tutorial, participants will be able to:</p>
<ol class="arabic simple">
<li><p>Understand and distinguish various aspects of consciousness including the hard problem of consciousness, the difference between phenomenal consciousness and access consciousness, as well as the distinctions between consciousness and sentience or intelligence</p></li>
<li><p>Explore core frameworks for analyzing consciousness, including diagnostic criteria, and will compare objective probabilities with subjective credences</p></li>
<li><p>Delve into reductionist theories of consciousness, such as Global Workspace Theory (GWT), theories of metacognition, and Higher-Order Thought (HOT) theories.</p></li>
</ol>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b32ce2e4e0f64af8824bee146e5dc964"}</script></div>
</div>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-and-import-feedback-gadget">
<h2>Install and import feedback gadget<a class="headerlink" href="#install-and-import-feedback-gadget" title="Permalink to this heading">#</a></h2>
<section id="id1">
<h3>Install and import feedback gadget<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install and import feedback gadget</span>

<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>vibecheck<span class="w"> </span>numpy<span class="w"> </span>matplotlib<span class="w"> </span>Pillow<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>transformers<span class="w"> </span>ipywidgets<span class="w"> </span>gradio<span class="w"> </span>trdg<span class="w"> </span>scikit-learn<span class="w"> </span>networkx<span class="w"> </span>pickleshare<span class="w"> </span>seaborn<span class="w"> </span>tabulate<span class="w"> </span>--quiet

<span class="kn">from</span> <span class="nn">vibecheck</span> <span class="kn">import</span> <span class="n">DatatopsContentReviewContainer</span>
<span class="k">def</span> <span class="nf">content_review</span><span class="p">(</span><span class="n">notebook_section</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DatatopsContentReviewContainer</span><span class="p">(</span>
        <span class="s2">""</span><span class="p">,</span>  <span class="c1"># No text prompt - leave this as is</span>
        <span class="n">notebook_section</span><span class="p">,</span>
        <span class="p">{</span>
        <span class="s2">"url"</span><span class="p">:</span> <span class="s2">"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab"</span><span class="p">,</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"sciencematch_sm"</span><span class="p">,</span> <span class="c1"># change the name of the course : neuromatch_dl, climatematch_ct, etc</span>
        <span class="s2">"user_key"</span><span class="p">:</span> <span class="s2">"y1x3mpx5"</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>

<span class="n">feedback_prefix</span> <span class="o">=</span> <span class="s2">"W2D5_T1"</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class="-Color -Color-Yellow">WARNING: typer 0.12.3 does not provide the extra 'all'</span>

</pre></div>
</div>
</div>
</div>
</section>
<section id="import-dependencies">
<h3>Import dependencies<a class="headerlink" href="#import-dependencies" title="Permalink to this heading">#</a></h3>
<p>Enhanced organization and clarity in import statements for better readability</p>
<div class="cell tag_remove-input docutils container">
</div>
</section>
</section>
<section id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<section id="id2">
<h3>Figure settings<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="c1"># @markdown</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="helper-functions">
<h2>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<section id="id3">
<h3>Helper functions<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions</span>
<span class="c1"># @markdown</span>

<span class="k">class</span> <span class="nc">FirstOrderNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">data_factor</span><span class="p">,</span> <span class="n">use_gelu</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initializes the FirstOrderNetwork with specific configurations.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - hidden_units (int): The number of units in the hidden layer.</span>
<span class="sd">        - data_factor (int): Factor to scale the amount of data processed.</span>
<span class="sd">                             A factor of 1 indicates the default data amount,</span>
<span class="sd">                             while 10 indicates 10 times the default amount.</span>
<span class="sd">        - use_gelu (bool): Flag to use GELU (True) or ReLU (False) as the activation function.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FirstOrderNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Define the encoder, hidden, and decoder layers with specified units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="c1"># Dropout layer to prevent overfitting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># Temperature parameter for activation sharpness control</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="c1"># Set the data factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_factor</span> <span class="o">=</span> <span class="n">data_factor</span>

        <span class="c1"># Choose the activation function based on the use_gelu flag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_gelu</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Other activation functions for various purposes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span>

        <span class="c1"># Initialize network weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initializes weights of the encoder, hidden, and decoder layers uniformly."""</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Defines the forward pass through the network.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - x (Tensor): The input tensor to the network.</span>

<span class="sd">        Returns:</span>
<span class="sd">        - Tensor: The output of the network after passing through the layers and activations.</span>
<span class="sd">        """</span>
        <span class="c1"># Encoder step with dropout and sigmoid activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">))</span>

        <span class="c1"># Hidden layer step with dropout and sigmoid activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">))</span>

        <span class="c1"># Decoder step with dropout and sigmoid activation</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">))</span>

        <span class="c1"># Adjust output based on a threshold</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">output</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">output</span> <span class="o">+</span> <span class="mf">0.12</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">initialize_global</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">Input_Size_1</span><span class="p">,</span> <span class="n">Hidden_Size_1</span><span class="p">,</span> <span class="n">Output_Size_1</span><span class="p">,</span> <span class="n">Input_Size_2</span>
    <span class="k">global</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">patterns_number</span>
    <span class="k">global</span> <span class="n">learning_rate_1</span><span class="p">,</span> <span class="n">learning_rate_2</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">temperature</span> <span class="p">,</span> <span class="n">Threshold</span>
    <span class="k">global</span> <span class="n">First_set</span><span class="p">,</span> <span class="n">Second_set</span><span class="p">,</span> <span class="n">Third_set</span>
    <span class="k">global</span> <span class="n">First_set_targets</span><span class="p">,</span> <span class="n">Second_set_targets</span><span class="p">,</span> <span class="n">Third_set_targets</span>
    <span class="k">global</span> <span class="n">epoch_list</span><span class="p">,</span> <span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">epoch_2_order</span><span class="p">,</span> <span class="n">patterns_matrix1</span>
    <span class="k">global</span> <span class="n">Testing_graph_names</span>

    <span class="c1"># Network sizes</span>
    <span class="n">Input_Size_1</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">Hidden_Size_1</span> <span class="o">=</span> <span class="mi">60</span>
    <span class="n">Output_Size_1</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">Input_Size_2</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="c1"># Patterns</span>
    <span class="n">num_units</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">patterns_number</span> <span class="o">=</span> <span class="mi">200</span>

    <span class="c1"># Pre-training and hyperparameters</span>
    <span class="n">learning_rate_1</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">learning_rate_2</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">Threshold</span><span class="o">=</span><span class="mf">0.5</span>

    <span class="c1"># Testing</span>
    <span class="n">First_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">Second_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">Third_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">First_set_targets</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">Second_set_targets</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">Third_set_targets</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">Testing_graph_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Suprathreshold stimulus"</span><span class="p">,</span> <span class="s2">"Subthreshold stimulus"</span><span class="p">,</span> <span class="s2">"Low Vision"</span><span class="p">]</span>


    <span class="c1"># Graphic of pretraining</span>
    <span class="n">epoch_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">epoch_1_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
    <span class="n">epoch_2_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
    <span class="n">patterns_matrix1</span> <span class="o">=</span>  <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">patterns_number</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Initialize patterns_matrix as a PyTorch tensor on the GPU</span>

<span class="k">class</span> <span class="nc">SecondOrderNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_gelu</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SecondOrderNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Define a linear layer for comparing the difference between input and output of the first-order network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comparison_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="c1"># Linear layer for determining wagers, mapping from 100 features to a single output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wager</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Dropout layer to prevent overfitting by randomly setting input units to 0 with a probability of 0.3 during training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># Select activation function based on the `use_gelu` flag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_gelu</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span>

        <span class="c1"># Additional activation functions for potential use in network operations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Softmax for multi-class classification problems</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span>

        <span class="c1"># Initialize the weights of the network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Uniformly initialize weights for the comparison and wager layers</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">comparison_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wager</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_order_input</span><span class="p">,</span> <span class="n">first_order_output</span><span class="p">):</span>
        <span class="c1"># Calculate the difference between the first-order input and output</span>
        <span class="n">comparison_matrix</span> <span class="o">=</span> <span class="n">first_order_input</span> <span class="o">-</span> <span class="n">first_order_output</span>

        <span class="c1"># Pass the difference through the comparison layer and apply the chosen activation function</span>
        <span class="n">comparison_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">comparison_layer</span><span class="p">(</span><span class="n">comparison_matrix</span><span class="p">)</span>

        <span class="c1"># Calculate the wager value, applying dropout and sigmoid activation to the output of the wager layer</span>
        <span class="n">wager</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wager</span><span class="p">(</span><span class="n">comparison_out</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">wager</span>

<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Compute precision, recall, and F1 score."""</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">f1_score</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="k">def</span> <span class="nf">create_patterns</span><span class="p">(</span><span class="n">stimulus</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generates neural network input patterns based on specified stimulus conditions.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - stimulus (int): Determines the type of patterns to generate.</span>
<span class="sd">                      Acceptable values:</span>
<span class="sd">                      - 0: Suprathreshold stimulus</span>
<span class="sd">                      - 1: Subthreshold stimulus</span>
<span class="sd">                      - 2: Low vision condition</span>

<span class="sd">    Returns:</span>
<span class="sd">    - torch.Tensor: Tensor of generated patterns.</span>
<span class="sd">    - torch.Tensor: Tensor of target values corresponding to the generated patterns.</span>
<span class="sd">    """</span>

    <span class="c1"># Generate initial patterns and target tensors for base condition.</span>
    <span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">stim_present_tensor</span><span class="p">,</span> <span class="n">stim_absent_tensor</span><span class="p">,</span> <span class="n">order_2_tensor</span> <span class="o">=</span> <span class="n">Generate_Patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">stimulus</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Suprathreshold stimulus condition</span>
        <span class="c1"># Convert pattern tensors for processing on specified device (CPU/GPU).</span>
        <span class="n">patterns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">stim_present_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">stimulus</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Subthreshold stimulus condition, simulating blindsight with added noise</span>
        <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">generate_subthreshold_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">stimulus</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Low vision condition, reducing stimulus activation</span>
        <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">generate_low_vision_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Invalid stimulus ID for testing patterns creation."</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span>

<span class="k">def</span> <span class="nf">generate_subthreshold_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generates patterns and targets for the subthreshold stimulus condition by adding noise.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - patterns_number (int): Number of patterns to generate.</span>
<span class="sd">    - num_units (int): Number of units in each pattern.</span>
<span class="sd">    - device: The device (CPU/GPU) for tensor operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - Tuple containing two lists of torch.Tensor: (patterns, targets)</span>
<span class="sd">    """</span>
    <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">):</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.0012</span>  <span class="c1"># Base pattern with noise</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">stimulus_number</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">99</span><span class="p">)</span>  <span class="c1"># Selecting unit for stimulus</span>
            <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.0012</span>
            <span class="n">present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
            <span class="n">present</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
        <span class="n">patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="c1"># Convert lists to tensors for device processing.</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_low_vision_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generates patterns and targets for the low vision condition by reducing stimulus activation.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - patterns_number (int): Number of patterns to generate.</span>
<span class="sd">    - num_units (int): Number of units in each pattern.</span>
<span class="sd">    - device: The device (CPU/GPU) for tensor operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - Tuple containing two lists of torch.Tensor: (patterns, targets)</span>
<span class="sd">    """</span>
    <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">):</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">stimulus_number</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">99</span><span class="p">)</span>
            <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
            <span class="n">present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
            <span class="n">present</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.15</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
        <span class="n">patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="c1"># Convert lists to tensors for device processing.</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

  <span class="c1">#define the architecture, optimizers, loss functions, and schedulers for pre training</span>
<span class="k">def</span> <span class="nf">prepare_pre_training</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span><span class="n">factor</span><span class="p">,</span><span class="n">gelu</span><span class="p">,</span><span class="n">stepsize</span><span class="p">,</span> <span class="n">gam</span><span class="p">):</span>

  <span class="n">first_order_network</span> <span class="o">=</span> <span class="n">FirstOrderNetwork</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span><span class="n">factor</span><span class="p">,</span><span class="n">gelu</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">second_order_network</span> <span class="o">=</span> <span class="n">SecondOrderNetwork</span><span class="p">(</span><span class="n">gelu</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

  <span class="n">criterion_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
  <span class="n">criterion_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

  <span class="n">optimizer_1</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">first_order_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate_1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
  <span class="n">optimizer_2</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">second_order_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate_2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>


  <span class="c1"># Learning rate schedulers</span>
  <span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_1</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gam</span><span class="p">)</span>
  <span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_2</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gam</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">criterion_1</span><span class="p">,</span> <span class="n">criterion_2</span><span class="p">,</span> <span class="n">optimizer_1</span><span class="p">,</span> <span class="n">optimizer_2</span><span class="p">,</span> <span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span>

<span class="k">def</span> <span class="nf">title</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
  <span class="c1">#plot the title of the currently trained model, inside a rectangle</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">rectangle</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="mf">0.9</span> <span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">rectangle</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">string</span> <span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">26</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

<span class="c1"># Function to configure the training environment and load the models</span>
<span class="k">def</span> <span class="nf">config_training</span><span class="p">(</span><span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">gelu</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Configures the training environment by saving the state of the given models and loading them back.</span>
<span class="sd">    Initializes testing patterns for evaluation.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - first_order_network: The first order network instance.</span>
<span class="sd">    - second_order_network: The second order network instance.</span>
<span class="sd">    - hidden: Number of hidden units in the first order network.</span>
<span class="sd">    - factor: Factor influencing the network's architecture.</span>
<span class="sd">    - gelu: Activation function to be used in the network.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - Tuple of testing patterns, number of samples in the testing patterns, and the loaded model instances.</span>
<span class="sd">    """</span>
    <span class="c1"># Paths where the models' states will be saved</span>
    <span class="n">PATH</span> <span class="o">=</span> <span class="s1">'./cnn1.pth'</span>
    <span class="n">PATH_2</span> <span class="o">=</span> <span class="s1">'./cnn2.pth'</span>

    <span class="c1"># Save the weights of the pretrained networks to the specified paths</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">first_order_network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">second_order_network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH_2</span><span class="p">)</span>

    <span class="c1"># Generating testing patterns for three different sets</span>
    <span class="n">First_set</span><span class="p">,</span> <span class="n">First_set_targets</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Second_set</span><span class="p">,</span> <span class="n">Second_set_targets</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">Third_set</span><span class="p">,</span> <span class="n">Third_set_targets</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Aggregate testing patterns and their targets for ease of access</span>
    <span class="n">Testing_patterns</span> <span class="o">=</span> <span class="p">[[</span><span class="n">First_set</span><span class="p">,</span> <span class="n">First_set_targets</span><span class="p">],</span> <span class="p">[</span><span class="n">Second_set</span><span class="p">,</span> <span class="n">Second_set_targets</span><span class="p">],</span> <span class="p">[</span><span class="n">Third_set</span><span class="p">,</span> <span class="n">Third_set_targets</span><span class="p">]]</span>

    <span class="c1"># Determine the number of samples from the first set (assumed consistent across all sets)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Initialize and load the saved states into model instances</span>
    <span class="n">loaded_model</span> <span class="o">=</span> <span class="n">FirstOrderNetwork</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">gelu</span><span class="p">)</span>
    <span class="n">loaded_model_2</span> <span class="o">=</span> <span class="n">SecondOrderNetwork</span><span class="p">(</span><span class="n">gelu</span><span class="p">)</span>

    <span class="n">loaded_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
    <span class="n">loaded_model_2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH_2</span><span class="p">))</span>

    <span class="c1"># Ensure the models are moved to the appropriate device (CPU/GPU) and set to evaluation mode</span>
    <span class="n">loaded_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">loaded_model_2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">loaded_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">loaded_model_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">Testing_patterns</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">,</span> <span class="n">loaded_model_2</span>

<span class="c1"># Function to test the model using the configured testing patterns</span>
<span class="k">def</span> <span class="nf">testing</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">,</span> <span class="n">loaded_model_2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Tests the model on provided testing patterns and calculates F1 scores and other metrics for analysis.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - Testing_patterns: A list of testing datasets and their targets.</span>
<span class="sd">    - n_samples: Number of samples in each testing dataset.</span>
<span class="sd">    - loaded_model: The loaded first order network model for testing.</span>
<span class="sd">    - loaded_model_2: The loaded second order network model for testing.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - F1 scores for high and low wager scenarios, and results for plotting.</span>
<span class="sd">    """</span>
    <span class="n">results_for_plotting</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">f1_scores_high_wager</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">f1_scores_low_wager</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Iterate through each set of testing patterns and targets</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">)):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># Ensure no gradients are computed during testing</span>
            <span class="c1"># Obtain output from the first order model</span>
            <span class="n">output_first_order</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="c1"># Focus on the last 100 elements for wagering analysis</span>
            <span class="n">last_100_elements_wager</span> <span class="o">=</span> <span class="n">output_first_order</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">max_values</span> <span class="o">=</span> <span class="n">last_100_elements_wager</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">targets_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">targets_2</span> <span class="o">=</span> <span class="n">targets_2</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="c1"># Convert targets to binary classification for wagering scenario</span>
            <span class="n">targets_2</span> <span class="o">=</span> <span class="p">(</span><span class="n">targets_2</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>

            <span class="c1"># Convert tensors to NumPy arrays for metric calculations</span>
            <span class="n">predicted_np</span> <span class="o">=</span> <span class="n">max_values</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">targets_2_np</span> <span class="o">=</span> <span class="n">targets_2</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="c1"># Calculate True Positives, True Negatives, False Positives, and False Negatives</span>
            <span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_np</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">targets_2_np</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
            <span class="n">TN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_np</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">targets_2_np</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">))</span>
            <span class="n">FP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_np</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">targets_2_np</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">))</span>
            <span class="n">FN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_np</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">targets_2_np</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>

            <span class="c1"># Compute precision, recall, and F1 score for both high and low wager scenarios</span>
            <span class="n">precision_h</span><span class="p">,</span> <span class="n">recall_h</span><span class="p">,</span> <span class="n">f1_score_h</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
            <span class="n">precision_l</span><span class="p">,</span> <span class="n">recall_l</span><span class="p">,</span> <span class="n">f1_score_l</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

            <span class="n">f1_scores_high_wager</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score_h</span><span class="p">)</span>
            <span class="n">f1_scores_low_wager</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score_l</span><span class="p">)</span>

            <span class="c1"># Collect results for plotting</span>
            <span class="n">results_for_plotting</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">"counts"</span><span class="p">:</span> <span class="p">[[</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">],</span> <span class="p">[</span><span class="n">FN</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TN</span><span class="p">],</span> <span class="p">[</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">,</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TN</span><span class="p">]],</span>
                <span class="s2">"metrics"</span><span class="p">:</span> <span class="p">[[</span><span class="n">precision_h</span><span class="p">,</span> <span class="n">recall_h</span><span class="p">,</span> <span class="n">f1_score_h</span><span class="p">],</span> <span class="p">[</span><span class="n">precision_l</span><span class="p">,</span> <span class="n">recall_l</span><span class="p">,</span> <span class="n">f1_score_l</span><span class="p">]],</span>
                <span class="s2">"title_results"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Results Table - Set </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                <span class="s2">"title_metrics"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Metrics Table - Set </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">})</span>

    <span class="k">return</span> <span class="n">f1_scores_high_wager</span><span class="p">,</span> <span class="n">f1_scores_low_wager</span><span class="p">,</span> <span class="n">results_for_plotting</span>

<span class="k">def</span> <span class="nf">Generate_Patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">):</span>
    <span class="c1"># Generates patterns and targets for training the networks</span>
    <span class="c1"># patterns_number: Number of patterns to generate</span>
    <span class="c1"># num_units: Number of units in each pattern</span>
    <span class="c1"># Returns lists of patterns, stimulus present/absent indicators, and second order targets</span>

    <span class="n">patterns</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Store generated patterns</span>
    <span class="n">stim_present</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Indicators for when a stimulus is present in the pattern</span>
    <span class="n">stim_absent</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Indicators for when no stimulus is present</span>
    <span class="n">order_2_pr</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Second order network targets based on the presence or absence of stimulus</span>

    <span class="c1"># Generate patterns, half noise and half potential stimuli</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">):</span>
        <span class="c1"># First half: Noise patterns</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">patterns_number</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>  <span class="c1"># Generate a noise pattern</span>
            <span class="n">patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
            <span class="n">stim_present</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">))</span>  <span class="c1"># Stimulus absent</span>
            <span class="n">stim_absent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">))</span>  <span class="c1"># Redundant, consider removing</span>
            <span class="n">order_2_pr</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="mf">0.0</span> <span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>  <span class="c1"># No stimulus, low wager</span>
        <span class="c1"># Second half: Stimulus patterns</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stimulus_number</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_units</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Choose a unit for potential stimulus</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>
            <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># Set stimulus intensity</span>
            <span class="n">patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
            <span class="n">present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
            <span class="c1"># Determine if stimulus is above discrimination threshold</span>
            <span class="k">if</span> <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">order_2_pr</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="mf">1.0</span> <span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>  <span class="c1"># Stimulus detected, high wager</span>
                <span class="n">present</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">order_2_pr</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="mf">0.0</span> <span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>  <span class="c1"># Stimulus not detected, low wager</span>
                <span class="n">present</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">stim_present</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
            <span class="n">stim_absent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">))</span>  <span class="c1"># Redundant, consider removing</span>

    <span class="n">patterns_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">stim_present_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">stim_present</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">stim_absent_tensor</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">stim_absent</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">order_2_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">order_2_pr</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">stim_present_tensor</span> <span class="p">,</span> <span class="n">stim_absent_tensor</span><span class="p">,</span> <span class="n">order_2_tensor</span>

<span class="k">def</span> <span class="nf">create_patterns</span><span class="p">(</span><span class="n">stimulus</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generates neural network input patterns based on specified stimulus conditions.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - stimulus (int): Determines the type of patterns to generate.</span>
<span class="sd">                      Acceptable values:</span>
<span class="sd">                      - 0: Suprathreshold stimulus</span>
<span class="sd">                      - 1: Subthreshold stimulus</span>
<span class="sd">                      - 2: Low vision condition</span>

<span class="sd">    Returns:</span>
<span class="sd">    - torch.Tensor: Tensor of generated patterns.</span>
<span class="sd">    - torch.Tensor: Tensor of target values corresponding to the generated patterns.</span>
<span class="sd">    """</span>

    <span class="c1"># Generate initial patterns and target tensors for base condition.</span>
    <span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">stim_present_tensor</span><span class="p">,</span> <span class="n">stim_absent_tensor</span><span class="p">,</span> <span class="n">order_2_tensor</span> <span class="o">=</span> <span class="n">Generate_Patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">stimulus</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Suprathreshold stimulus condition</span>
        <span class="c1"># Convert pattern tensors for processing on specified device (CPU/GPU).</span>
        <span class="n">patterns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">stim_present_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">stimulus</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Subthreshold stimulus condition, simulating blindsight with added noise</span>
        <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">generate_subthreshold_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">stimulus</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Low vision condition, reducing stimulus activation</span>
        <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">generate_low_vision_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Invalid stimulus ID for testing patterns creation."</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span>

<span class="k">def</span> <span class="nf">generate_subthreshold_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generates patterns and targets for the subthreshold stimulus condition by adding noise.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - patterns_number (int): Number of patterns to generate.</span>
<span class="sd">    - num_units (int): Number of units in each pattern.</span>
<span class="sd">    - device: The device (CPU/GPU) for tensor operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - Tuple containing two lists of torch.Tensor: (patterns, targets)</span>
<span class="sd">    """</span>
    <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">):</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.0012</span>  <span class="c1"># Base pattern with noise</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">stimulus_number</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">99</span><span class="p">)</span>  <span class="c1"># Selecting unit for stimulus</span>
            <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.0012</span>
            <span class="n">present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
            <span class="n">present</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
        <span class="n">patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="c1"># Convert lists to tensors for device processing.</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_low_vision_patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generates patterns and targets for the low vision condition by reducing stimulus activation.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - patterns_number (int): Number of patterns to generate.</span>
<span class="sd">    - num_units (int): Number of units in each pattern.</span>
<span class="sd">    - device: The device (CPU/GPU) for tensor operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - Tuple containing two lists of torch.Tensor: (patterns, targets)</span>
<span class="sd">    """</span>
    <span class="n">patterns</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">):</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">stimulus_number</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">99</span><span class="p">)</span>
            <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
            <span class="n">present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
            <span class="n">present</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">pattern</span><span class="p">[</span><span class="n">stimulus_number</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.15</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
        <span class="n">patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="c1"># Convert lists to tensors for device processing.</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">patterns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this heading">#</a></h2>
<section id="id4">
<h3>Plotting functions<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>
<span class="c1"># @markdown</span>

<span class="k">def</span> <span class="nf">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">plot_title</span><span class="o">=</span><span class="s2">"Training Signals"</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots the maximum values of signal units and a binary indicator for max values greater than 0.5.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - patterns_tensor: A tensor containing signals, where each signal is expected to have multiple units.</span>
<span class="sd">    """</span>

    <span class="c1"># Calculate the maximum value of units for each signal within the patterns tensor</span>
    <span class="n">max_values_of_units</span> <span class="o">=</span> <span class="n">patterns_tensor</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Ensure it's on CPU and in NumPy format for plotting</span>

    <span class="c1"># Determine the binary indicators based on the max value being greater than 0.5</span>
    <span class="n">binary_indicators</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_values_of_units</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Create a figure with 2 subplots (2 rows, 1 column)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">plot_title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>  <span class="c1"># Set the overall title for the plot</span>

    <span class="c1"># First subplot for the maximum values of each signal</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">max_values_of_units</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s1">'steps-mid'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Signal Number'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Max Value of Signal Units'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Second subplot for the binary indicators</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">binary_indicators</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s1">'steps-mid'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Signal Number'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Indicator (Max &gt; 0.5) in each signal'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>  <span class="c1"># Adjust y-axis limits for clarity</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">pre_train_plots</span><span class="p">(</span><span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">epoch_2_order</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="c1"># LOSS PLOTS</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>  <span class="c1"># Adjust the figure size as needed</span>

    <span class="c1"># First graph for 1st Order Network</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'1st Order Network Loss'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epochs - Pretraining Phase'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>

    <span class="c1"># Second graph for 2nd Order Network</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">epoch_2_order</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'2nd Order Network Loss'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epochs - Pretraining Phase'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'Blindsight_Pre_training_Loss_</span><span class="si">{}</span><span class="s1">.png'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">title</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"_"</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"/"</span><span class="p">,</span> <span class="s2">"_"</span><span class="p">)),</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">'tight'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_testing</span><span class="p">(</span><span class="n">results_for_plotting</span> <span class="p">,</span> <span class="n">title</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Plot a table focused on 'PRECISION', 'RECALL', 'F1 SCORE', indicating consciousness level and testing scenario."""</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">results_for_plotting</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># Adjusted for added header space</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'tight'</span><span class="p">)</span>

    <span class="c1"># Define column labels</span>
    <span class="n">col_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Scenario"</span><span class="p">,</span> <span class="s2">"Consciousness Level"</span><span class="p">,</span> <span class="s2">"PRECISION"</span><span class="p">,</span> <span class="s2">"RECALL"</span><span class="p">,</span> <span class="s2">"F1 SCORE"</span><span class="p">]</span>

    <span class="c1"># Initialize list to hold all rows of data including headers</span>
    <span class="n">full_data</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Process each result to extract and prepare the data rows</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results_for_plotting</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">level</span><span class="p">,</span> <span class="n">metrics</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s2">"High Consciousness"</span><span class="p">,</span> <span class="s2">"Low Consciousness"</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="s2">"metrics"</span><span class="p">]):</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">[</span><span class="n">Testing_graph_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">level</span><span class="p">]</span> <span class="o">+</span> <span class="n">metrics</span>
            <span class="n">full_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># Extract metric values for color scaling (excluding the first two columns which are text)</span>
    <span class="n">metric_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">full_data</span><span class="p">)[:,</span> <span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>  <span class="c1"># Convert to float for color scaling</span>
    <span class="n">max_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">metric_values</span><span class="p">)</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">metric_values</span> <span class="o">/</span> <span class="n">max_value</span>  <span class="c1"># Normalize for color mapping</span>

    <span class="c1"># Prepare colors for all cells, defaulting to white for non-metric cells</span>
    <span class="n">cell_colors</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"white"</span><span class="p">,</span> <span class="s2">"white"</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdYlGn</span><span class="p">(</span><span class="n">colors</span><span class="p">)]</span>

    <span class="c1"># Create the table with cell colors</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">cellText</span><span class="o">=</span><span class="n">full_data</span><span class="p">,</span> <span class="n">colLabels</span><span class="o">=</span><span class="n">col_labels</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">cellLoc</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">cellColours</span><span class="o">=</span><span class="n">cell_colors</span><span class="p">)</span>
    <span class="n">table</span><span class="o">.</span><span class="n">auto_set_font_size</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">table</span><span class="o">.</span><span class="n">set_fontsize</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">table</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="set-device-gpu-or-cpu-execute-set-device">
<h3>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>
<span class="c1"># @markdown</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used</span>
<span class="sd">    in PyTorch operations to specify the device.</span>
<span class="sd">    """</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is not enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"If you want to enable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"`Hardware accelerator.` and select `GPU` from the dropdown menu"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"If you want to disable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"`Hardware accelerator.` and select `None` from the dropdown menu"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-global-neural-workspace">
<h1>Section 1: Global Neural Workspace<a class="headerlink" href="#section-1-global-neural-workspace" title="Permalink to this heading">#</a></h1>
<section id="video-1">
<h2>Video 1<a class="headerlink" href="#video-1" title="Permalink to this heading">#</a></h2>
<section id="id5">
<h3>Video 1<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "da3a4eed67bf4e8ea53e79c88dedc30b"}</script></div>
</div>
</section>
</section>
<section id="section-1a-modularity-of-the-mind">
<h2>Section 1a: Modularity Of The Mind<a class="headerlink" href="#section-1a-modularity-of-the-mind" title="Permalink to this heading">#</a></h2>
<p>In this section, we are exploring an important concept in machine learning: the idea that the complexity we observe in the physical world often arises from simpler, independently functioning parts. Think of the world as being made up of different modules or units that usually operate on their own but sometimes interact with each other. This is similar to how different apps on your phone work independently but can share information when needed.</p>
<p>This idea is closely linked to a field called causal inference, which involves studying how these separate units or mechanisms cause and influence each other. The goal is to understand and model how these mechanisms work both individually and together. Importantly, these mechanisms often interact only minimally, which means they can keep working properly even if changes occur in other parts. This characteristic makes them very robust, or capable of handling disturbances well.</p>
<p>A specific example from machine learning that uses this idea is called Recurrent Independent Mechanisms (RIMs). In RIMs, different parts of the model mostly work independently, but they can also communicate or “pay attention” to each other when it’s necessary. This setup allows for efficient and dynamic processing of information. The research paper available here (https://arxiv.org/pdf/1909.10893) discusses this approach in detail. It highlights the benefits of designing models that recognize and utilize the independence and occasional interactions of these mechanisms. Such models are often more adaptable and can generalize better, meaning they perform well across a variety of different tasks or situations.</p>
<p><img alt="Picture which shows how RIMs work over two steps." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D5_Mysteries/static/RIMs.png?raw=true"/></p>
<p>This figure shows how RIMs work over two steps.</p>
<ul class="simple">
<li><p>Query generation: each RIM starts by creating a query. This query helps each RIM pull out the necessary information from the data it receives at that moment.</p></li>
<li><p>Attention-based selection: on the right side of the figure, you can see that some RIMs are chosen to be active (colored in blue) and others stay inactive (colored in white). This selection is made using a special scoring system called attention, which picks RIMs based on how relevant they are to the current visual inputs.</p></li>
<li><p>State transition for active RIMs: the RIMs that get activated update their internal states according to their specific rules, using the information they’ve gathered. The RIMs that aren’t activated don’t change and keep their previous states.</p></li>
<li><p>Communication between RIMs: finally, the active RIMs share information with each other, but this communication is limited. They use a system similar to key-value pairing, which helps them share only the most important information needed for the next step.</p></li>
</ul>
<p>To make this more concrete, consider the example of modeling the motion of two balls. We can think of each ball as an independent mechanism. Although both balls are affected by Earth’s gravity, and very slightly by each other, they generally move independently. They only interact significantly when they collide. This model captures the essence of independent mechanisms interacting sparsely, a key idea in developing more effective and generalizable AI systems.</p>
<p>Now, let’s download the RIM model!</p>
<section id="data-retrieval">
<h3>Data retrieval<a class="headerlink" href="#data-retrieval" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Data retrieval</span>
<span class="c1"># @markdown</span>

<span class="c1"># URL of the repository to clone</span>
<span class="o">!</span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/SamueleBolotta/RIMs-Sequential-MNIST
<span class="o">%</span><span class="k">cd</span> RIMs-Sequential-MNIST

<span class="c1"># Imports</span>
<span class="kn">from</span> <span class="nn">data</span> <span class="kn">import</span> <span class="n">MnistData</span>
<span class="kn">from</span> <span class="nn">networks</span> <span class="kn">import</span> <span class="n">MnistModel</span><span class="p">,</span> <span class="n">LSTM</span>

<span class="c1"># Function to download files</span>
<span class="k">def</span> <span class="nf">download_file</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">destination</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Starting to download </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">destination</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">destination</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Successfully downloaded </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">destination</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Path of the models</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'LSTM'</span><span class="p">:</span> <span class="s1">'lstm_model_dir/lstm_best_model.pt'</span><span class="p">,</span>
    <span class="s1">'RIM'</span><span class="p">:</span> <span class="s1">'rim_model_dir/best_model.pt'</span>
<span class="p">}</span>

<span class="c1"># URLs of the models</span>
<span class="n">model_urls</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'LSTM'</span><span class="p">:</span> <span class="s1">'https://osf.io/4gajq/download'</span><span class="p">,</span>
    <span class="s1">'RIM'</span><span class="p">:</span> <span class="s1">'https://osf.io/3squn/download'</span>
<span class="p">}</span>

<span class="c1"># Check if model files exist, if not, download them</span>
<span class="k">for</span> <span class="n">model_key</span><span class="p">,</span> <span class="n">model_url</span> <span class="ow">in</span> <span class="n">model_urls</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">[</span><span class="n">model_key</span><span class="p">]):</span>
        <span class="n">download_file</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="n">model_path</span><span class="p">[</span><span class="n">model_key</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2"> model downloaded."</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2"> model already exists. No download needed."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into 'RIMs-Sequential-MNIST'...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>remote: Enumerating objects: 516, done.
remote: Counting objects:   0% (1/516)
remote: Counting objects:   1% (6/516)
remote: Counting objects:   2% (11/516)
remote: Counting objects:   3% (16/516)
remote: Counting objects:   4% (21/516)
remote: Counting objects:   5% (26/516)
remote: Counting objects:   6% (31/516)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>remote: Counting objects:   7% (37/516)
remote: Counting objects:   8% (42/516)
remote: Counting objects:   9% (47/516)
remote: Counting objects:  10% (52/516)
remote: Counting objects:  11% (57/516)
remote: Counting objects:  12% (62/516)
remote: Counting objects:  13% (68/516)
remote: Counting objects:  14% (73/516)
remote: Counting objects:  15% (78/516)
remote: Counting objects:  16% (83/516)
remote: Counting objects:  17% (88/516)
remote: Counting objects:  18% (93/516)
remote: Counting objects:  19% (99/516)
remote: Counting objects:  20% (104/516)
remote: Counting objects:  21% (109/516)
remote: Counting objects:  22% (114/516)
remote: Counting objects:  23% (119/516)
remote: Counting objects:  24% (124/516)
remote: Counting objects:  25% (129/516)
remote: Counting objects:  26% (135/516)
remote: Counting objects:  27% (140/516)
remote: Counting objects:  28% (145/516)
remote: Counting objects:  29% (150/516)
remote: Counting objects:  30% (155/516)
remote: Counting objects:  31% (160/516)
remote: Counting objects:  32% (166/516)
remote: Counting objects:  33% (171/516)
remote: Counting objects:  34% (176/516)
remote: Counting objects:  35% (181/516)
remote: Counting objects:  36% (186/516)
remote: Counting objects:  37% (191/516)
remote: Counting objects:  38% (197/516)
remote: Counting objects:  39% (202/516)
remote: Counting objects:  40% (207/516)
remote: Counting objects:  41% (212/516)
remote: Counting objects:  42% (217/516)
remote: Counting objects:  43% (222/516)
remote: Counting objects:  44% (228/516)
remote: Counting objects:  45% (233/516)
remote: Counting objects:  46% (238/516)
remote: Counting objects:  47% (243/516)
remote: Counting objects:  48% (248/516)
remote: Counting objects:  49% (253/516)
remote: Counting objects:  50% (258/516)
remote: Counting objects:  51% (264/516)
remote: Counting objects:  52% (269/516)
remote: Counting objects:  53% (274/516)
remote: Counting objects:  54% (279/516)
remote: Counting objects:  55% (284/516)
remote: Counting objects:  56% (289/516)
remote: Counting objects:  57% (295/516)
remote: Counting objects:  58% (300/516)
remote: Counting objects:  59% (305/516)
remote: Counting objects:  60% (310/516)
remote: Counting objects:  61% (315/516)
remote: Counting objects:  62% (320/516)
remote: Counting objects:  63% (326/516)
remote: Counting objects:  64% (331/516)
remote: Counting objects:  65% (336/516)
remote: Counting objects:  66% (341/516)
remote: Counting objects:  67% (346/516)
remote: Counting objects:  68% (351/516)
remote: Counting objects:  69% (357/516)
remote: Counting objects:  70% (362/516)
remote: Counting objects:  71% (367/516)
remote: Counting objects:  72% (372/516)
remote: Counting objects:  73% (377/516)
remote: Counting objects:  74% (382/516)
remote: Counting objects:  75% (387/516)
remote: Counting objects:  76% (393/516)
remote: Counting objects:  77% (398/516)
remote: Counting objects:  78% (403/516)
remote: Counting objects:  79% (408/516)
remote: Counting objects:  80% (413/516)
remote: Counting objects:  81% (418/516)
remote: Counting objects:  82% (424/516)
remote: Counting objects:  83% (429/516)
remote: Counting objects:  84% (434/516)
remote: Counting objects:  85% (439/516)
remote: Counting objects:  86% (444/516)
remote: Counting objects:  87% (449/516)
remote: Counting objects:  88% (455/516)
remote: Counting objects:  89% (460/516)
remote: Counting objects:  90% (465/516)
remote: Counting objects:  91% (470/516)
remote: Counting objects:  92% (475/516)
remote: Counting objects:  93% (480/516)
remote: Counting objects:  94% (486/516)
remote: Counting objects:  95% (491/516)
remote: Counting objects:  96% (496/516)
remote: Counting objects:  97% (501/516)
remote: Counting objects:  98% (506/516)
remote: Counting objects:  99% (511/516)
remote: Counting objects: 100% (516/516)
remote: Counting objects: 100% (516/516), done.
remote: Compressing objects:   0% (1/254)
remote: Compressing objects:   1% (3/254)
remote: Compressing objects:   2% (6/254)
remote: Compressing objects:   3% (8/254)
remote: Compressing objects:   4% (11/254)
remote: Compressing objects:   5% (13/254)
remote: Compressing objects:   6% (16/254)
remote: Compressing objects:   7% (18/254)
remote: Compressing objects:   8% (21/254)
remote: Compressing objects:   9% (23/254)
remote: Compressing objects:  10% (26/254)
remote: Compressing objects:  11% (28/254)
remote: Compressing objects:  12% (31/254)
remote: Compressing objects:  13% (34/254)
remote: Compressing objects:  14% (36/254)
remote: Compressing objects:  15% (39/254)
remote: Compressing objects:  16% (41/254)
remote: Compressing objects:  17% (44/254)
remote: Compressing objects:  18% (46/254)
remote: Compressing objects:  19% (49/254)
remote: Compressing objects:  20% (51/254)
remote: Compressing objects:  21% (54/254)
remote: Compressing objects:  22% (56/254)
remote: Compressing objects:  23% (59/254)
remote: Compressing objects:  24% (61/254)
remote: Compressing objects:  25% (64/254)
remote: Compressing objects:  26% (67/254)
remote: Compressing objects:  27% (69/254)
remote: Compressing objects:  28% (72/254)
remote: Compressing objects:  29% (74/254)
remote: Compressing objects:  30% (77/254)
remote: Compressing objects:  31% (79/254)
remote: Compressing objects:  32% (82/254)
remote: Compressing objects:  33% (84/254)
remote: Compressing objects:  34% (87/254)
remote: Compressing objects:  35% (89/254)
remote: Compressing objects:  36% (92/254)
remote: Compressing objects:  37% (94/254)
remote: Compressing objects:  38% (97/254)
remote: Compressing objects:  39% (100/254)
remote: Compressing objects:  40% (102/254)
remote: Compressing objects:  41% (105/254)
remote: Compressing objects:  42% (107/254)
remote: Compressing objects:  43% (110/254)
remote: Compressing objects:  44% (112/254)
remote: Compressing objects:  45% (115/254)
remote: Compressing objects:  46% (117/254)
remote: Compressing objects:  47% (120/254)
remote: Compressing objects:  48% (122/254)
remote: Compressing objects:  49% (125/254)
remote: Compressing objects:  50% (127/254)
remote: Compressing objects:  51% (130/254)
remote: Compressing objects:  52% (133/254)
remote: Compressing objects:  53% (135/254)
remote: Compressing objects:  54% (138/254)
remote: Compressing objects:  55% (140/254)
remote: Compressing objects:  56% (143/254)
remote: Compressing objects:  57% (145/254)
remote: Compressing objects:  58% (148/254)
remote: Compressing objects:  59% (150/254)
remote: Compressing objects:  60% (153/254)
remote: Compressing objects:  61% (155/254)
remote: Compressing objects:  62% (158/254)
remote: Compressing objects:  63% (161/254)
remote: Compressing objects:  64% (163/254)
remote: Compressing objects:  65% (166/254)
remote: Compressing objects:  66% (168/254)
remote: Compressing objects:  67% (171/254)
remote: Compressing objects:  68% (173/254)
remote: Compressing objects:  69% (176/254)
remote: Compressing objects:  70% (178/254)
remote: Compressing objects:  71% (181/254)
remote: Compressing objects:  72% (183/254)
remote: Compressing objects:  73% (186/254)
remote: Compressing objects:  74% (188/254)
remote: Compressing objects:  75% (191/254)
remote: Compressing objects:  76% (194/254)
remote: Compressing objects:  77% (196/254)
remote: Compressing objects:  78% (199/254)
remote: Compressing objects:  79% (201/254)
remote: Compressing objects:  80% (204/254)
remote: Compressing objects:  81% (206/254)
remote: Compressing objects:  82% (209/254)
remote: Compressing objects:  83% (211/254)
remote: Compressing objects:  84% (214/254)
remote: Compressing objects:  85% (216/254)
remote: Compressing objects:  86% (219/254)
remote: Compressing objects:  87% (221/254)
remote: Compressing objects:  88% (224/254)
remote: Compressing objects:  89% (227/254)
remote: Compressing objects:  90% (229/254)
remote: Compressing objects:  91% (232/254)
remote: Compressing objects:  92% (234/254)
remote: Compressing objects:  93% (237/254)
remote: Compressing objects:  94% (239/254)
remote: Compressing objects:  95% (242/254)
remote: Compressing objects:  96% (244/254)
remote: Compressing objects:  97% (247/254)
remote: Compressing objects:  98% (249/254)
remote: Compressing objects:  99% (252/254)
remote: Compressing objects: 100% (254/254)
remote: Compressing objects: 100% (254/254), done.
Receiving objects:   0% (1/516)
Receiving objects:   1% (6/516)
Receiving objects:   2% (11/516)
Receiving objects:   3% (16/516)
Receiving objects:   4% (21/516)
Receiving objects:   5% (26/516)
Receiving objects:   6% (31/516)
Receiving objects:   7% (37/516)
Receiving objects:   8% (42/516)
Receiving objects:   9% (47/516)
Receiving objects:  10% (52/516)
Receiving objects:  11% (57/516)
Receiving objects:  12% (62/516)
Receiving objects:  13% (68/516)
Receiving objects:  14% (73/516)
Receiving objects:  15% (78/516)
Receiving objects:  16% (83/516)
Receiving objects:  17% (88/516)
Receiving objects:  18% (93/516)
Receiving objects:  19% (99/516)
Receiving objects:  20% (104/516)
Receiving objects:  21% (109/516)
Receiving objects:  22% (114/516)
Receiving objects:  23% (119/516)
Receiving objects:  24% (124/516)
Receiving objects:  25% (129/516)
Receiving objects:  26% (135/516)
Receiving objects:  27% (140/516)
Receiving objects:  28% (145/516)
Receiving objects:  29% (150/516)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Receiving objects:  30% (155/516)
Receiving objects:  31% (160/516)
Receiving objects:  32% (166/516)
Receiving objects:  33% (171/516)
Receiving objects:  34% (176/516)
Receiving objects:  35% (181/516)
Receiving objects:  36% (186/516)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Receiving objects:  37% (191/516)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Receiving objects:  38% (197/516)
Receiving objects:  39% (202/516)
Receiving objects:  40% (207/516)
Receiving objects:  41% (212/516)
Receiving objects:  42% (217/516)
Receiving objects:  43% (222/516)
Receiving objects:  44% (228/516)
Receiving objects:  45% (233/516)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Receiving objects:  46% (238/516)
Receiving objects:  47% (243/516)
Receiving objects:  48% (248/516)
Receiving objects:  49% (253/516)
Receiving objects:  50% (258/516)
Receiving objects:  51% (264/516)
Receiving objects:  52% (269/516)
Receiving objects:  53% (274/516)
Receiving objects:  54% (279/516)
Receiving objects:  55% (284/516)
Receiving objects:  56% (289/516)
Receiving objects:  57% (295/516)
Receiving objects:  58% (300/516)
Receiving objects:  59% (305/516)
Receiving objects:  60% (310/516)
Receiving objects:  61% (315/516)
Receiving objects:  62% (320/516)
Receiving objects:  63% (326/516)
Receiving objects:  64% (331/516)
Receiving objects:  65% (336/516)
Receiving objects:  66% (341/516)
Receiving objects:  67% (346/516)
Receiving objects:  68% (351/516)
Receiving objects:  69% (357/516)
Receiving objects:  70% (362/516)
Receiving objects:  71% (367/516)
Receiving objects:  72% (372/516)
Receiving objects:  73% (377/516)
Receiving objects:  74% (382/516)
Receiving objects:  75% (387/516)
Receiving objects:  76% (393/516)
Receiving objects:  77% (398/516)
Receiving objects:  78% (403/516)
Receiving objects:  79% (408/516)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>remote: Total 516 (delta 285), reused 460 (delta 252), pack-reused 0
Receiving objects:  80% (413/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  81% (418/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  82% (424/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  83% (429/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  84% (434/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  85% (439/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  86% (444/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  87% (449/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  88% (455/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  89% (460/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  90% (465/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  91% (470/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  92% (475/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  93% (480/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  94% (486/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  95% (491/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  96% (496/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  97% (501/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  98% (506/516), 26.54 MiB | 53.17 MiB/s
Receiving objects:  99% (511/516), 26.54 MiB | 53.17 MiB/s
Receiving objects: 100% (516/516), 26.54 MiB | 53.17 MiB/s
Receiving objects: 100% (516/516), 27.94 MiB | 53.17 MiB/s, done.
Resolving deltas:   0% (0/285)
Resolving deltas:   1% (3/285)
Resolving deltas:   2% (6/285)
Resolving deltas:   3% (9/285)
Resolving deltas:   4% (12/285)
Resolving deltas:   5% (15/285)
Resolving deltas:   6% (18/285)
Resolving deltas:   7% (20/285)
Resolving deltas:   8% (23/285)
Resolving deltas:   9% (26/285)
Resolving deltas:  10% (29/285)
Resolving deltas:  11% (32/285)
Resolving deltas:  12% (35/285)
Resolving deltas:  13% (38/285)
Resolving deltas:  14% (40/285)
Resolving deltas:  15% (43/285)
Resolving deltas:  16% (46/285)
Resolving deltas:  17% (49/285)
Resolving deltas:  18% (52/285)
Resolving deltas:  19% (55/285)
Resolving deltas:  20% (57/285)
Resolving deltas:  21% (60/285)
Resolving deltas:  22% (63/285)
Resolving deltas:  23% (66/285)
Resolving deltas:  24% (69/285)
Resolving deltas:  25% (72/285)
Resolving deltas:  26% (75/285)
Resolving deltas:  27% (77/285)
Resolving deltas:  28% (80/285)
Resolving deltas:  29% (83/285)
Resolving deltas:  30% (86/285)
Resolving deltas:  31% (89/285)
Resolving deltas:  32% (92/285)
Resolving deltas:  33% (95/285)
Resolving deltas:  34% (97/285)
Resolving deltas:  35% (100/285)
Resolving deltas:  36% (103/285)
Resolving deltas:  37% (106/285)
Resolving deltas:  38% (109/285)
Resolving deltas:  39% (112/285)
Resolving deltas:  40% (114/285)
Resolving deltas:  41% (117/285)
Resolving deltas:  42% (120/285)
Resolving deltas:  43% (123/285)
Resolving deltas:  44% (126/285)
Resolving deltas:  45% (129/285)
Resolving deltas:  46% (132/285)
Resolving deltas:  47% (134/285)
Resolving deltas:  48% (137/285)
Resolving deltas:  49% (140/285)
Resolving deltas:  50% (143/285)
Resolving deltas:  51% (146/285)
Resolving deltas:  52% (149/285)
Resolving deltas:  53% (152/285)
Resolving deltas:  54% (154/285)
Resolving deltas:  55% (157/285)
Resolving deltas:  56% (160/285)
Resolving deltas:  57% (163/285)
Resolving deltas:  58% (166/285)
Resolving deltas:  59% (169/285)
Resolving deltas:  60% (171/285)
Resolving deltas:  61% (174/285)
Resolving deltas:  62% (177/285)
Resolving deltas:  63% (180/285)
Resolving deltas:  64% (183/285)
Resolving deltas:  65% (186/285)
Resolving deltas:  66% (189/285)
Resolving deltas:  67% (191/285)
Resolving deltas:  68% (194/285)
Resolving deltas:  69% (197/285)
Resolving deltas:  70% (200/285)
Resolving deltas:  71% (203/285)
Resolving deltas:  72% (206/285)
Resolving deltas:  73% (209/285)
Resolving deltas:  74% (211/285)
Resolving deltas:  75% (214/285)
Resolving deltas:  76% (217/285)
Resolving deltas:  77% (220/285)
Resolving deltas:  78% (223/285)
Resolving deltas:  79% (226/285)
Resolving deltas:  80% (228/285)
Resolving deltas:  81% (231/285)
Resolving deltas:  82% (234/285)
Resolving deltas:  83% (237/285)
Resolving deltas:  84% (240/285)
Resolving deltas:  85% (243/285)
Resolving deltas:  86% (246/285)
Resolving deltas:  87% (248/285)
Resolving deltas:  88% (251/285)
Resolving deltas:  89% (254/285)
Resolving deltas:  90% (257/285)
Resolving deltas:  91% (260/285)
Resolving deltas:  92% (263/285)
Resolving deltas:  93% (266/285)
Resolving deltas:  94% (268/285)
Resolving deltas:  95% (271/285)
Resolving deltas:  96% (274/285)
Resolving deltas:  97% (277/285)
Resolving deltas:  98% (280/285)
Resolving deltas:  99% (283/285)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Resolving deltas: 100% (285/285)
Resolving deltas: 100% (285/285), done.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Updating files:  73% (28/38)
Updating files:  76% (29/38)
Updating files:  78% (30/38)
Updating files:  81% (31/38)
Updating files:  84% (32/38)
Updating files:  86% (33/38)
Updating files:  89% (34/38)
Updating files:  92% (35/38)
Updating files:  94% (36/38)
Updating files:  97% (37/38)
Updating files: 100% (38/38)
Updating files: 100% (38/38), done.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/work/NeuroAI_Course/NeuroAI_Course/tutorials/W2D5_Mysteries/student/RIMs-Sequential-MNIST
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LSTM model already exists. No download needed.
RIM model already exists. No download needed.
</pre></div>
</div>
</div>
</div>
</section>
<section id="rims">
<h3>RIMs<a class="headerlink" href="#rims" title="Permalink to this heading">#</a></h3>
<p>In this example, a RIM model was trained using a version of the MNIST dataset, where each image of a handwritten digit was resized to 14x14 pixels. The MNIST dataset is commonly used in the field of machine learning for training models to recognize handwritten digits. Typically, these images are 28x28 pixels, but in this case, they have been made smaller.</p>
<p>After training, the goal was to evaluate how well the model could apply what it learned to new situations - in other words, how well it could generalize. To test this, the model was not just used on other 14x14 images, but on larger images of sizes 16x16, 19x19, and 24x24 pixels. These different sizes were used in separate validation sets: 16x16 images were in Validation Set 3, 19x19 images in Validation Set 2, and 24x24 images again in Validation Set 3.</p>
<p>This approach helps to understand whether the model can still recognize the digits accurately even when they appear at different scales or resolutions than what it was originally trained on. By testing the model on various image sizes, we can see how flexible and effective the model is at dealing with variations in input data, which is crucial for its application in real-world scenarios where data might not always be uniform.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Config</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'cuda'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'hidden_size'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'input_size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'model'</span><span class="p">:</span> <span class="s1">'RIM'</span><span class="p">,</span> <span class="c1"># Or 'RIM' for the MnistModel</span>
    <span class="s1">'train'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># Set to False to load the saved model</span>
    <span class="s1">'num_units'</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
    <span class="s1">'rnn_cell'</span><span class="p">:</span> <span class="s1">'LSTM'</span><span class="p">,</span>
    <span class="s1">'key_size_input'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'value_size_input'</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s1">'query_size_input'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'num_input_heads'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'num_comm_heads'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">'input_dropout'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s1">'comm_dropout'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s1">'key_size_comm'</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s1">'value_size_comm'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'query_size_comm'</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s1">'k'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">'size'</span><span class="p">:</span> <span class="mi">14</span><span class="p">,</span>
    <span class="s1">'loadsaved'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># Ensure this is 1 to load saved model</span>
    <span class="s1">'log_dir'</span><span class="p">:</span> <span class="s1">'rim_model_dir'</span>
<span class="p">}</span>

<span class="c1"># Choose the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MnistModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># Instantiating MnistModel (RIM) with config</span>
<span class="n">model_directory</span> <span class="o">=</span> <span class="n">model_path</span><span class="p">[</span><span class="s1">'RIM'</span><span class="p">]</span>

<span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Set the map_location based on whether CUDA is available</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">config</span><span class="p">[</span><span class="s1">'cuda'</span><span class="p">]</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="c1"># Use torch.load with the map_location parameter</span>
<span class="n">saved</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_directory</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">saved</span><span class="p">[</span><span class="s1">'net'</span><span class="p">])</span>

<span class="c1"># Data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">MnistData</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">],</span> <span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'size'</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s1">'size'</span><span class="p">]),</span> <span class="n">config</span><span class="p">[</span><span class="s1">'k'</span><span class="p">])</span>

<span class="c1"># Evaluation function</span>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total validation samples: </span><span class="si">{</span><span class="n">loader</span><span class="o">.</span><span class="n">val_len</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  <span class="c1"># Print total number of validation samples</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">val_len</span><span class="p">())):</span>
            <span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">test_x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
            <span class="n">test_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">test_y</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">probs</span>  <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">preds</span> <span class="o">==</span> <span class="n">test_y</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="n">correct</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">/=</span> <span class="mi">100</span>  <span class="c1"># Use the total number of items in the validation set for accuracy calculation</span>
    <span class="k">return</span> <span class="n">accuracy</span>


<span class="c1"># Evaluate on all three validation sets</span>
<span class="n">validation_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">val_get1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">val_get2</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">val_get3</span><span class="p">]</span>
<span class="n">validation_accuracies_rim</span> <span class="o">=</span> <span class="p">[]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'model'</span><span class="p">]</span><span class="si">}</span><span class="s2">, Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Configuration: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">validation_functions</span><span class="p">:</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
    <span class="n">validation_accuracies_rim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU is not enabled in this notebook. 
If you want to enable it, in the menu under `Runtime` -&gt; 
`Hardware accelerator.` and select `GPU` from the dropdown menu
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: RIM, Device: cpu
Configuration: {'cuda': True, 'epochs': 200, 'batch_size': 64, 'hidden_size': 100, 'input_size': 1, 'model': 'RIM', 'train': False, 'num_units': 6, 'rnn_cell': 'LSTM', 'key_size_input': 64, 'value_size_input': 400, 'query_size_input': 64, 'num_input_heads': 1, 'num_comm_heads': 4, 'input_dropout': 0.1, 'comm_dropout': 0.1, 'key_size_comm': 32, 'value_size_comm': 100, 'query_size_comm': 32, 'k': 4, 'size': 14, 'loadsaved': 1, 'log_dir': 'rim_model_dir'}
Total validation samples: 20
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total validation samples: 20
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total validation samples: 20
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">76</span>
<span class="g g-Whitespace">     </span><span class="mi">73</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Configuration: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">75</span> <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">validation_functions</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">76</span>     <span class="n">accuracy</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">77</span>     <span class="n">validation_accuracies_rim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

<span class="nn">Cell In[10], line 59,</span> in <span class="ni">test_model</span><span class="nt">(model, loader, func)</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">test_y</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">59</span> <span class="n">probs</span>  <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span> <span class="n">correct</span> <span class="o">=</span> <span class="n">preds</span> <span class="o">==</span> <span class="n">test_y</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1532,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1531</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1532</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1541,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1536</span> <span class="c1"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1537</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1538</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1539</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1540</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1541</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1543</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1544</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/work/NeuroAI_Course/NeuroAI_Course/tutorials/W2D5_Mysteries/student/RIMs-Sequential-MNIST/networks.py:32,</span> in <span class="ni">MnistModel.forward</span><span class="nt">(self, x, y)</span>
<span class="g g-Whitespace">     </span><span class="mi">30</span> <span class="c1"># pass through RIMCell for all timesteps</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">32</span> 	<span class="n">hs</span><span class="p">,</span> <span class="n">cs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rim_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">cs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">33</span> <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span> <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">35</span> 	<span class="c1"># Compute Loss</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1532,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1531</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1532</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1541,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1536</span> <span class="c1"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1537</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1538</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1539</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1540</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1541</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1543</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1544</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/work/NeuroAI_Course/NeuroAI_Course/tutorials/W2D5_Mysteries/student/RIMs-Sequential-MNIST/RIM.py:233,</span> in <span class="ni">RIMCell.forward</span><span class="nt">(self, x, hs, cs)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="c1"># Compute RNN(LSTM or GRU) output</span>
<span class="g g-Whitespace">    </span><span class="mi">232</span> <span class="k">if</span> <span class="n">cs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">233</span> 	<span class="n">hs</span><span class="p">,</span> <span class="n">cs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">cs</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">234</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span> 	<span class="n">hs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1532,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1531</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1532</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1541,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1536</span> <span class="c1"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1537</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1538</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1539</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1540</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1541</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1543</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1544</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/work/NeuroAI_Course/NeuroAI_Course/tutorials/W2D5_Mysteries/student/RIMs-Sequential-MNIST/RIM.py:52,</span> in <span class="ni">GroupLSTMCell.forward</span><span class="nt">(self, x, hid_state)</span>
<span class="g g-Whitespace">     </span><span class="mi">45</span><span class="w"> </span><span class="sd">"""</span>
<span class="g g-Whitespace">     </span><span class="mi">46</span><span class="sd"> input: x (batch_size, num_lstms, input_size)</span>
<span class="g g-Whitespace">     </span><span class="mi">47</span><span class="sd"> 	   hid_state (tuple of length 2 with each element of size (batch_size, num_lstms, hidden_state))</span>
<span class="g g-Whitespace">     </span><span class="mi">48</span><span class="sd"> output: h (batch_size, num_lstms, hidden_state)</span>
<span class="g g-Whitespace">     </span><span class="mi">49</span><span class="sd"> 		c ((batch_size, num_lstms, hidden_state))</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span><span class="sd"> """</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">hid_state</span>
<span class="ne">---&gt; </span><span class="mi">52</span> <span class="n">preact</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">i2h</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">h2h</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span> <span class="n">gates</span> <span class="o">=</span> <span class="n">preact</span><span class="p">[:,</span> <span class="p">:,</span>  <span class="p">:</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">]</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">55</span> <span class="n">g_t</span> <span class="o">=</span> <span class="n">preact</span><span class="p">[:,</span> <span class="p">:,</span>  <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">:]</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1532,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1531</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1532</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/nn/modules/module.py:1541,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1536</span> <span class="c1"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1537</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1538</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1539</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1540</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1541</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1543</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1544</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/work/NeuroAI_Course/NeuroAI_Course/tutorials/W2D5_Mysteries/student/RIMs-Sequential-MNIST/RIM.py:23,</span> in <span class="ni">GroupLinearLayer.forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>     <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">23</span>     <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span>     <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="lstm">
<h3>LSTM<a class="headerlink" href="#lstm" title="Permalink to this heading">#</a></h3>
<p>Let’s now repeat the same process with LSTMs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Config</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'cuda'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'hidden_size'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'input_size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'model'</span><span class="p">:</span> <span class="s1">'LSTM'</span><span class="p">,</span>
    <span class="s1">'train'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># Set to False to load the saved model</span>
    <span class="s1">'num_units'</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
    <span class="s1">'rnn_cell'</span><span class="p">:</span> <span class="s1">'LSTM'</span><span class="p">,</span>
    <span class="s1">'key_size_input'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'value_size_input'</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s1">'query_size_input'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'num_input_heads'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'num_comm_heads'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">'input_dropout'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s1">'comm_dropout'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s1">'key_size_comm'</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s1">'value_size_comm'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'query_size_comm'</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s1">'k'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">'size'</span><span class="p">:</span> <span class="mi">14</span><span class="p">,</span>
    <span class="s1">'loadsaved'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># Ensure this is 1 to load saved model</span>
    <span class="s1">'log_dir'</span><span class="p">:</span> <span class="s1">'rim_model_dir'</span>
<span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># Instantiating LSTM with config</span>
<span class="n">model_directory</span> <span class="o">=</span> <span class="n">model_path</span><span class="p">[</span><span class="s1">'LSTM'</span><span class="p">]</span>

<span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Set the map_location based on whether CUDA is available</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">config</span><span class="p">[</span><span class="s1">'cuda'</span><span class="p">]</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="c1"># Use torch.load with the map_location parameter</span>
<span class="n">saved</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_directory</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">saved</span><span class="p">[</span><span class="s1">'net'</span><span class="p">])</span>

<span class="c1"># Data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">MnistData</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">],</span> <span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'size'</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s1">'size'</span><span class="p">]),</span> <span class="n">config</span><span class="p">[</span><span class="s1">'k'</span><span class="p">])</span>

<span class="c1"># Evaluation function</span>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total validation samples: </span><span class="si">{</span><span class="n">loader</span><span class="o">.</span><span class="n">val_len</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  <span class="c1"># Print total number of validation samples</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">val_len</span><span class="p">())):</span>
            <span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">test_x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
            <span class="n">test_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">test_y</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">probs</span>  <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">preds</span> <span class="o">==</span> <span class="n">test_y</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="n">correct</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">/=</span> <span class="mi">100</span>  <span class="c1"># Use the total number of items in the validation set for accuracy calculation</span>
    <span class="k">return</span> <span class="n">accuracy</span>


<span class="c1"># Evaluate on all three validation sets</span>
<span class="n">validation_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">val_get1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">val_get2</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">val_get3</span><span class="p">]</span>
<span class="n">validation_accuracies_lstm</span> <span class="o">=</span> <span class="p">[]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'model'</span><span class="p">]</span><span class="si">}</span><span class="s2">, Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Configuration: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">validation_functions</span><span class="p">:</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
    <span class="n">validation_accuracies_lstm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print accuracies for all validation sets (RIMs)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">accuracy</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">validation_accuracies_rim</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Validation Set </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> Accuracy (RIMs): </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

<span class="c1"># Print accuracies for all validation sets (LSTM)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">accuracy</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">validation_accuracies_lstm</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Validation Set </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> Accuracy (LSTM): </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The accuracy of the model on 16x16 images is fairly close to what was observed on smaller images, indicating that the increase in size to 16x16 does not significantly impact the model’s ability to recognize the images. However, the model demonstrates much stronger performance, or generalizes better, when working with the larger 19x19 and 24x24 images.</p>
</section>
<section id="discussion-point">
<h3>Discussion point<a class="headerlink" href="#discussion-point" title="Permalink to this heading">#</a></h3>
<p>Why do you think this happened?</p>
</section>
<section id="hint">
<h3>Hint<a class="headerlink" href="#hint" title="Permalink to this heading">#</a></h3>
<p>To understand why this improvement occurs, consider how RIMs are designed. These networks are built as a collection of modules, each functioning independently. They don’t continuously interact with each other; instead, they primarily operate separately and only occasionally connect through a mechanism known as “attention.” This attention mechanism allows a module to focus on specific, relevant parts of the input data when necessary.</p>
<p>Because each module in a RIM can focus on learning different features or aspects of the data, it becomes very adaptable. For instance, one module might become specialized in recognizing edges, another in textures, and so on. When the model encounters a new environment or different image sizes, like 19x19 or 24x24, each module uses its specialized knowledge to handle the changes in its specific area. This modular and focused approach allows RIMs to maintain or even improve performance across varied conditions, demonstrating what we refer to as robust generalization. This means that the model is not only good at performing the task it was specifically trained for but also adapts well to new, slightly different tasks or conditions.</p>
</section>
<section id="rims-and-consciousness">
<h3>RIMs and consciousness<a class="headerlink" href="#rims-and-consciousness" title="Permalink to this heading">#</a></h3>
<p>You might wonder how RIMs relate to consciousness. As we have seen, RIMs focus on modularity in neural processing. In this approach, various modules or units operate semi-independently but coordinate through a mechanism akin to attention. This modularity allows the system to specialize in different tasks, with the attention mechanism directing computational resources efficiently by focusing on the most relevant parts of a problem at any given time. When it comes to humans, the theory that semi-independent modules are foundational for human consciousness is rooted in the concept of modular organization within the brain. This idea posits that consciousness emerges from the interaction of various specialized, yet relatively independent, neural circuits or modules. Each of these modules processes specific types of information or performs distinct cognitive functions. The integration of their activities leads to a unified conscious experience. Such a system is believed to be the foundation of one of the most popular theories of consciosness, namely the Global Workspace Thory.</p>
</section>
</section>
<hr class="docutils"/>
<section id="section-1b-a-shared-workspace">
<h2>Section 1b: A Shared Workspace<a class="headerlink" href="#section-1b-a-shared-workspace" title="Permalink to this heading">#</a></h2>
<p>In this section, we explore an advanced model in deep learning that builds on the idea of using structured, specialized modules to improve how the system scales and generalizes. This approach takes inspiration from two sources: the 1980s focus on modular architectures in AI and the Global Workspace Theory from cognitive neuroscience. You can read more about this model in the linked research paper here (https://arxiv.org/pdf/2103.01197.pdf).</p>
<p>The core idea behind this model is the use of a “shared global workspace” which serves as a coordination platform for the various specialized modules within the network. This setup enhances the model’s flexibility and its ability to generalize systematically, which means it can apply learned knowledge to new, unseen tasks more effectively. Essentially, the model incorporates multiple specialist modules, each focusing on different aspects of a problem, but these modules do not communicate directly with each other very often. Instead, they interact through a central shared memory, which helps the entire system work together cohesively and efficiently.</p>
<p><img alt="Picture which shows how a shared workspace mechanism works." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D5_Mysteries/static/Shared_Workspace.png?raw=true"/></p>
<p>Recurrent Independent Mechanisms (RIMs) typically use a self-attention mechanism to facilitate information exchange among specialist modules. Normally, this involves modules paying attention to one another in pairs—each module checks in with every other module. However, the new model changes this dynamic by introducing a shared workspace with a limited capacity. This change is designed to make interactions more efficient: at each step in the computation, the specialist modules compete for a chance to write their information into this global workspace. Once the information is stored, it is then broadcasted back out to all the modules simultaneously. This method eliminates the need for each module to communicate individually with every other module, streamlining the entire process and improving how information flows throughout the system.</p>
<p>By centralizing communication this way, the model mimics how a human brain might focus only on the most relevant information at any given time, improving both performance and efficiency in complex tasks. This approach allows for better coordination among the modules and enhances the overall effectiveness of the model in handling a variety of challenges.</p>
<p>RIMs leverage a self-attention mechanism to enable information sharing among specialist modules, traditionally through pairwise interactions where each module attends to every other. This new approach, however, introduces a shared workspace with limited capacity to streamline this process. At each computational step, specialist modules compete for the opportunity to write to this shared workspace. Subsequently, the information stored in the workspace is broadcasted to all specialists simultaneously, enhancing coordination and information flow among the modules without the need for direct pairwise communication.</p>
<section id="coding-exercise-creating-a-shared-workspace">
<h3>Coding Exercise: Creating a Shared Workspace<a class="headerlink" href="#coding-exercise-creating-a-shared-workspace" title="Permalink to this heading">#</a></h3>
<p>In our model, the interaction among the modules (or specialists) and the shared workspace is managed by what is known as a key-query-value attention mechanism. This mechanism is crucial for determining how the modules interact with the shared workspace. Here’s how it works:</p>
<ul class="simple">
<li><p>Key: Each specialist module generates a “key,” which can be thought of as a type of identifier that represents the type of information the module wants to share.</p></li>
<li><p>Query: The workspace generates a “query” for each computational step. This query represents the workspace’s current informational needs—essentially, what it needs to know next to facilitate the overall task.</p></li>
<li><p>Value: Each specialist also prepares a “value,” which is the actual information it proposes to add to the workspace.</p></li>
</ul>
<p>At each computational step, each specialist generates a key based on the information it processes and a value that it wants to store in the workspace. Simultaneously, the workspace issues a query reflecting its current needs. The keys from each specialist are compared to the query, and attention scores are computed. These scores assess the relevance of the information each specialist holds in relation to what the workspace needs at that moment. Specialists with the highest attention scores get to update the workspace with their values. This ensures that the most relevant information at any given time is prioritized for storage and further processing.</p>
<p>This dynamic process of competition and selection via the attention mechanism allows the model to focus on the most pertinent information, enhancing efficiency and decision-making capabilities. It mimics a sort of “cognitive economy,” where only the most relevant data is processed and shared among modules, reducing redundancy and enhancing the overall performance of the system. Moreover, this theory is directly linked to theories of consciousness in neuroscience. It suggests that consciousness arises from the ability of various brain processes to access a shared information platform.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># Ensure reproducibility</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SharedWorkspace</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_specialists</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_memory_slots</span><span class="p">,</span> <span class="n">memory_slot_dim</span><span class="p">):</span>
        <span class="c1">#################################################</span>
        <span class="c1">## TODO for students: fill in the missing variables ##</span>
        <span class="c1"># Fill out function and remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
        <span class="c1">#################################################</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_specialists</span> <span class="o">=</span> <span class="n">num_specialists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_memory_slots</span> <span class="o">=</span> <span class="n">num_memory_slots</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory_slot_dim</span> <span class="o">=</span> <span class="n">memory_slot_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">workspace_memory</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_memory_slots</span><span class="p">,</span> <span class="n">memory_slot_dim</span><span class="p">))</span>

        <span class="c1"># Attention mechanism components for writing to the workspace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">memory_slot_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">write_to_workspace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">specialists_states</span><span class="p">):</span>
        <span class="c1">#################################################</span>
        <span class="c1">## TODO for students: fill in the missing variables ##</span>
        <span class="c1"># Fill out function and remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
        <span class="c1">#################################################</span>
        <span class="c1"># Flatten specialists' states if they're not already</span>
        <span class="n">specialists_states</span> <span class="o">=</span> <span class="n">specialists_states</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>

        <span class="c1"># Compute key, query, and value</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">specialists_states</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">workspace_memory</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">specialists_states</span><span class="p">)</span>

        <span class="c1"># Compute attention scores and apply softmax</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory_slot_dim</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">attention_probs</span> <span class="o">=</span> <span class="o">...</span>

        <span class="c1"># Update workspace memory with weighted sum of values</span>
        <span class="n">updated_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">workspace_memory</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">updated_memory</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">workspace_memory</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">specialists_states</span><span class="p">):</span>
        <span class="c1">#################################################</span>
        <span class="c1">## TODO for students: fill in the missing variables ##</span>
        <span class="c1"># Fill out function and remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
        <span class="c1">#################################################</span>
        <span class="n">updated_memory</span> <span class="o">=</span> <span class="o">...</span>
        <span class="k">return</span> <span class="n">updated_memory</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D5_Mysteries/solutions/W2D5_Tutorial1_Solution_e6fdb078.py"><em>Click for solution</em></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example parameters</span>
<span class="n">num_specialists</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_memory_slots</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">memory_slot_dim</span> <span class="o">=</span> <span class="mi">6</span>

<span class="c1"># Generate deterministic specialists' states</span>
<span class="n">specialists_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_specialists</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

<span class="n">workspace</span> <span class="o">=</span> <span class="n">SharedWorkspace</span><span class="p">(</span><span class="n">num_specialists</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_memory_slots</span><span class="p">,</span> <span class="n">memory_slot_dim</span><span class="p">)</span>
<span class="n">expected_output</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">specialists_states</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Expected Output:"</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After updating the shared workspace with the most critical signals, this information is then broadcast back to all specialists. Each specialist updates its state using this broadcast information, which can involve an attention mechanism for consolidation and an update function (like an LSTM or GRU step) based on the new combined state. Let’s add this method!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">broadcast_from_workspace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">specialists_states</span><span class="p">):</span>
    <span class="c1"># Broadcast updated memory to specialists</span>
    <span class="n">broadcast_query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">specialists_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_specialists</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_slot_dim</span><span class="p">)</span>
    <span class="n">broadcast_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">workspace_memory</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_specialists</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute attention scores for broadcasting</span>
    <span class="n">broadcast_attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">broadcast_query</span><span class="p">,</span> <span class="n">broadcast_keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory_slot_dim</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">broadcast_attention_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">broadcast_attention_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Update specialists' states with attention-weighted memory information</span>
    <span class="n">broadcast_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">workspace_memory</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_specialists</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">updated_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">broadcast_attention_probs</span><span class="p">,</span> <span class="n">broadcast_values</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">updated_states</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">specialists_states</span><span class="p">)</span>

<span class="c1"># Assign the method to the class</span>
<span class="n">SharedWorkspace</span><span class="o">.</span><span class="n">broadcast_from_workspace</span> <span class="o">=</span> <span class="n">broadcast_from_workspace</span>
</pre></div>
</div>
</div>
</div>
<p>This approach structures the shared workspace to function in a modular fashion.</p>
</section>
<section id="step-1-aggregation-of-specialist-states">
<h3>Step 1: Aggregation of specialist states<a class="headerlink" href="#step-1-aggregation-of-specialist-states" title="Permalink to this heading">#</a></h3>
<p>Initially, each specialist module in the system processes its own piece of information, creating a representation of what it has learned or observed. This is the first step where all the individual insights from the specialists are prepared to be shared.</p>
</section>
<section id="step-2-competitive-information-update-in-the-shared-workspace">
<h3>Step 2: Competitive information update in the shared workspace<a class="headerlink" href="#step-2-competitive-information-update-in-the-shared-workspace" title="Permalink to this heading">#</a></h3>
<p>Once each specialist has processed its information, this data is then sent to the shared workspace. Here, not all information is treated equally; instead, there’s a competition among specialists to determine whose information is most relevant at that moment. This relevance is decided through an attention mechanism where specialists ‘compete’ to match the current needs (or query) of the workspace. Only the most relevant data, as determined by this competitive process, gets the chance to update the workspace.</p>
</section>
<section id="step-3-broadcasting-updated-information">
<h3>Step 3: Broadcasting updated information<a class="headerlink" href="#step-3-broadcasting-updated-information" title="Permalink to this heading">#</a></h3>
<p>After the shared workspace has been updated with the most pertinent information, this consolidated knowledge is then broadcast back to all the specialists. This means that each specialist receives the updated, aggregated information, allowing them to adjust their actions or processing based on the collective insights of the entire system.</p>
</section>
<section id="dynamic-filtering-and-enhanced-generalization">
<h3>Dynamic filtering and enhanced generalization<a class="headerlink" href="#dynamic-filtering-and-enhanced-generalization" title="Permalink to this heading">#</a></h3>
<p>The whole mechanism allows the system to dynamically filter information based on the current context. This means that at every computational step, the system can prioritize and focus on the most relevant signals, ignoring less pertinent data. Such dynamic filtering enhances the model’s ability to generalize from past experiences. By focusing on the most relevant information, the model can adapt to new situations more effectively, applying learned lessons from similar past contexts.</p>
</section>
<section id="integration-into-a-full-system">
<h3>Integration into a full system<a class="headerlink" href="#integration-into-a-full-system" title="Permalink to this heading">#</a></h3>
<p>To incorporate this structured approach into your model, you would start by setting up the SharedWorkspace within your Recurrent Independent Mechanisms (RIM) architecture. Make sure the initial representations by specialists are processed effectively, then manage their competition and update in the SharedWorkspace, and finally ensure that the updated insights are properly distributed back to each specialist. This integration ensures that the system functions cohesively, enhancing both performance and adaptability.</p>
</section>
</section>
<hr class="docutils"/>
<section id="section-1c-a-toy-model-for-illustrating-gnw">
<h2>Section 1c: a toy model for illustrating GNW<a class="headerlink" href="#section-1c-a-toy-model-for-illustrating-gnw" title="Permalink to this heading">#</a></h2>
<p>Now, we outline a <code class="docutils literal notranslate"><span class="pre">SimpleGNWModel</span></code> class for simulating node activation within a network. It uses an Erdős-Rényi graph to model connections and includes methods to activate nodes, reset the network, and visualize the results. This setup provides an interactive introduction to network dynamics, making it easy to observe how activations spread across a network.</p>
<p>In the network visualization, the colors distinguish between active and inactive nodes. Active nodes are colored green, indicating they have been activated either directly or through their connection to another activated node. Inactive nodes are colored red, showing they have yet to be activated in the simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleGNWModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span> <span class="o">=</span> <span class="n">num_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">erdos_renyi_graph</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">activate_node</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">selected_node</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="n">selected_node</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Simulate global broadcast</span>
        <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">selected_node</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="n">neighbor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">reset_activations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">draw_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">color_map</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'green'</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="k">else</span> <span class="s1">'red'</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="p">]</span>
        <span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">color_map</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Create a GNW model instance</span>
<span class="n">gnw_model</span> <span class="o">=</span> <span class="n">SimpleGNWModel</span><span class="p">()</span>

<span class="c1"># Button to activate a node</span>
<span class="n">activate_button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">'Activate Node'</span><span class="p">)</span>

<span class="c1"># Button to reset activations</span>
<span class="n">reset_button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">'Reset'</span><span class="p">)</span>

<span class="c1"># Output area for the network graph</span>
<span class="n">output_area</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">on_activate_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">output_area</span><span class="p">:</span>
        <span class="n">output_area</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">gnw_model</span><span class="o">.</span><span class="n">activate_node</span><span class="p">()</span>
        <span class="n">gnw_model</span><span class="o">.</span><span class="n">draw_network</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">on_reset_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">output_area</span><span class="p">:</span>
        <span class="n">output_area</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">gnw_model</span><span class="o">.</span><span class="n">reset_activations</span><span class="p">()</span>
        <span class="n">gnw_model</span><span class="o">.</span><span class="n">draw_network</span><span class="p">()</span>

<span class="n">activate_button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_activate_clicked</span><span class="p">)</span>
<span class="n">reset_button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_reset_clicked</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">activate_button</span><span class="p">,</span> <span class="n">reset_button</span><span class="p">,</span> <span class="n">output_area</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>When you click on the “Activate Node” button, the code randomly selects one node in the network and activates it, changing its status to active (if it was inactive). This action also triggers a “global broadcast” effect, meaning that all of the selected node’s immediate neighbors are activated as well. The network visualization then updates to reflect these changes: the activated nodes are colored green, while any nodes that remain inactive are colored red. This process visually demonstrates how activation can spread through a network, highlighting the connections between nodes and the potential influence of a single node’s activation on its neighbors.</p>
</section>
<section id="recap">
<h2>Recap<a class="headerlink" href="#recap" title="Permalink to this heading">#</a></h2>
<p>In these sections, we’ve discussed models like Recurrent Independent Mechanisms (RIMs) and those inspired by cognitive neuroscience’s Global Workspace Theory (GWT). These models are pivotal in advancing AI’s ability to generalize, paralleling how the human brain processes unfamiliar information. This concept is vital in both artificial intelligence and neuroscience, offering a window into the mechanisms of consciousness.</p>
<p>Both RIMs and GWT-inspired models employ a modular design where specialized components coordinate through a central mechanism, enhancing system flexibility, efficiency, and scalability:</p>
<ul class="simple">
<li><p><strong>Flexibility</strong>: Each module adapts swiftly to new inputs, showing a localized response to changes.</p></li>
<li><p><strong>Efficiency</strong>: By centralizing communications, the system processes only pertinent information, reducing overload.</p></li>
<li><p><strong>Scalability</strong>: The system can expand by incorporating additional modules without extensive redesigns.</p></li>
</ul>
<p>These AI frameworks not only pave the way for robust technologies, like autonomous systems and medical diagnostics but also deepen our understanding of consciousness. By mimicking how different parts of the brain might communicate and dominate the global workspace at different times, these models provide insights into how conscious awareness and decision-making could emerge in the brain.</p>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-2-metacognition">
<h1>Section 2: Metacognition<a class="headerlink" href="#section-2-metacognition" title="Permalink to this heading">#</a></h1>
<section id="video">
<h2>Video<a class="headerlink" href="#video" title="Permalink to this heading">#</a></h2>
<section id="video-2">
<h3>Video 2<a class="headerlink" href="#video-2" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
</section>
<section id="section-2a-second-order-model">
<h2>Section 2a: Second order model<a class="headerlink" href="#section-2a-second-order-model" title="Permalink to this heading">#</a></h2>
<p>Blindsight is a neurological phenomenon where individuals with damage to their primary visual cortex can still respond to visual stimuli without consciously perceiving them. To study this, we use a simulated dataset specifically created to mimic the conditions of blindsight. This dataset contains 200 patterns, equally split between two types:</p>
<ul class="simple">
<li><p><strong>Random noise patterns</strong> consist of low activations ranging between 0.0 and 0.02.</p></li>
<li><p><strong>Designed stimuli patterns</strong> - each pattern includes one unit that shows a higher activation level, varying between 0.0 and 1.0.</p></li>
</ul>
<p>This dataset allows us to test various hypotheses concerning how sensory processing and network responses adapt under different conditions of visual impairment.</p>
<p>We have three main testing scenarios, each designed to alter the signal-to-noise ratio to simulate different levels of visual impairment:</p>
<ul class="simple">
<li><p><strong>Suprathreshold stimulus condition</strong>: here, the network is tested against familiar patterns used during training to assess its response to known stimuli.</p></li>
<li><p><strong>Subthreshold stimulus condition</strong>: this condition slightly enhances the noise level, akin to actual blindsight conditions, testing the network’s capability to discern subtle signals.</p></li>
<li><p><strong>Low vision condition</strong>: the intensity of stimuli is decreased in this scenario to evaluate how well the network performs with significantly reduced sensory input.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare your results with the patterns generate below</span>
<span class="n">initialize_global</span><span class="p">()</span>
<span class="n">set_1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">set_2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">set_3</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">set_1</span><span class="p">,</span><span class="s2">"Suprathreshold stimulus"</span><span class="p">)</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">set_2</span><span class="p">,</span><span class="s2">"Subthreshold stimulus"</span><span class="p">)</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">set_3</span><span class="p">,</span><span class="s2">"Low Vision"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first-order network model lays the groundwork for our experiments and is structured as follows:</p>
<ul class="simple">
<li><p>Input layer: consists of 100 units representing either noise or stimulus patterns.</p></li>
<li><p>Hidden layer: includes a 60-unit layer tasked with processing the inputs.</p></li>
<li><p>Output layer: comprises 100 units where the responses to stimuli are recorded.</p></li>
<li><p>Dropout and activation: includes dropout layers to prevent overfitting and a temperature-controlled activation function to fine-tune response sharpness.</p></li>
</ul>
<p>The primary aim of the first-order network is to accurately capture and react to the input patterns, setting a baseline for comparison with more complex models.</p>
<section id="activity-1-developing-a-second-order-network">
<h3>Activity 1: Developing a Second-Order Network<a class="headerlink" href="#activity-1-developing-a-second-order-network" title="Permalink to this heading">#</a></h3>
<p>Your task is to expand upon the first-order network by integrating a second-order network that incorporates a meta-cognitive layer assessing the predictions of the first-order network. This layer introduces a wagering mechanism, where the network “bets” on its confidence in its predictions, enhancing our understanding of network certainty.</p>
<p>These are the steps for completion:</p>
<ol class="arabic simple">
<li><p>Architectural development: grasp the underlying principles of a second-order network and complete the architectural code.</p></li>
<li><p>Performance evaluation: visualize training losses and test the model using provided code, assessing its initial performance.</p></li>
<li><p>Model fine-tuning: leveraging the provided training function, experiment with fine-tuning the model to enhance its accuracy and efficiency.</p></li>
</ol>
<p>The second-order network is structured as a feedforward backpropagation network.</p>
<ul class="simple">
<li><p>Input layer: comprises a 100-unit comparison matrix. This matrix quantifies the discrepancy between each corresponding pair of input and output units from the first-order network. For example, if an input unit and its corresponding output unit have activations of 0.6 and 0.7, respectively, the comparison unit’s activation would be -0.1. This setup essentially encodes the prediction error of the first-order network’s outputs as an input pattern for the second-order network.</p></li>
<li><p>Output layer: consists of two units representing “high” and “low” wagers, indicating the network’s confidence in its predictions. The initial weights for these output units range between 0.0 and 0.1.</p></li>
<li><p>Comparator weights: set to 1.0 for connections from the first-order input layer to the comparison matrix, and -1.0 for connections from the first-order output layer. This configuration emphasizes the differential error as a critical input for the second-order decision-making process.</p></li>
</ul>
<p>The second-order network’s novel approach uses the error generated by the first-order network as a direct input for making decisions—specifically, wagering on the confidence of its outputs. This methodology reflects a meta-cognitive layer of processing, akin to evaluating one’s confidence in their answers or predictions.</p>
<p>By exploring these adjustments, you can optimize the network’s functionality, making it a powerful tool for understanding and simulating complex cognitive phenomena like blindsight.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SecondOrderNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_gelu</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SecondOrderNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Define a linear layer for comparing the difference between input and output of the first-order network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comparison_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="c1"># Linear layer for determining wagers, mapping from 100 features to a single output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wager</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Dropout layer to prevent overfitting by randomly setting input units to 0 with a probability of 0.3 during training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># Select activation function based on the `use_gelu` flag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_gelu</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span>

        <span class="c1"># Additional activation functions for potential use in network operations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Softmax for multi-class classification problems</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span>

        <span class="c1"># Initialize the weights of the network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Uniformly initialize weights for the comparison and wager layers</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">comparison_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wager</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_order_input</span><span class="p">,</span> <span class="n">first_order_output</span><span class="p">):</span>
        <span class="c1">###################################################################</span>
        <span class="c1">## Fill out the following then remove</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Calculate the wager value, applying dropout and sigmoid activation to the output of the wager layer"</span><span class="p">)</span>
        <span class="c1">###################################################################</span>

        <span class="c1"># Calculate the difference between the first-order input and output</span>
        <span class="n">comparison_matrix</span> <span class="o">=</span> <span class="n">first_order_input</span> <span class="o">-</span> <span class="n">first_order_output</span>

        <span class="c1"># Pass the difference through the comparison layer and apply the chosen activation function</span>
        <span class="n">comparison_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">comparison_layer</span><span class="p">(</span><span class="n">comparison_matrix</span><span class="p">)</span>

        <span class="c1"># Calculate the wager value, applying dropout and sigmoid activation to the output of the wager layer</span>
        <span class="n">wager</span> <span class="o">=</span> <span class="o">...</span>

        <span class="k">return</span> <span class="n">wager</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D5_Mysteries/solutions/W2D5_Tutorial1_Solution_ef314cab.py"><em>Click for solution</em></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the architecture, optimizers, loss functions, and schedulers for pre training</span>
<span class="n">hidden</span><span class="o">=</span><span class="mi">60</span>
<span class="n">factor</span><span class="o">=</span><span class="mi">1</span>
<span class="n">gelu</span><span class="o">=</span><span class="kc">False</span>
<span class="n">gam</span><span class="o">=</span><span class="mf">0.99</span>
<span class="n">stepsize</span><span class="o">=</span><span class="mi">1</span>

<span class="n">initialize_global</span><span class="p">()</span>

<span class="c1"># First order network instantiation (defined somewhere else)</span>
<span class="n">first_order_network</span> <span class="o">=</span> <span class="n">FirstOrderNetwork</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span><span class="n">factor</span><span class="p">,</span><span class="n">gelu</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pre_train</span><span class="p">(</span><span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">criterion_1</span><span class="p">,</span> <span class="n">criterion_2</span><span class="p">,</span> <span class="n">optimizer_1</span><span class="p">,</span> <span class="n">optimizer_2</span><span class="p">,</span> <span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">meta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Conducts pre-training for first-order and second-order networks.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - first_order_network (torch.nn.Module): Network for basic input-output mapping.</span>
<span class="sd">    - second_order_network (torch.nn.Module): Network for decision-making based on the first network's output.</span>
<span class="sd">    - criterion_1, criterion_2 (torch.nn): Loss functions for the respective networks.</span>
<span class="sd">    - optimizer_1, optimizer_2 (torch.optim): Optimizers for the respective networks.</span>
<span class="sd">    - scheduler_1, scheduler_2 (torch.optim.lr_scheduler): Schedulers for learning rate adjustment.</span>
<span class="sd">    - factor (float): Parameter influencing data augmentation or pattern generation.</span>
<span class="sd">    - meta (bool): Flag indicating the use of meta-learning strategies.</span>

<span class="sd">    Returns:</span>
<span class="sd">    Tuple containing updated networks and epoch-wise loss records.</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># Generate training patterns and targets for each epoch</span>
        <span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">stim_present_tensor</span><span class="p">,</span> <span class="n">stim_absent_tensor</span><span class="p">,</span> <span class="n">order_2_tensor</span> <span class="o">=</span> <span class="n">Generate_Patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>

        <span class="c1"># Forward pass through the first-order network</span>
        <span class="n">output_first_order</span> <span class="o">=</span> <span class="n">first_order_network</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">)</span>

        <span class="n">optimizer_1</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Conditionally execute the second-order network pass and related operations</span>
        <span class="k">if</span> <span class="n">meta</span><span class="p">:</span>
            <span class="n">optimizer_2</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Forward pass through the second-order network with inputs from the first-order network</span>
            <span class="n">output_second_order</span> <span class="o">=</span> <span class="n">second_order_network</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">output_first_order</span><span class="p">)</span>

            <span class="c1"># Calculate the loss for the second-order network (wagering decision based on comparison)</span>
            <span class="n">loss_2</span> <span class="o">=</span> <span class="n">criterion_2</span><span class="p">(</span><span class="n">output_second_order</span><span class="p">,</span> <span class="n">order_2_tensor</span><span class="p">)</span>

            <span class="c1"># Backpropagate the second-order network's loss</span>
            <span class="n">loss_2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Allows further backpropagation for loss_1 after loss_2</span>

            <span class="c1"># Update second-order network weights</span>
            <span class="n">optimizer_2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">epoch_2_order</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_2</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Skip computations for the second-order network</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="c1"># Potentially forward pass through the second-order network without tracking gradients</span>
                <span class="n">output_second_order</span> <span class="o">=</span> <span class="n">second_order_network</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">output_first_order</span><span class="p">)</span>

        <span class="c1"># Calculate the loss for the first-order network (accuracy of stimulus representation)</span>
        <span class="n">loss_1</span> <span class="o">=</span> <span class="n">criterion_1</span><span class="p">(</span><span class="n">output_first_order</span><span class="p">,</span> <span class="n">stim_present_tensor</span><span class="p">)</span>

        <span class="c1"># Backpropagate the first-order network's loss</span>
        <span class="n">loss_1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Update first-order network weights</span>
        <span class="n">optimizer_1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Reset first-order optimizer gradients to zero for the next iteration</span>

        <span class="c1"># Update the first-order scheduler</span>
        <span class="n">scheduler_1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Update the second-order scheduler</span>
        <span class="n">scheduler_2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">epoch_1_order</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_1</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">epoch_2_order</span>

<span class="c1"># Hyperparameters</span>
<span class="n">hidden</span><span class="o">=</span><span class="mi">60</span>
<span class="n">factor</span><span class="o">=</span><span class="mi">1</span>
<span class="n">gelu</span><span class="o">=</span><span class="kc">False</span>
<span class="n">gam</span><span class="o">=</span><span class="mf">0.99</span>
<span class="n">stepsize</span><span class="o">=</span><span class="mi">1</span>
<span class="n">meta</span><span class="o">=</span><span class="kc">True</span>

<span class="c1"># Initialize any global variables or settings, potentially for random seed setting or environment setup</span>
<span class="n">initialize_global</span><span class="p">()</span>

<span class="c1"># Prepare networks, loss functions, optimizers, and schedulers for pre-training</span>
<span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">criterion_1</span><span class="p">,</span> <span class="n">criterion_2</span><span class="p">,</span> <span class="n">optimizer_1</span><span class="p">,</span> <span class="n">optimizer_2</span><span class="p">,</span> <span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">prepare_pre_training</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">gelu</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">gam</span><span class="p">)</span>

<span class="c1"># Conduct pre-training for both the first-order and second-order networks</span>
<span class="n">first_order_network_pre</span><span class="p">,</span> <span class="n">second_order_network_pre</span><span class="p">,</span> <span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">epoch_2_order</span> <span class="o">=</span> <span class="n">pre_train</span><span class="p">(</span><span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">criterion_1</span><span class="p">,</span> <span class="n">criterion_2</span><span class="p">,</span> <span class="n">optimizer_1</span><span class="p">,</span> <span class="n">optimizer_2</span><span class="p">,</span> <span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">meta</span><span class="p">)</span>

<span class="c1"># Plot the training progress of both networks to visualize performance and learning trends</span>
<span class="n">pre_train_plots</span><span class="p">(</span><span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">epoch_2_order</span><span class="p">,</span> <span class="s2">"2nd-Order-Network"</span><span class="p">)</span>

<span class="c1"># Configuration step for the main training phase or evaluation</span>
<span class="n">Testing_patterns</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">,</span> <span class="n">loaded_model_2</span> <span class="o">=</span> <span class="n">config_training</span><span class="p">(</span><span class="n">first_order_network_pre</span><span class="p">,</span> <span class="n">second_order_network_pre</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">gelu</span><span class="p">)</span>

<span class="c1"># Perform testing of the trained models on a separate dataset to evaluate performance</span>
<span class="n">f1_scores_high_wager</span><span class="p">,</span> <span class="n">f1_scores_low_wager</span><span class="p">,</span> <span class="n">results_for_plotting</span> <span class="o">=</span> <span class="n">testing</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">,</span> <span class="n">loaded_model_2</span><span class="p">)</span>

<span class="c1"># Visualize the testing results, comparing the model performance against a baseline to assess improvements</span>
<span class="n">plot_testing</span><span class="p">(</span><span class="n">results_for_plotting</span><span class="p">,</span> <span class="s2">"Baseline"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h3>Discussion point<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>Let’s dive into the outcomes!</p>
<ul class="simple">
<li><p>Did you notice any variations between the two models?</p></li>
<li><p>Can you explain how these differences influenced the performance?</p></li>
<li><p>What role does a second-order network play, and in which situations would it be more effective?</p></li>
</ul>
</section>
</section>
<hr class="docutils"/>
<section id="section-2b-hoss-model">
<h2>Section 2b: HOSS model<a class="headerlink" href="#section-2b-hoss-model" title="Permalink to this heading">#</a></h2>
<section id="id7">
<h3>Video<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<section id="video-3">
<h4>Video 3<a class="headerlink" href="#video-3" title="Permalink to this heading">#</a></h4>
<div class="cell tag_remove-input docutils container">
</div>
<p>In this section, we’ll merge ideas from earlier discussions to present a fresh perspective on how conscious awareness might arise in neural systems. This view comes from higher-order theory, which suggests that consciousness stems from the ability to monitor basic, or first-order, information processing activities, instead of merely broadcasting information globally. This concept agrees with global workspace theories that emphasize the need for a comprehensive monitor that oversees various first-order processes. Moreover, it extends the ideas discussed previously about the role of a second-order network, which is crucial for overseeing first-order operations and helps us understand phenomena like blindsight, where a person can respond to visual stimuli without consciously seeing them.</p>
<p>To analyze how our brains handle and update perceptions, we’ll operate within a simplified Bayesian framework. This framework helps us evaluate how we perceive reality based on the information we receive. For example, if you hear rustling leaves, your brain calculates the likelihood of it being caused by the wind versus an animal. This calculation involves updating what we initially guess (our prior belief) with new evidence (observed data), resulting in a new, more informed belief (posterior probability).</p>
<p>The function below calculates these updated beliefs and uses Kullback-Leibler (KL) divergence to quantify how much the new information changes our understanding. The KL divergence is a way of measuring the ‘distance’ between your initial belief and your updated belief. It’s like measuring how much you have to change your mind given new evidence.</p>
<p>We base our analysis on a flat, or single-layer, Bayesian network model. This model directly connects our sensory inputs with our perceptual states, simplifying the complex interactions in our brain into a more manageable form. By stripping away the complexities of multi-layered networks, we focus purely on how direct observations impact our consciousness. This simplified approach helps us to better understand the intricate dance between perception and awareness in our neural systems.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">HOSS_evaluate_flat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Perform inference on a 2D Bayes net for asymmetric inference on presence vs. absence.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    X - Observed data</span>
<span class="sd">    mu - Means for each perceptual state</span>
<span class="sd">    Sigma - Covariance matrix</span>
<span class="sd">    Wprior - Prior probabilities of perceptual states</span>

<span class="sd">    #Returns:</span>
<span class="sd">    post_W - Posterior probabilities of perceptual states</span>
<span class="sd">    KL_W - Kullback-Leibler divergence from posterior to prior</span>
<span class="sd">    """</span>
    <span class="c1"># Prior on perceptual states W</span>
    <span class="n">p_W</span> <span class="o">=</span> <span class="n">Wprior</span>

    <span class="c1"># Compute likelihood of observed X for each possible W (P(X|W))</span>
    <span class="n">log_lik_X_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">[</span><span class="n">m</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">Sigma</span><span class="p">))</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>

    <span class="c1"># Renormalize to get P(X|W)</span>
    <span class="n">log_p_X_W</span> <span class="o">=</span> <span class="n">log_lik_X_W</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">log_lik_X_W</span><span class="p">)</span>

    <span class="c1"># Posterior over W (P(W|X=x))</span>
    <span class="n">log_post_W</span> <span class="o">=</span> <span class="n">log_p_X_W</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_W</span><span class="p">)</span>
    <span class="n">log_post_W</span> <span class="o">=</span> <span class="n">log_post_W</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">log_post_W</span><span class="p">)</span>  <span class="c1"># Normalize</span>
    <span class="n">post_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_post_W</span><span class="p">)</span>

    <span class="c1"># KL divergences</span>
    <span class="n">KL_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">post_W</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">post_W</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_W</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">post_W</span><span class="p">,</span> <span class="n">KL_W</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="make-our-stimulus-space">
<h3>Make our stimulus space<a class="headerlink" href="#make-our-stimulus-space" title="Permalink to this heading">#</a></h3>
<p>The model we are using is grounded in classical “signal detection theory”, or SDT for short. SDT is in turn a special case of a Bayesian generative model, in which an arbitrary “evidence” value is drawn from an unknown distribution, and the task of the observer is to infer which distribution this evidence came from.</p>
<p>Let’s give a bit more detail on how SDT fits into the broader framework of Bayesian generative models. In SDT, an observer receives a piece of evidence—this could be any sensory input, like a sound, a light signal, or a statistical data point. The evidence comes from one of several potential distributions. Each distribution represents a different “state of the world.” For instance, one distribution might represent the presence of a signal (like a beep), while another might represent just noise. The observer uses Bayesian inference to assess the probability that the received evidence came from one distribution or another. This involves updating their beliefs (probabilities) based on the new evidence. Based on the probabilities calculated through Bayesian inference, the observer decides which distribution most likely produced the evidence.</p>
<p>Let’s now imagine we have two categories, A and B - for instance, left- and right-tilted visual stimuli. The sensory “evidence” can be written as 2D vector, where the first element is evidence for A, and the second element evidence for B:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating the array X with strong evidence for A and weak evidence for B</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>The origin (0,0) represents low activation of both features, consistent with no stimulus (or noise) being presented. Comparing how the model handles inference on stimulus presence vs. absence - detecting, vs. not detecting a stimulus - allows us to capture the classical conscious vs. unconscious contrast in consciousness science.</p>
<p>Let’s start by creating our space, and placing three Gaussian distributions on the space that represent the likelihood of observing a pair of features given each of three stimulus classes: leftward tilt (w1), rightward tilt (w2) and noise/nothing (w0). By setting up this model, we aim to simulate and analyze how an observer infers the presence or absence of a stimulus. When the observer detects a stimulus, the inference process would lean towards either the leftward or rightward tilt, depending on which Gaussian (w1 or w2) the observed data points are closer to in feature space. When the observer fails to detect a stimulus, the inference process would recognize that the data points fall closer to the noise distribution centered at the origin.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the grid</span>
<span class="n">xgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mf">6.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">xgrid</span><span class="p">)</span>

<span class="c1"># Mean and covariance of the distributions</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]])</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Plotting</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>

<span class="c1"># Colors and labels according to the specification</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'green'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'w0'</span><span class="p">,</span> <span class="s1">'w1'</span><span class="p">,</span> <span class="s1">'w2'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">labels</span><span class="p">)):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">)),</span> <span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Create custom legends</span>
<span class="n">legend_elements</span> <span class="o">=</span> <span class="p">[</span><span class="n">Patch</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">color</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">labels</span><span class="p">)]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">legend_elements</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="c1"># Reverse the X1 axis</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'X1'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'X2'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'2D SDT'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="o">-</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the input parameters</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">Wprior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">])</span>  <span class="c1"># flat priors</span>

<span class="c1"># High evidence for X1, low evidence for X2</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">post_w</span><span class="p">,</span> <span class="n">KL_W</span> <span class="o">=</span> <span class="n">HOSS_evaluate_flat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Posterior probabilities for X = [3, 0]:'</span><span class="p">,</span> <span class="n">post_w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'KL Divergence for X = [3, 0]:'</span><span class="p">,</span> <span class="n">KL_W</span><span class="p">)</span>

<span class="c1"># High evidence for X2, low evidence for X1</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">post_w</span><span class="p">,</span> <span class="n">KL_W</span> <span class="o">=</span> <span class="n">HOSS_evaluate_flat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Posterior probabilities for X = [0, 3]:'</span><span class="p">,</span> <span class="n">post_w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'KL Divergence for X = [0, 3]:'</span><span class="p">,</span> <span class="n">KL_W</span><span class="p">)</span>

<span class="c1"># No evidence for either</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">post_w</span><span class="p">,</span> <span class="n">KL_W</span> <span class="o">=</span> <span class="n">HOSS_evaluate_flat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Posterior probabilities for X = [0, 0]:'</span><span class="p">,</span> <span class="n">post_w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'KL Divergence for X = [0, 0]:'</span><span class="p">,</span> <span class="n">KL_W</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This is as we would expect - the most likely state is recovered in each case. The slightly higher KL divergence in the third scenario indicates a greater degree of “surprise” or information gain, as the prior was uniformly distributed across all states, but the posterior is now highly concentrated on the third state.</p>
</section>
<section id="add-in-higher-order-node-for-global-detection">
<h3>Add in higher-order node for global detection<a class="headerlink" href="#add-in-higher-order-node-for-global-detection" title="Permalink to this heading">#</a></h3>
<p>So far, our model has been straightforward, or “flat,” where each perceptual state (like leftward tilt, rightward tilt, or no stimulus) is treated separately. However, real-life perception often requires more complex judgments about the presence or absence of any stimulus, not just identifying specific types. This is where a higher-order node comes into play.</p>
<section id="introducing-the-a-level">
<h4>Introducing the “A” Level:<a class="headerlink" href="#introducing-the-a-level" title="Permalink to this heading">#</a></h4>
<p>Think of the “A” level as a kind of overseer or monitor that watches over the lower-level states (w1, w2, etc.). This higher-order node isn’t concerned with the specific content of the stimulus (like which direction something is tilting) but rather with whether there’s any significant stimulus at all versus just noise. It takes inputs from the same data (pairs of X’s), but it adds a layer of awareness. It evaluates whether the data points suggest any meaningful content or if they’re likely just random noise. The system can now answer questions on two levels—about the content (W-level) and about the awareness or presence of any content (A-level). The output from the A-level, denoted as <code class="docutils literal notranslate"><span class="pre">post_A</span></code>, represents the posterior probability that there is any relevant content as opposed to mere noise. To make this work, we also need to set priors (initial guesses before seeing the data) at both the W-level (content) and A-level (awareness). This helps the model start with a baseline expectation about the likelihood of encountering various stimuli or noise.</p>
<p>By introducing this higher-order node, our model gains several advantages:</p>
<ul class="simple">
<li><p><strong>Flexibility in awareness</strong>: the A-level allows the system to flexibly determine the overall presence of any stimulus across a variety of conditions, enhancing the model’s ability to deal with complex, real-world sensory environments.</p></li>
<li><p><strong>Enhanced information processing</strong>: with the higher-order state, the model doesn’t just react to sensory inputs; it evaluates them. This means it can more effectively determine which sensory data are reliable and should be used for further processing and which should be disregarded as noise.</p></li>
<li><p><strong>Improved efficiency</strong>: the higher-order monitoring makes the system more efficient. It can prevent unnecessary processing of irrelevant information and focus computational resources on processing significant, reliable stimuli.</p></li>
</ul>
<p>In the next sections, we will illustrate the operation of a higher-order state space (HOSS) for monitoring first-order information processing. This model, with its higher-order node, more closely mimics human perceptual processing where not every sensory input leads to awareness. It only brings to consciousness those inputs that are deemed significant through this higher-level evaluation. This higher-order state has a wide purview, enabling the system to “know” which of its (potentially high-dimensional, rich) first-order states are reliable enough for use in future computation and communication to others. Through this mechanism, the HOSS model not only enhances the accuracy of stimulus awareness but also significantly improves the system’s efficiency in processing and utilizing information.</p>
</section>
</section>
<section id="coding-exercise">
<h3>Coding exercise<a class="headerlink" href="#coding-exercise" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">HOSS_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Inference on 2D Bayes net for asymmetric inference on presence vs. absence.</span>
<span class="sd">    """</span>

    <span class="c1">#################################################</span>
    <span class="c1">## TODO for students: fill in the missing variables ##</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
    <span class="c1">#################################################</span>

    <span class="c1"># Initialise variables and conditional prob tables</span>
    <span class="n">p_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">])</span>  <span class="c1"># prior on awareness state A</span>
    <span class="n">p_W_a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wprior</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># likelihood of world states W given aware, last entry is absence</span>
    <span class="n">p_W_a0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Wprior</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># likelihood of world states W given unaware, last entry is absence</span>
    <span class="n">p_W</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_W_a1</span> <span class="o">+</span> <span class="n">p_W_a0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># prior on W marginalising over A (for KL)</span>

    <span class="c1"># Compute likelihood of observed X for each possible W (P(X|mu_w, Sigma))</span>
    <span class="n">lik_X_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">for</span> <span class="n">mu_i</span> <span class="ow">in</span> <span class="n">mu</span><span class="p">])</span>
    <span class="n">p_X_W</span> <span class="o">=</span> <span class="n">lik_X_W</span> <span class="o">/</span> <span class="n">lik_X_W</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># normalise to get P(X|W)</span>

    <span class="c1"># Combine with likelihood of each world state w given awareness state A</span>
    <span class="n">lik_W_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">p_X_W</span> <span class="o">*</span> <span class="n">p_W_a0</span> <span class="o">*</span> <span class="n">p_A</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p_X_W</span> <span class="o">*</span> <span class="n">p_W_a1</span> <span class="o">*</span> <span class="n">p_A</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">post_A</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># sum over W</span>
    <span class="n">post_A</span> <span class="o">=</span> <span class="n">post_A</span> <span class="o">/</span> <span class="n">post_A</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># normalise</span>

    <span class="c1"># Posterior over W (P(W|X=x) marginalising over A)</span>
    <span class="n">post_W</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># sum over A</span>
    <span class="n">post_W</span> <span class="o">=</span> <span class="n">post_W</span> <span class="o">/</span> <span class="n">post_W</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># normalise</span>

    <span class="c1"># KL divergences</span>
    <span class="n">KL_W</span> <span class="o">=</span> <span class="p">(</span><span class="n">post_W</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">post_W</span> <span class="o">/</span> <span class="n">p_W</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">KL_A</span> <span class="o">=</span> <span class="p">(</span><span class="n">post_A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">post_A</span> <span class="o">/</span> <span class="n">p_A</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">post_W</span><span class="p">,</span> <span class="n">post_A</span><span class="p">,</span> <span class="n">KL_W</span><span class="p">,</span> <span class="n">KL_A</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D5_Mysteries/solutions/W2D5_Tutorial1_Solution_c1e9099b.py"><em>Click for solution</em></a></p>
<p>This is now factorised in the code, so we first set the prior on presence (vs. absence), and then set the priors on w1 vs. w2, and the model takes care of the rest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the input parameters for this specific example</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># Input observed features</span>
<span class="n">Wprior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>  <span class="c1"># Prior probabilities of stimuli</span>
<span class="n">Aprior</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Prior probability of being aware</span>

<span class="c1"># Call the HOSS_evaluate function with the specified parameters</span>
<span class="n">post_W</span><span class="p">,</span> <span class="n">post_A</span><span class="p">,</span> <span class="n">KL_W</span><span class="p">,</span> <span class="n">KL_A</span> <span class="o">=</span> <span class="n">HOSS_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>

<span class="c1"># Print the posterior probabilities</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Posterior probabilities at W level: </span><span class="si">{</span><span class="n">post_W</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Posterior probability at A level: </span><span class="si">{</span><span class="n">post_A</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the input parameters for this specific example</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># Input observed features</span>
<span class="n">Wprior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>  <span class="c1"># Prior probabilities of stimuli</span>
<span class="n">Aprior</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Prior probability of being aware</span>

<span class="c1"># Call the HOSS_evaluate function with the specified parameters</span>
<span class="n">post_W</span><span class="p">,</span> <span class="n">post_A</span><span class="p">,</span> <span class="n">KL_W</span><span class="p">,</span> <span class="n">KL_A</span> <span class="o">=</span> <span class="n">HOSS_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>

<span class="c1"># Print the posterior probabilities</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Posterior probabilities at W level: </span><span class="si">{</span><span class="n">post_W</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Posterior probability at A level: </span><span class="si">{</span><span class="n">post_A</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="simulate-kl-divergence-surfaces">
<h3>Simulate KL divergence surfaces<a class="headerlink" href="#simulate-kl-divergence-surfaces" title="Permalink to this heading">#</a></h3>
<p>We can also simulate K-L divergences (a measure of Bayesian surprise) at each layer in the network, which under predictive coding models of brain has been proposed to scale with neural activation (eg Friston, 2005; Summerfield &amp; de Lange, 2014).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the grid</span>
<span class="n">xgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Define the means for the Gaussian distributions</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>

<span class="c1"># Define the covariance matrix</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Prior probabilities</span>
<span class="n">Wprior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">Aprior</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Initialize arrays to hold confidence and posterior probability</span>
<span class="n">confW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>
<span class="n">posteriorAware</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>
<span class="n">KL_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>
<span class="n">KL_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>

<span class="c1"># Compute confidence and posterior probability for each point in the grid</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xgrid</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">xj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xgrid</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">xi</span><span class="p">,</span> <span class="n">xj</span><span class="p">]</span>
        <span class="n">post_w</span><span class="p">,</span> <span class="n">post_A</span><span class="p">,</span> <span class="n">KL_w</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">KL_A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">HOSS_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>

        <span class="n">confW</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">post_w</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">post_w</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">posteriorAware</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">post_A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Calculate the mean K-L divergence for absent and present awareness states</span>
<span class="n">KL_A_absent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">KL_A</span><span class="p">[</span><span class="n">posteriorAware</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">KL_A_present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">KL_A</span><span class="p">[</span><span class="n">posteriorAware</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">KL_w_absent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">KL_w</span><span class="p">[</span><span class="n">posteriorAware</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">KL_w_present</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">KL_w</span><span class="p">[</span><span class="n">posteriorAware</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">])</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># K-L divergence, perceptual states</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">xgrid</span><span class="p">,</span> <span class="n">KL_w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'X1'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'X2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'K-L divergence, perceptual states'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'square'</span><span class="p">)</span>

<span class="c1"># K-L divergence, awareness state</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">xgrid</span><span class="p">,</span> <span class="n">KL_A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'X1'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'X2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'K-L divergence, awareness state'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'square'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h3>Discussion point<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p>Can you recognise the difference between the K-L divergence for the W-level and the one for the A-level?</p>
</section>
<section id="id9">
<h3>Hint<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h3>
<p>At the level of perceptual states W, there is substantial asymmetry in the K-L divergence expected when the model says ‘seen’ vs. ‘unseen’ (lefthand panel). This is due to the large belief updates invoked in the perceptual layer W by samples that deviate from the lower lefthand corner - from absence. In contrast, when we compute K-L divergence for the A-level (righthand panel), the level of prediction error is symmetric across seen and unseen decisions, leading to “hot” zones both at the upper righthand (present) and lower lefthand (absent) corners of the 2D space.</p>
<p>Intuitively, this means that at the W-level there’s a noticeable difference in the K-L divergence values between “seen” and “unseen” predictions. This large difference is mainly due to significant updates in the model’s beliefs at this level when the detected samples are far from what is expected under the condition of “absence.” However, when we analyze the K-L divergence at the A-level, the discrepancies in prediction errors between “seen” and “unseen” are balanced. This creates equally strong responses in the model, whether something is detected or not detected.</p>
<p>We can also sort the K-L divergences as a function of whether the model “reported” presence or absence. As can be seen in the bar plots below, there is more asymmetry in the prediction error at the W compared to the A levels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create figure with specified size</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># KL divergence for W states</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">'unseen'</span><span class="p">,</span> <span class="s1">'seen'</span><span class="p">],</span> <span class="p">[</span><span class="n">KL_w_absent</span><span class="p">,</span> <span class="n">KL_w_present</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'K-L divergence, W states'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

<span class="c1"># KL divergence for A states</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">'unseen'</span><span class="p">,</span> <span class="s1">'seen'</span><span class="p">],</span> <span class="p">[</span><span class="n">KL_A_absent</span><span class="p">,</span> <span class="n">KL_A_present</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'K-L divergence, A states'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Show plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="simulate-ignition-asymmetry-vs-symmetry">
<h3>Simulate ignition (asymmetry vs. symmetry)<a class="headerlink" href="#simulate-ignition-asymmetry-vs-symmetry" title="Permalink to this heading">#</a></h3>
<p>A notable feature about the HOSS architecture is that it is designed in a way that there are more possible states that the model can perceive when something is present compared to when something is absent. This setup leads to an interesting observation: when the model decides something is present, it tends to generate more prediction errors across its network. This accumulation of prediction errors is measured using Kullback-Leibler (K-L) divergence at various points in the network, particularly at a level called W.</p>
<p>This behavior, where there is more prediction error during presence decisions, relates closely to what researchers observe in the brain, known as global ignition responses. These responses are significant bursts of brain activity linked to the moment we become aware of something. Studies, such as those by Del Cul et al. (2007) and Dehaene and Changeux (2011), suggest that these responses support theories like the global workspace model, which explains consciousness as a kind of information sharing across different parts of the brain.</p>
<p>In our model, we explore this by adjusting the strength of the stimulus (referred to as sensory precision) and observing how it affects the prediction errors for both ‘seen’ and ‘unseen’ decisions at different levels of the network.</p>
<p>However, it’s important to note that in the context of the HOSS architecture, these ignition-like responses are not the cause of information being shared globally across the network. Instead, they are more like side effects (epiphenomenal consequences) of other underlying computations. In simpler terms, these bursts of activity are results of what’s happening deeper in the network, not the direct means of sharing information globally.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment parameters</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">Nsubjects</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">Ntrials</span> <span class="o">=</span> <span class="mi">600</span>
<span class="n">cond</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Ntrials</span><span class="o">//</span><span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Ntrials</span><span class="o">//</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Ntrials</span><span class="o">//</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="n">Wprior</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">Aprior</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Sensory precision values</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="c1"># Initialize lists for results</span>
<span class="n">all_KL_w_yes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sem_KL_w_yes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_KL_w_no</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sem_KL_w_no</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_KL_A_yes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sem_KL_A_yes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_KL_A_no</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sem_KL_A_no</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_prob_y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#################################################</span>
<span class="c1">## TODO for students: fill in the missing variables ##</span>
<span class="c1"># Fill out function and remove</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
<span class="c1">#################################################</span>

<span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Processing gammas'</span><span class="p">):</span>
    <span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mf">1.</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">mean_KL_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nsubjects</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">mean_KL_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nsubjects</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">prob_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nsubjects</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">Nsubjects</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Subjects for gamma=</span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">KL_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cond</span><span class="p">))</span>
        <span class="n">KL_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cond</span><span class="p">))</span>
        <span class="n">posteriorAware</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cond</span><span class="p">))</span>

        <span class="c1"># Generate sensory samples</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">cov</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cond</span><span class="p">])</span>

        <span class="c1"># Model inversion for each trial</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">post_w</span><span class="p">,</span> <span class="n">post_A</span><span class="p">,</span> <span class="n">KL_w</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">KL_A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">HOSS_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>
            <span class="n">posteriorAware</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">post_A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Assuming post_A is a tuple with awareness probability at index 1</span>

        <span class="n">binaryAware</span> <span class="o">=</span> <span class="n">posteriorAware</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">conditions</span> <span class="o">=</span> <span class="p">[(</span><span class="n">cond</span> <span class="o">==</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="n">cond</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="n">cond</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="n">cond</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)]</span>
            <span class="n">aware_conditions</span> <span class="o">=</span> <span class="p">[(</span><span class="n">binaryAware</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">binaryAware</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">binaryAware</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">binaryAware</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">mean_KL_w</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">KL_w</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">aware_conditions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">conditions</span><span class="p">[</span><span class="n">i</span><span class="p">])])</span>
            <span class="n">mean_KL_A</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">KL_A</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">aware_conditions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">conditions</span><span class="p">[</span><span class="n">i</span><span class="p">])])</span>

        <span class="n">prob_y</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">binaryAware</span><span class="p">[</span><span class="n">cond</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">])</span>

    <span class="c1"># Aggregate results across subjects</span>
    <span class="n">all_KL_w_yes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_KL_w</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="n">sem_KL_w_yes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mean_KL_w</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Nsubjects</span><span class="p">))</span>
    <span class="n">all_KL_w_no</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_KL_w</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="n">sem_KL_w_no</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mean_KL_w</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Nsubjects</span><span class="p">))</span>
    <span class="n">all_KL_A_yes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_KL_A</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="n">sem_KL_A_yes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mean_KL_A</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Nsubjects</span><span class="p">))</span>
    <span class="n">all_KL_A_no</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_KL_A</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="n">sem_KL_A_no</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mean_KL_A</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Nsubjects</span><span class="p">))</span>
    <span class="n">all_prob_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">prob_y</span><span class="p">))</span>

<span class="c1"># Create figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mf">4.67</span><span class="p">))</span>

<span class="c1"># First subplot: Probability of reporting "seen" for w_1 or w_2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">all_prob_y</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'SOA (precision)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Prob. report "seen" for w_1 or w_2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Second subplot: K-L divergence, perceptual states</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">all_KL_w_yes</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">sem_KL_w_yes</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Seen'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">all_KL_w_no</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">sem_KL_w_no</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Unseen'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'SOA (precision)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'K-L divergence, perceptual states'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Third subplot: K-L divergence, awareness state</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">all_KL_A_yes</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">sem_KL_A_yes</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Seen'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">all_KL_A_no</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">sem_KL_A_no</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Unseen'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'SOA (precision)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'K-L divergence, awareness state'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Adjust layout and display the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D5_Mysteries/solutions/W2D5_Tutorial1_Solution_4919b2bc.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D5_Mysteries/static/W2D5_Tutorial1_Solution_4919b2bc_585.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D5_Mysteries/static/W2D5_Tutorial1_Solution_4919b2bc_585.png" style="width: 1575.0px; height: 443.0px;"/></a>
</section>
<section id="id10">
<h3>Discussion point<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>Can you think of experiments that could distinguish between the HOSS and GWS accounts of ignition?</p>
</section>
</section>
<section id="bonus-section-1">
<h2>Bonus section 1<a class="headerlink" href="#bonus-section-1" title="Permalink to this heading">#</a></h2>
<section id="train-a-first-order-network">
<h3>Train a first-order network<a class="headerlink" href="#train-a-first-order-network" title="Permalink to this heading">#</a></h3>
<p>This section invites you to engage with a straightforward, auto-generated dataset on blindsight, originally introduced by Pasquali et al. in 2010. Blindsight is a fascinating condition where individuals who are cortically blind due to damage in their primary visual cortex can still respond to visual stimuli without conscious perception. This intriguing phenomenon underscores the intricate nature of sensory processing and the brain’s ability to process information without conscious awareness.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the autogenerated data</span>
<span class="n">initialize_global</span><span class="p">()</span>
<span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">_</span> <span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">Generate_Patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The pre-training dataset for the network consisted of 200 patterns. These were evenly divided: half were purely noise (with unit activations randomly chosen between 0.0 and 0.02), and the other half represented potential stimuli. In the stimulus patterns, 99 out of 100 units had activations ranging between 0.0 and 0.02, with one unique unit having an activation between 0.0 and 1.0.</p>
</section>
<section id="testing-patterns">
<h3>Testing patterns<a class="headerlink" href="#testing-patterns" title="Permalink to this heading">#</a></h3>
<p>As we have seen before, the network underwent evaluations under three distinct conditions, each modifying the signal-to-noise ratio in a unique way to explore different degrees and types of blindness.</p>
<p>Suprathreshold stimulus condition: here, the network was exposed to the identical set of 200 patterns used during pre-training, testing the network’s response to familiar inputs.</p>
<p>Subthreshold stimulus condition (blindsight simulation): this condition aimed to mimic blindsight. It was achieved by introducing a slight noise increment (+0.0012) to every input of the first-order network, barring the one designated as the stimulus. This setup tested the network’s ability to discern faint signals amidst noise.</p>
<p>Low vision condition: to simulate low vision, the activation levels of the stimuli were reduced. Unlike the range from 0.0 to 1.0 used in pre-training, the stimuli’s activation levels were adjusted to span from 0.0 to 0.3. This condition examined the network’s capability to recognize stimuli with diminished intensity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare your results with the patterns generate below</span>
<span class="n">set_1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">set_2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">set_3</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_patterns</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">set_1</span><span class="p">,</span><span class="s2">"Suprathreshold stimulus"</span><span class="p">)</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">set_2</span><span class="p">,</span><span class="s2">"Subthreshold stimulus"</span><span class="p">)</span>
<span class="n">plot_signal_max_and_indicator</span><span class="p">(</span><span class="n">set_3</span><span class="p">,</span><span class="s2">"Low Vision"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="activity-1-building-a-nework-for-a-blindsight-situation">
<h3>Activity 1: Building a nework for a blindsight situation<a class="headerlink" href="#activity-1-building-a-nework-for-a-blindsight-situation" title="Permalink to this heading">#</a></h3>
<p>In this activity, we’ll construct a neural network model using our auto-generated dataset, focusing on blindsight scenarios. The model will primarily consist of fully connected layers, establishing a straightforward, first-order network. The aim here is to assess the basic network’s performance.</p>
</section>
<section id="steps-to-follow">
<h3>Steps to follow<a class="headerlink" href="#steps-to-follow" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Examine the network architecture: understand the structure of the neural network you’re about to work with.</p></li>
<li><p>Visualize loss metrics: observe and analyze the network’s performance during pre-training by visualizing the loss over epochs.</p></li>
<li><p>Evaluate the model: use the provided code snippets to calculate and interpret the model’s accuracy, recall, and F1-score, giving you insight into the network’s capabilities.</p></li>
</ol>
</section>
<section id="understanding-the-process">
<h3>Understanding the process<a class="headerlink" href="#understanding-the-process" title="Permalink to this heading">#</a></h3>
<p>The goal is to gain a thorough comprehension of the network’s architecture and to interpret the pre-training results visually. This will provide a clearer picture of the model’s potential and limitations.</p>
<p>The network is designed as a backpropagation autoassociator. It features a 100-unit input layer, directly linked to a 60-unit hidden layer, which in turn connects to a 100-unit output layer. Initial connection weights are set within the range of -1.0 to 1.0 for the first-order network. To mitigate overfitting, dropout is employed within the network architecture. The architecture includes a configurable activation function. This flexibility allows for adjustments and tuning in Activity 3, aiming for optimal model performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FirstOrderNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">data_factor</span><span class="p">,</span> <span class="n">use_gelu</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initializes the FirstOrderNetwork with specific configurations.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - hidden_units (int): The number of units in the hidden layer.</span>
<span class="sd">        - data_factor (int): Factor to scale the amount of data processed.</span>
<span class="sd">                             A factor of 1 indicates the default data amount,</span>
<span class="sd">                             while 10 indicates 10 times the default amount.</span>
<span class="sd">        - use_gelu (bool): Flag to use GELU (True) or ReLU (False) as the activation function.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FirstOrderNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Define the encoder, hidden, and decoder layers with specified units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="c1"># Dropout layer to prevent overfitting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># Temperature parameter for activation sharpness control</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="c1"># Set the data factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_factor</span> <span class="o">=</span> <span class="n">data_factor</span>

        <span class="c1"># Choose the activation function based on the use_gelu flag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_gelu</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Other activation functions for various purposes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span>

        <span class="c1"># Initialize network weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initializes weights of the encoder, hidden, and decoder layers uniformly."""</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Defines the forward pass through the network.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - x (Tensor): The input tensor to the network.</span>

<span class="sd">        Returns:</span>
<span class="sd">        - Tensor: The output of the network after passing through the layers and activations.</span>
<span class="sd">        """</span>
        <span class="c1"># Encoder step with dropout and sigmoid activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">))</span>

        <span class="c1"># Hidden layer step with dropout and sigmoid activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">))</span>

        <span class="c1"># Decoder step with dropout and sigmoid activation</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">))</span>

        <span class="c1"># Adjust output based on a threshold</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">output</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">output</span> <span class="o">+</span> <span class="mf">0.12</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<p>For now, we will train the first order network only.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the architecture, optimizers, loss functions, and schedulers for pre training</span>
<span class="n">hidden</span><span class="o">=</span><span class="mi">60</span>
<span class="n">factor</span><span class="o">=</span><span class="mi">1</span>
<span class="n">gelu</span><span class="o">=</span><span class="kc">False</span>
<span class="n">gam</span><span class="o">=</span><span class="mf">0.99</span>
<span class="n">stepsize</span><span class="o">=</span><span class="mi">1</span>

<span class="n">initialize_global</span><span class="p">()</span>

<span class="c1"># Networks instantiation</span>
<span class="n">first_order_network</span> <span class="o">=</span> <span class="n">FirstOrderNetwork</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span><span class="n">factor</span><span class="p">,</span><span class="n">gelu</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">second_order_network</span> <span class="o">=</span> <span class="n">SecondOrderNetwork</span><span class="p">(</span><span class="n">gelu</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># We define it, but won't use it until activity 3</span>

<span class="c1"># Loss function</span>
<span class="n">criterion_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Optimizer</span>
<span class="n">optimizer_1</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">first_order_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate_1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>

<span class="c1"># Learning rate schedulers</span>
<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_1</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gam</span><span class="p">)</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># Generate training patterns and targets for each epoch.</span>
    <span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">stim_present_tensor</span><span class="p">,</span> <span class="n">stim_absent_tensor</span><span class="p">,</span> <span class="n">order_2_tensor</span> <span class="o">=</span> <span class="n">Generate_Patterns</span><span class="p">(</span><span class="n">patterns_number</span><span class="p">,</span> <span class="n">num_units</span><span class="p">)</span>

    <span class="c1"># Forward pass through the first-order network</span>
    <span class="n">output_first_order</span> <span class="o">=</span> <span class="n">first_order_network</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">)</span>

    <span class="c1"># Skip computations for the second-order network</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># Potentially forward pass through the second-order network without tracking gradients</span>
        <span class="n">output_second_order</span> <span class="o">=</span> <span class="n">second_order_network</span><span class="p">(</span><span class="n">patterns_tensor</span><span class="p">,</span> <span class="n">output_first_order</span><span class="p">)</span>

    <span class="c1"># Calculate the loss for the first-order network (accuracy of stimulus representation)</span>
    <span class="n">loss_1</span> <span class="o">=</span> <span class="n">criterion_1</span><span class="p">(</span><span class="n">output_first_order</span><span class="p">,</span> <span class="n">stim_present_tensor</span><span class="p">)</span>

    <span class="c1"># Backpropagate the first-order network's loss</span>
    <span class="n">loss_1</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Update first-order network weights</span>
    <span class="n">optimizer_1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Reset first-order optimizer gradients to zero for the next iteration</span>
    <span class="n">optimizer_1</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Update the first-order scheduler</span>
    <span class="n">scheduler_1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">epoch_1_order</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_1</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Plot training loss curve</span>
<span class="n">pre_train_plots</span><span class="p">(</span><span class="n">epoch_1_order</span><span class="p">,</span> <span class="n">epoch_2_order</span><span class="p">,</span> <span class="s2">"First order network training"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="testing-under-3-blindsight-conditions">
<h3>Testing under 3 blindsight conditions<a class="headerlink" href="#testing-under-3-blindsight-conditions" title="Permalink to this heading">#</a></h3>
<p>We will now use the testing auto-generated datasets from activity 1 to test the network’s performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare networks for testing by calling the configuration function</span>
<span class="n">Testing_patterns</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">,</span> <span class="n">loaded_model_2</span> <span class="o">=</span> <span class="n">config_training</span><span class="p">(</span><span class="n">first_order_network</span><span class="p">,</span> <span class="n">second_order_network</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">gelu</span><span class="p">)</span>

<span class="c1"># Perform testing using the defined function and plot the results</span>
<span class="n">f1_scores_high_wager</span><span class="p">,</span> <span class="n">f1_scores_low_wager</span><span class="p">,</span> <span class="n">results_for_plotting</span> <span class="o">=</span> <span class="n">testing</span><span class="p">(</span><span class="n">Testing_patterns</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">,</span> <span class="n">loaded_model_2</span><span class="p">)</span>

<span class="c1"># Assuming plot_testing is defined, call it to display results</span>
<span class="n">plot_testing</span><span class="p">(</span><span class="n">results_for_plotting</span><span class="p">,</span> <span class="s2">"Baseline"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="bonus-section-2">
<h2>Bonus section 2<a class="headerlink" href="#bonus-section-2" title="Permalink to this heading">#</a></h2>
<section id="plot-surfaces-for-content-awareness-inferences">
<h3>Plot surfaces for content / awareness inferences<a class="headerlink" href="#plot-surfaces-for-content-awareness-inferences" title="Permalink to this heading">#</a></h3>
<p>To explore the properties of the HOSS model, we can simulate inference at different levels of the hierarchy over the full 2D space of possible input X’s. The left panel below shows that the probability of awareness (of any stimulus contents) rises in a graded manner from the lower left corner of the graph (low activation of any feature) to the upper right (high activation of both features). In contrast, the right panel shows that confidence in making a discrimination response (e.g. rightward vs. leftward) increases away from the major diagonal, as the model becomes sure that the sample was generated by either a leftward or rightward tilted stimulus.</p>
<p>Together, the two surfaces make predictions about the relationships we might see between discrimination confidence and awareness in a simple psychophysics experiment. One notable prediction is that discrimination could still be possible - and lead to some degree of confidence - even when the higher-order node is “reporting” unawareness of the stimulus.</p>
<p>Now, let’s get hands on and plot those auto-generated patterns!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the grid</span>
<span class="n">xgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Define the means for the Gaussian distributions</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>

<span class="c1"># Define the covariance matrix</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Prior probabilities</span>
<span class="n">Wprior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">Aprior</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Initialize arrays to hold confidence and posterior probability</span>
<span class="n">confW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>
<span class="n">posteriorAware</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>
<span class="n">KL_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>
<span class="n">KL_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)))</span>

<span class="c1"># Compute confidence and posterior probability for each point in the grid</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xgrid</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">xj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xgrid</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">xi</span><span class="p">,</span> <span class="n">xj</span><span class="p">]</span>
        <span class="n">post_w</span><span class="p">,</span> <span class="n">post_A</span><span class="p">,</span> <span class="n">KL_w</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">KL_A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">HOSS_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">Aprior</span><span class="p">,</span> <span class="n">Wprior</span><span class="p">)</span>
        <span class="n">confW</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">post_w</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">post_w</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">posteriorAware</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">post_A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Posterior probability "seen"</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">xgrid</span><span class="p">,</span> <span class="n">posteriorAware</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'X1'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'X2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Posterior probability "seen"'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'square'</span><span class="p">)</span>

<span class="c1"># Confidence in identity</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">contour_set</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">xgrid</span><span class="p">,</span> <span class="n">confW</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">xgrid</span><span class="p">,</span> <span class="n">posteriorAware</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">'white'</span><span class="p">])</span>  <span class="c1"># Line contour for threshold</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'X1'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'X2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Confidence in identity'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'square'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id11">
<h2>Video<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<section id="video-4">
<h3>Video 4<a class="headerlink" href="#video-4" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="video-5">
<h3>Video 5<a class="headerlink" href="#video-5" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="video-6">
<h3>Video 6<a class="headerlink" href="#video-6" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="video-7">
<h3>Video 7<a class="headerlink" href="#video-7" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="video-8">
<h3>Video 8<a class="headerlink" href="#video-8" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
</section>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/W2D5_Mysteries/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W2D5_Intro.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Intro</p>
</div>
</a>
<a class="right-next" href="W2D5_Tutorial2.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 2: Ethics</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Consciousness
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Install and import feedback gadget
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
       Import dependencies
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
       Figure settings
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Helper functions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Plotting functions
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
       Set device (GPU or CPU). Execute
       <code class="docutils literal notranslate">
<span class="pre">
         set_device()
        </span>
</code>
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-global-neural-workspace">
   Section 1: Global Neural Workspace
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1">
     Video 1
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Video 1
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1a-modularity-of-the-mind">
     Section 1a: Modularity Of The Mind
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
       Data retrieval
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#rims">
       RIMs
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#lstm">
       LSTM
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion-point">
       Discussion point
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hint">
       Hint
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#rims-and-consciousness">
       RIMs and consciousness
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1b-a-shared-workspace">
     Section 1b: A Shared Workspace
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-creating-a-shared-workspace">
       Coding Exercise: Creating a Shared Workspace
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#step-1-aggregation-of-specialist-states">
       Step 1: Aggregation of specialist states
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#step-2-competitive-information-update-in-the-shared-workspace">
       Step 2: Competitive information update in the shared workspace
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#step-3-broadcasting-updated-information">
       Step 3: Broadcasting updated information
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#dynamic-filtering-and-enhanced-generalization">
       Dynamic filtering and enhanced generalization
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#integration-into-a-full-system">
       Integration into a full system
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1c-a-toy-model-for-illustrating-gnw">
     Section 1c: a toy model for illustrating GNW
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#recap">
     Recap
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-metacognition">
   Section 2: Metacognition
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video">
     Video
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2">
       Video 2
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2a-second-order-model">
     Section 2a: Second order model
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#activity-1-developing-a-second-order-network">
       Activity 1: Developing a Second-Order Network
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
       Discussion point
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2b-hoss-model">
     Section 2b: HOSS model
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id7">
       Video
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3">
         Video 3
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#make-our-stimulus-space">
       Make our stimulus space
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#add-in-higher-order-node-for-global-detection">
       Add in higher-order node for global detection
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#introducing-the-a-level">
         Introducing the “A” Level:
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise">
       Coding exercise
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#simulate-kl-divergence-surfaces">
       Simulate KL divergence surfaces
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id8">
       Discussion point
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id9">
       Hint
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#simulate-ignition-asymmetry-vs-symmetry">
       Simulate ignition (asymmetry vs. symmetry)
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id10">
       Discussion point
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1">
     Bonus section 1
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-a-first-order-network">
       Train a first-order network
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#testing-patterns">
       Testing patterns
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#activity-1-building-a-nework-for-a-blindsight-situation">
       Activity 1: Building a nework for a blindsight situation
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#steps-to-follow">
       Steps to follow
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#understanding-the-process">
       Understanding the process
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#testing-under-3-blindsight-conditions">
       Testing under 3 blindsight conditions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-2">
     Bonus section 2
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#plot-surfaces-for-content-awareness-inferences">
       Plot surfaces for content / awareness inferences
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id11">
     Video
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4">
       Video 4
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5">
       Video 5
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6">
       Video 6
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7">
       Video 7
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8">
       Video 8
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>